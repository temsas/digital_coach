from flask import Flask, render_template, request, jsonify
import os
import json
import logging
import re
import ast
from dotenv import load_dotenv
from services.spell_checker import SpellChecker

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

from config import Config
from services.gigachat_service import GigaChatService
from database.db_connection import Database

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
app.config['SECRET_KEY'] = 'digital-trainer-secret-2024'
app.config.from_object(Config)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–æ–≤
try:
    gigachat_service = GigaChatService()
    db = Database()
    GIGACHAT_AVAILABLE = True
    logger.info("‚úÖ GigaChat –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ")
except Exception as e:
    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ GigaChat: {e}")
    GIGACHAT_AVAILABLE = False
    gigachat_service = None
    db = None

# –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ç–µ–º—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –≤—ã–±–æ—Ä–∞
POPULAR_TOPICS = [
    "–ö–æ–º–ø—å—é—Ç–µ—Ä", 
    "–ò–Ω—Ç–µ—Ä–Ω–µ—Ç", 
    "–ü–∞—Ä–æ–ª–∏", 
    "–ë–∞–Ω–∫–æ–≤—Å–∫–∏–µ –∫–∞—Ä—Ç—ã", 
    "–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –ø–æ—á—Ç–∞"
]

@app.route('/')
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Ç—Ä–µ–Ω–∞–∂–µ—Ä–∞"""
    return render_template('index.html', 
                         GIGACHAT_AVAILABLE=GIGACHAT_AVAILABLE,
                         POPULAR_TOPICS=POPULAR_TOPICS)

@app.route('/api/generate-full-test', methods=['POST'])
def generate_full_test():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ –∏–∑ 5 –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ —Ç–µ–º–µ - –° –ü–†–û–í–ï–†–ö–û–ô –û–ü–ï–ß–ê–¢–û–ö"""
    if not GIGACHAT_AVAILABLE:
        return jsonify({
            'status': 'error',
            'error': 'GigaChat –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω'
        }), 503

    try:
        data = request.get_json()
        original_topic = data.get('topic', '').strip().lower()
        
        if not original_topic:
            return jsonify({
                'status': 'error',
                'error': '–¢–µ–º–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç–æ–π'
            }), 400

        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –æ–ø–µ—á–∞—Ç–∫–∏
        if spell_checker:
            corrected_topic, was_corrected = spell_checker.correct_spelling(original_topic)
        else:
            corrected_topic = original_topic
            was_corrected = False

        logger.info(f"üéØ –ó–∞–ø—Ä–æ—Å –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ç–µ—Å—Ç–∞ –ø–æ —Ç–µ–º–µ: '{original_topic}' -> '{corrected_topic}'")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç–µ–º–∞ –æ–¥–Ω–∞ –∏–∑ –æ—Å–Ω–æ–≤–Ω—ã—Ö (–∏–ª–∏ –∏—Ö —Å–∏–Ω–æ–Ω–∏–º—ã)
        allowed_topics = ['–∫–æ–º–ø—å—é—Ç–µ—Ä', '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç', '–ø–∞—Ä–æ–ª–∏', '–±–∞–Ω–∫–æ–≤—Å–∫–∏–µ –∫–∞—Ä—Ç—ã', '—ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –ø–æ—á—Ç–∞']
        topic_synonyms = get_topic_synonyms(corrected_topic)
        
        if corrected_topic not in allowed_topics and not topic_synonyms:
            return jsonify({
                'status': 'error',
                'error': f'–¢–µ–º–∞ "{corrected_topic}" –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–µ–º—ã: –∫–æ–º–ø—å—é—Ç–µ—Ä, –∏–Ω—Ç–µ—Ä–Ω–µ—Ç, –ø–∞—Ä–æ–ª–∏, –±–∞–Ω–∫–æ–≤—Å–∫–∏–µ –∫–∞—Ä—Ç—ã, —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –ø–æ—á—Ç–∞'
            })




        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã –ø–æ –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ô —Ç–µ–º–µ
        relevant_sections = get_relevant_sections(corrected_topic)
        logger.info(f"üìö –ù–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤: {len(relevant_sections)}")
        
        if not relevant_sections:
            return jsonify({
                'status': 'error',
                'error': f'–í —É—á–µ–±–Ω–∏–∫–∞—Ö –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —Ç–µ–º–µ "{corrected_topic}". –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é —Ç–µ–º—É –∏–∑ —Å–ø–∏—Å–∫–∞.'
            })

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç –ø–æ –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ô —Ç–µ–º–µ
        test_data = generate_contextual_test(corrected_topic, relevant_sections)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –≤ –æ—Ç–≤–µ—Ç
        if was_corrected:
            test_data['correction_info'] = {
                'was_corrected': True,
                'original_topic': original_topic,
                'corrected_topic': corrected_topic
            }
        
        logger.info(f"‚úÖ –¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω: {len(test_data['questions'])} –≤–æ–ø—Ä–æ—Å–æ–≤")
        
        return jsonify({
            'status': 'success',
            'test_data': test_data
        })

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ—Å—Ç–∞: {e}")
        return jsonify({
            'status': 'error',
            'error': '–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ç–µ—Å—Ç–∞'
        }), 500
    
def generate_contextual_test(topic, relevant_sections):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º"""
    # –°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–µ–º —Ç–µ–æ—Ä–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    theory = generate_contextual_theory(topic, relevant_sections)
    
    # –ó–∞—Ç–µ–º –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤–æ–ø—Ä–æ—Å—ã —Å –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    questions = generate_contextual_questions(topic, relevant_sections, theory)
    
    return {
        'topic': topic,
        'theory': theory,
        'questions': questions
    }

def format_beautiful_text(text, topic):
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ –∫—Ä–∞—Å–∏–≤—ã–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–∏–¥ —Å –∞–±–∑–∞—Ü–∞–º–∏"""
    try:
        prompt = f"""
–ü–†–ï–û–ë–†–ê–ó–£–ô –¢–ï–ö–°–¢ –í –ö–†–ê–°–ò–í–´–ô –°–¢–†–£–ö–¢–£–†–ò–†–û–í–ê–ù–ù–´–ô –§–û–†–ú–ê–¢ –° –ß–ï–¢–ö–ò–ú–ò –ê–ë–ó–ê–¶–ê–ú–ò:

–ò–°–•–û–î–ù–´–ô –¢–ï–ö–°–¢:
{text}

–¢–ï–ú–ê: {topic}

–ó–ê–î–ê–ß–ê:
–ü—Ä–µ–æ–±—Ä–∞–∑—É–π —Ç–µ–∫—Å—Ç –≤ —Ö–æ—Ä–æ—à–æ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, –ª–µ–≥–∫–æ —á–∏—Ç–∞–µ–º—ã–π –≤–∏–¥ —Å:
- –ß–ï–¢–ö–ò–ú–ò –ê–ë–ó–ê–¶–ê–ú–ò (–∫–∞–∂–¥—ã–π –Ω–æ–≤—ã–π —Å–º—ã—Å–ª–æ–≤–æ–π –±–ª–æ–∫ - –Ω–æ–≤—ã–π –∞–±–∑–∞—Ü)
- –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ —Ä–∞–∑—Ä—ã–≤–∞–º–∏ –º–µ–∂–¥—É –∏–¥–µ—è–º–∏
- –ú–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Å–ø–∏—Å–∫–∞–º–∏ –≥–¥–µ —É–º–µ—Å—Ç–Ω–æ
- –í—ã–¥–µ–ª–µ–Ω–∏–µ–º –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤
- –ü–æ–Ω—è—Ç–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π —Å –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
- –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ–º –¥–ª–∏–Ω–Ω—ã—Ö —Å–ø–ª–æ—à–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤

–í–ê–ñ–ù–´–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø:
1. –ö–ê–ñ–î–ê–Ø –Ω–æ–≤–∞—è –∏–¥–µ—è –∏–ª–∏ —Ç–µ–º–∞ –¥–æ–ª–∂–Ω–∞ –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å –Ω–æ–≤–æ–≥–æ –∞–±–∑–∞—Ü–∞
2. –ú–µ–∂–¥—É –∞–±–∑–∞—Ü–∞–º–∏ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
3. –ò—Å–ø–æ–ª—å–∑—É–π –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å —ç–º–æ–¥–∑–∏ –¥–ª—è –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤
4. –†–∞–∑–±–∏–≤–∞–π –¥–ª–∏–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞ –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–µ
5. –î–µ–ª–∞–π —Ç–µ–∫—Å—Ç –≤–∏–∑—É–∞–ª—å–Ω–æ –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã–º –∏ –ª–µ–≥–∫–∏–º –¥–ª—è —á—Ç–µ–Ω–∏—è

–ü–†–ò–ú–ï–† –ü–†–ê–í–ò–õ–¨–ù–û–ì–û –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–Ø:
üåü **–û—Å–Ω–æ–≤–Ω–∞—è –∫–æ–Ω—Ü–µ–ø—Ü–∏—è**
–ú—ã—à—å ‚Äî —ç—Ç–æ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –º–∞–Ω–∏–ø—É–ª—è—Ç–æ—Ä, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π —á–µ–ª–æ–≤–µ–∫—É –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å —Å –∫–æ–º–ø—å—é—Ç–µ—Ä–æ–º —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å. –û–Ω–∞ —è–≤–ª—è–µ—Ç—Å—è –Ω–µ–∑–∞–º–µ–Ω–∏–º—ã–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–æ–º–ø—å—é—Ç–µ—Ä–æ–º –Ω–∞—Ä—è–¥—É —Å –∫–ª–∞–≤–∏–∞—Ç—É—Ä–æ–π.

üéØ **–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç**
–ú—ã—à—å –æ—Å–Ω–∞—â–µ–Ω–∞ –¥–≤—É–º—è –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –∫–Ω–æ–ø–∫–∞–º–∏:

- **–õ–µ–≤–∞—è –∫–Ω–æ–ø–∫–∞** ‚Äî –æ—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
- **–ü—Ä–∞–≤–∞—è –∫–Ω–æ–ø–∫–∞** ‚Äî –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –º–µ–Ω—é
- **–ö–æ–ª—ë—Å–∏–∫–æ** ‚Äî –¥–ª—è –ø—Ä–æ–∫—Ä—É—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü

üí° **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ**
–î–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ñ–∞–π–ª–∞–º–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥–≤–æ–π–Ω–æ–π –∫–ª–∏–∫ –ª–µ–≤–æ–π –∫–Ω–æ–ø–∫–æ–π –º—ã—à–∏...

–í–ï–†–ù–ò –¢–û–õ–¨–ö–û –û–¢–§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ù–´–ô –¢–ï–ö–°–¢ –ë–ï–ó –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–• –ö–û–ú–ú–ï–ù–¢–ê–†–ò–ï–í.
"""

        response = gigachat_service.client.chat(prompt)
        formatted_text = response.choices[0].message.content.strip()
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ —É–ª—É—á—à–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        formatted_text = ensure_proper_paragraphs(formatted_text)
        
        return formatted_text
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞: {e}")
        return format_text_with_paragraphs(text)

def ensure_proper_paragraphs(text):
    """–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –∞–±–∑–∞—Ü—ã"""
    # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —Å—Ç—Ä–æ–∫–∏
    lines = text.split('\n')
    formatted_lines = []
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —ç–º–æ–¥–∑–∏ –∏–ª–∏ **, —ç—Ç–æ likely –∑–∞–≥–æ–ª–æ–≤–æ–∫ - –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
        if re.match(r'^[üéØüí°üìö‚ö†Ô∏è‚úÖüåüüìñüõ†Ô∏è]|^\*\*', line):
            if formatted_lines and formatted_lines[-1] != '':
                formatted_lines.append('')  # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –ø–µ—Ä–µ–¥ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
            formatted_lines.append(line)
            formatted_lines.append('')  # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –ø–æ—Å–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞
        # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å -, —ç—Ç–æ —ç–ª–µ–º–µ–Ω—Ç —Å–ø–∏—Å–∫–∞
        elif line.startswith('-'):
            formatted_lines.append(line)
        # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –¥–ª–∏–Ω–Ω–∞—è, —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        elif len(line) > 120:
            sentences = re.split(r'[.!?]+', line)
            sentences = [s.strip() for s in sentences if s.strip()]
            for sentence in sentences:
                if sentence:
                    formatted_lines.append(sentence + '.')
            formatted_lines.append('')
        else:
            formatted_lines.append(line)
            formatted_lines.append('')  # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –º–µ–∂–¥—É –∞–±–∑–∞—Ü–∞–º–∏
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ, —É–±–∏—Ä–∞—è –ª–∏—à–Ω–∏–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
    result = []
    prev_empty = False
    for line in formatted_lines:
        if line == '':
            if not prev_empty:
                result.append(line)
                prev_empty = True
        else:
            result.append(line)
            prev_empty = False
    
    return '\n'.join(result)

def format_text_with_paragraphs(text):
    """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∞–±–∑–∞—Ü–∞–º–∏"""
    # –£–¥–∞–ª—è–µ–º —Å–Ω–æ—Å–∫–∏ —Ç–∏–ø–∞ [^1], [^2], [^3]
    text = re.sub(r'\[\^\d+\]', '', text)
    
    # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    sentences = re.split(r'[.!?]+', text)
    sentences = [s.strip() for s in sentences if s.strip() and len(s.strip()) > 10]
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ –∞–±–∑–∞—Ü—ã –ø–æ 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    paragraphs = []
    current_paragraph = []
    
    for i, sentence in enumerate(sentences):
        current_paragraph.append(sentence)
        
        # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π –∞–±–∑–∞—Ü –∫–∞–∂–¥—ã–µ 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–ª–∏ –ø—Ä–∏ —Å–º–µ–Ω–µ —Ç–µ–º—ã
        if (len(current_paragraph) >= 2 or 
            (i < len(sentences)-1 and is_topic_change(sentence, sentences[i+1]))):
            paragraph_text = '. '.join(current_paragraph) + '.'
            paragraphs.append(paragraph_text)
            current_paragraph = []
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –∞–±–∑–∞—Ü
    if current_paragraph:
        paragraph_text = '. '.join(current_paragraph) + '.'
        paragraphs.append(paragraph_text)
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å –ø—É—Å—Ç—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏ –º–µ–∂–¥—É –∞–±–∑–∞—Ü–∞–º–∏
    return '\n\n'.join(paragraphs)

def is_topic_change(sentence1, sentence2):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–ª–µ–¥—É—é—â–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å–º–µ–Ω–æ–π —Ç–µ–º—ã"""
    topic_indicators = [
        '—Ç–∞–∫–∂–µ', '–∫—Ä–æ–º–µ —Ç–æ–≥–æ', '–±–æ–ª–µ–µ —Ç–æ–≥–æ', '–æ–¥–Ω–∞–∫–æ', '—Ç–µ–º –Ω–µ –º–µ–Ω–µ–µ',
        '—Å –¥—Ä—É–≥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã', '–Ω–∞–ø—Ä–∏–º–µ—Ä', '—Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º', '–ø–æ—ç—Ç–æ–º—É'
    ]
    
    sentence2_lower = sentence2.lower()
    return any(indicator in sentence2_lower for indicator in topic_indicators)

def format_text_manually(text):
    """–†—É—á–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∫–∞–∫ —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç"""
    # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    sentences = re.split(r'[.!?]+', text)
    sentences = [s.strip() for s in sentences if s.strip()]
    
    # –°–æ–∑–¥–∞–µ–º –∞–±–∑–∞—Ü—ã –ø–æ 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    paragraphs = []
    current_paragraph = []
    
    for i, sentence in enumerate(sentences):
        current_paragraph.append(sentence)
        
        # –ö–∞–∂–¥—ã–µ 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–ª–∏ –ø—Ä–∏ –¥–ª–∏–Ω–µ > 200 —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π –∞–±–∑–∞—Ü
        if len(current_paragraph) >= 2 or len(' '.join(current_paragraph)) > 200:
            paragraph_text = ' '.join(current_paragraph) + '.'
            paragraphs.append(paragraph_text)
            current_paragraph = []
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞—Ç–æ–∫
    if current_paragraph:
        paragraph_text = ' '.join(current_paragraph) + '.'
        paragraphs.append(paragraph_text)
    
    return '\n\n'.join(paragraphs)

def generate_contextual_questions(topic, relevant_sections, theory):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∞ - –°–ù–ê–ß–ê–õ–ê –£–ß–ï–ë–ù–ò–ö–ò, –ü–û–¢–û–ú –ò–ù–¢–ï–†–ù–ï–¢"""
    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –º–æ–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–Ω–µ—à–Ω–∏–µ –∑–Ω–∞–Ω–∏—è
        use_external = should_use_external_knowledge(topic, relevant_sections)
        
        if use_external:
            source_instruction = "–ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —É—á–µ–±–Ω–∏–∫–æ–≤ –∏, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ, –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞–Ω–∏—è."
        else:
            source_instruction = "–ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —É—á–µ–±–Ω–∏–∫–æ–≤. –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞–Ω–∏—è."
        
        prompt = f"""
–°–û–ó–î–ê–ô –†–û–í–ù–û 5 –ö–ê–ß–ï–°–¢–í–ï–ù–ù–´–• –í–û–ü–†–û–°–û–í –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –ü–û–ù–ò–ú–ê–ù–ò–Ø –¢–ï–ú–´: "{topic}"

–ò–°–¢–û–ß–ù–ò–ö–ò –ò–ù–§–û–†–ú–ê–¶–ò–ò:

1. –£–ß–ï–ë–ù–ò–ö–ò –ü–û –¶–ò–§–†–û–í–û–ô –ì–†–ê–ú–û–¢–ù–û–°–¢–ò:
{format_sections_for_analysis(relevant_sections) if relevant_sections else "–í —É—á–µ–±–Ω–∏–∫–∞—Ö –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–π —Ç–µ–º–µ."}

2. –¢–ï–û–†–ï–¢–ò–ß–ï–°–ö–ê–Ø –°–ü–†–ê–í–ö–ê (–Ω–∞ –æ—Å–Ω–æ–≤–µ —É—á–µ–±–Ω–∏–∫–æ–≤):
{theory}



–í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê –ì–ï–ù–ï–†–ê–¶–ò–ò –í–û–ü–†–û–°–û–í:
1. {source_instruction}
2. –í–û–ó–í–†–ê–©–ê–ô –¢–û–õ–¨–ö–û –í–ê–õ–ò–î–ù–´–ô JSON –ë–ï–ó –õ–Æ–ë–´–• –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–• –¢–ï–ö–°–¢–û–í
3. correct_answer –î–û–õ–ñ–ï–ù –ë–´–¢–¨ –ß–ò–°–õ–û–ú –æ—Ç 0 –¥–æ 3
4. options –î–û–õ–ñ–ï–ù –°–û–î–ï–†–ñ–ê–¢–¨ –†–û–í–ù–û 4 –í–ê–†–ò–ê–ù–¢–ê
5. –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ —É—á–µ–±–Ω–∏–∫–∞—Ö
6. –î–û–õ–ñ–ù–û –ë–´–¢–¨ –†–û–í–ù–û 5 –í–û–ü–†–û–°–û–í

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (–¢–û–õ–¨–ö–û JSON):
{{
    "questions": [
        {{
            "question": "–¢–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞...",
            "options": ["–í–∞—Ä–∏–∞–Ω—Ç 1", "–í–∞—Ä–∏–∞–Ω—Ç 2", "–í–∞—Ä–∏–∞–Ω—Ç 3", "–í–∞—Ä–∏–∞–Ω—Ç 4"],
            "correct_answer": 0,
            "explanation": "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É—á–µ–±–Ω–∏–∫–æ–≤..."
    
            }}
    ]
}}

–ù–ï –î–û–ë–ê–í–õ–Ø–ô –ö–û–ú–ú–ï–ù–¢–ê–†–ò–ò, –û–ë–™–Ø–°–ù–ï–ù–ò–Ø –ò–õ–ò –î–†–£–ì–û–ô –¢–ï–ö–°–¢ –í–ù–ï JSON –°–¢–†–£–ö–¢–£–†–´!
"""

        response = gigachat_service.client.chat(prompt)
        content = response.choices[0].message.content

        content = re.sub(r'^```json\s*', '', content)
        content = re.sub(r'\s*```$', '', content)
        
        questions = parse_questions_json(content)
        
        # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ –º–µ–Ω—å—à–µ 5 –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ —Ä–∞–∑—Ä–µ—à–µ–Ω—ã –≤–Ω–µ—à–Ω–∏–µ –∑–Ω–∞–Ω–∏—è, –ø—Ä–æ–±—É–µ–º –µ—â–µ —Ä–∞–∑
        if len(questions) < 5 and use_external:
            logger.warning(f"‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω–æ —Ç–æ–ª—å–∫–æ {len(questions)} –≤–æ–ø—Ä–æ—Å–æ–≤, –ø–æ–≤—Ç–æ—Ä—è–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Å –≤–Ω–µ—à–Ω–∏–º–∏ –∑–Ω–∞–Ω–∏—è–º–∏")
            return generate_contextual_questions(topic, relevant_sections, theory)
        
        return questions[:5]
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤: {e}")

        return generate_contextual_questions(topic, relevant_sections, theory)


def should_use_external_knowledge_for_test(topic, relevant_sections):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–Ω–µ—à–Ω–∏–µ –∑–Ω–∞–Ω–∏—è –¥–ª—è —Ç–µ—Å—Ç–æ–≤"""
    if not relevant_sections:
        return True
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ —É—á–µ–±–Ω–∏–∫–µ –¥–ª—è 5 —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
    total_content = " ".join([section['content'] for section in relevant_sections])
    
    # –ï—Å–ª–∏ –≤ —É—á–µ–±–Ω–∏–∫–µ –º–∞–ª–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–ª–∏ –æ–Ω–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∞—è
    modern_keywords = [
        '—Å–º–∞—Ä—Ç—Ñ–æ–Ω', '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ', '–æ–±–ª–∞–∫–æ', '—Å—Ç—Ä–∏–º–∏–Ω–≥', '–ø–æ–¥–∫–∞—Å—Ç',
        '–±–∏–æ–º–µ—Ç—Ä–∏—è', '–±–ª–æ–∫—á–µ–π–Ω', '–∫—Ä–∏–ø—Ç–æ', '–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç', 'iot',
        '–∫–∏–±–µ—Ä–±—É–ª–ª–∏–Ω–≥', '–¥–∏–ø—Ñ–µ–π–∫', 'vpn', '–¥–≤—É—Ö—Ñ–∞–∫—Ç–æ—Ä–Ω–∞—è', '–±–∏–æ–º–µ—Ç—Ä–∏—è'
    ]
    
    topic_lower = topic.lower()
    has_modern_aspect = any(keyword in topic_lower for keyword in modern_keywords)
    
    if has_modern_aspect or len(total_content) < 500:
        return True
    
    return False

def enhance_questions_with_knowledge(questions, topic, relevant_sections):
    """–£–ª—É—á—à–∞–µ—Ç –≤–æ–ø—Ä–æ—Å—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∑–Ω–∞–Ω–∏—è–º–∏"""
    enhanced_questions = []
    
    for i, question in enumerate(questions):
        try:
            # –£–ª—É—á—à–∞–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –¥–ª—è –±–æ–ª–µ–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏ –ø–æ–ª–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
            enhanced_explanation = enhance_explanation_with_context(
                question['explanation'], 
                topic, 
                relevant_sections,
                question['question'],
                question['correct_answer']
            )
            
            question['explanation'] = enhanced_explanation
            enhanced_questions.append(question)
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–ª—É—á—à–∏—Ç—å –≤–æ–ø—Ä–æ—Å {i}: {e}")
            enhanced_questions.append(question)  # –û—Å—Ç–∞–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å
    
    return enhanced_questions

def enhance_explanation_with_context(explanation, topic, relevant_sections, question, correct_answer):
    """–î–æ–ø–æ–ª–Ω—è–µ—Ç –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏–∑ —É—á–µ–±–Ω–∏–∫–∞ –∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    
    enhancement_prompt = f"""
–£–õ–£–ß–®–ò –û–ë–™–Ø–°–ù–ï–ù–ò–ï –î–õ–Ø –í–û–ü–†–û–°–ê –¢–ï–°–¢–ê, –î–û–ë–ê–í–ò–í –ö–û–ù–¢–ï–ö–°–¢ –ò–ó –£–ß–ï–ë–ù–ò–ö–ê –ò –°–û–í–†–ï–ú–ï–ù–ù–´–• –ò–°–¢–û–ß–ù–ò–ö–û–í:

–¢–ï–ú–ê –¢–ï–°–¢–ê: {topic}
–í–û–ü–†–û–°: {question}
–ü–†–ê–í–ò–õ–¨–ù–´–ô –û–¢–í–ï–¢: {correct_answer}

–¢–ï–ö–£–©–ï–ï –û–ë–™–Ø–°–ù–ï–ù–ò–ï:
{explanation}

–ò–ù–§–û–†–ú–ê–¶–ò–Ø –ò–ó –£–ß–ï–ë–ù–ò–ö–ê:
{format_sections_for_analysis(relevant_sections) if relevant_sections else "–í —É—á–µ–±–Ω–∏–∫–µ –Ω–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É."}

–ó–ê–î–ê–ß–ê:
1. –ï—Å–ª–∏ –≤ —É—á–µ–±–Ω–∏–∫–µ –µ—Å—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è - –≤–∫–ª—é—á–∏ –µ—ë –≤ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
2. –î–æ–±–∞–≤—å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –ø—Ä–∞–∫—Ç–∏–∫–∏
3. –£–∫–∞–∂–∏, –µ—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ —É—á–µ–±–Ω–∏–∫–µ –∏–ª–∏ –Ω–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞—Ö
4. –°–æ—Ö—Ä–∞–Ω–∏ –ø–æ–ª–µ–∑–Ω—ã–µ —Å–æ–≤–µ—Ç—ã –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
5. –°–¥–µ–ª–∞–π –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –±–æ–ª–µ–µ –ø–æ–ª–Ω—ã–º –∏ –ø–æ–ª–µ–∑–Ω—ã–º –¥–ª—è –æ–±—É—á–µ–Ω–∏—è

–§–û–†–ú–ê–¢ –£–õ–£–ß–®–ï–ù–ù–û–ì–û –û–ë–™–Ø–°–ù–ï–ù–ò–Ø:
- –ù–∞—á–∏–Ω–∞–π —Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ –æ—Ç–≤–µ—Ç–∞
- –û–±—ä—è—Å–Ω–∏ –ø–æ—á–µ–º—É –æ—Ç–≤–µ—Ç –≤–µ—Ä–Ω—ã–π —Å —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
- –ü—Ä–∏–≤–µ–¥–∏ –ø—Ä–∏–º–µ—Ä –∏–∑ —Ä–µ–∞–ª—å–Ω–æ–π –∂–∏–∑–Ω–∏
- –î–∞–π –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–ª–µ–∑–Ω—ã–π —Å–æ–≤–µ—Ç
- –£–∫–∞–∂–∏ —Å–≤—è–∑—å —Å —Ç–µ–æ—Ä–∏–µ–π –∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –ø—Ä–∞–∫—Ç–∏–∫–∞–º–∏

–í–ï–†–ù–ò –¢–û–õ–¨–ö–û –£–õ–£–ß–®–ï–ù–ù–û–ï –û–ë–™–Ø–°–ù–ï–ù–ò–ï –ë–ï–ó –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–• –ö–û–ú–ú–ï–ù–¢–ê–†–ò–ï–í.
"""
    
    try:
        response = gigachat_service.client.chat(enhancement_prompt)
        enhanced = response.choices[0].message.content.strip()
        return enhanced
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É–ª—É—á—à–µ–Ω–∏—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è: {e}")
        return explanation  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ



def get_topic_synonyms(topic):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –¥–ª—è 5 –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–µ–º"""
    synonyms_map = {
        '–∫–æ–º–ø—å—é—Ç–µ—Ä': [
            '–∫–æ–º–ø—å—é—Ç–µ—Ä', '–ø–∫', '–Ω–æ—É—Ç–±—É–∫', '—Å–∏—Å—Ç–µ–º–Ω—ã–π –±–ª–æ–∫', '–º–æ–Ω–∏—Ç–æ—Ä', 
            '–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä', '–æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–∞–º—è—Ç—å', '–∂–µ—Å—Ç–∫–∏–π –¥–∏—Å–∫', '–∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞', '–º—ã—à—å',
            'windows', '–æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞', '—Ä–∞–±–æ—á–∏–π —Å—Ç–æ–ª', '—Ñ–∞–π–ª—ã', '–ø–∞–ø–∫–∏'
        ],
        '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç': [
            '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç', '—Å–µ—Ç—å', 'online', '–±—Ä–∞—É–∑–µ—Ä', '–≤–µ–±', '—Å–∞–π—Ç', '–ø—Ä–æ–≤–æ–¥–Ω–∏–∫',
            '–±—Ä–∞—É–∑–µ—Ä', 'google', '–ø–æ–∏—Å–∫', '–æ–Ω–ª–∞–π–Ω', '—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ', 'wi-fi',
            '—Ä–æ—É—Ç–µ—Ä', '–º–æ–¥–µ–º', 'web', 'url', '–∞–¥—Ä–µ—Å', '—Å—Ç—Ä–∞–Ω–∏—Ü–∞'
        ],
        '–ø–∞—Ä–æ–ª–∏': [
            '–ø–∞—Ä–æ–ª—å', '–ø–∞—Ä–æ–ª–∏', '–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å', '–∑–∞—â–∏—Ç–∞', '–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è',
            '—É—á–µ—Ç–Ω–∞—è –∑–∞–ø–∏—Å—å', '–ª–æ–≥–∏–Ω', '–¥–æ—Å—Ç—É–ø', '–∫–æ–¥', 'pin',
            '–Ω–∞–¥–µ–∂–Ω—ã–π –ø–∞—Ä–æ–ª—å', '—Å–ª–æ–∂–Ω–æ—Å—Ç—å –ø–∞—Ä–æ–ª—è', '—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–∞—Ä–æ–ª–µ–π'
        ],
        '–±–∞–Ω–∫–æ–≤—Å–∫–∏–µ –∫–∞—Ä—Ç—ã': [
            '–±–∞–Ω–∫–æ–≤—Å–∫–∞—è –∫–∞—Ä—Ç–∞', '–∫–∞—Ä—Ç–∞', '–∫—Ä–µ–¥–∏—Ç–Ω–∞—è –∫–∞—Ä—Ç–∞', '–¥–µ–±–µ—Ç–æ–≤–∞—è –∫–∞—Ä—Ç–∞',
            '–ø–ª–∞—Ç–µ–∂–Ω–∞—è –∫–∞—Ä—Ç–∞', '–±–∞–Ω–∫–æ–º–∞—Ç', '–æ–ø–ª–∞—Ç–∞ –∫–∞—Ä—Ç–æ–π', 'cvv', '—Åvv',
            'pin-–∫–æ–¥', '–ø–ª–∞—Ç–µ–∂–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞', 'visa', 'mastercard', '–º–∏—Ä'
        ],
        '—ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –ø–æ—á—Ç–∞': [
            '—ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –ø–æ—á—Ç–∞', 'email', 'e-mail', '–ø–æ—á—Ç–∞', '–ø–∏—Å—å–º–æ',
            '–ø–æ—á—Ç–æ–≤—ã–π —è—â–∏–∫', '–∞–¥—Ä–µ—Å –ø–æ—á—Ç—ã', '–æ—Ç–ø—Ä–∞–≤–∫–∞ –ø–∏—Å–µ–º', '–≤–ª–æ–∂–µ–Ω–∏–µ',
            'spam', '—Å–ø–∞–º', '—Ä–∞—Å—Å—ã–ª–∫–∞', '–ø–µ—Ä–µ–ø–∏—Å–∫–∞'
        ]
    }
    
    topic_lower = topic.lower()
    return synonyms_map.get(topic_lower, [])

def generate_contextual_theory_for_test(topic, relevant_sections):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–π —Å–ø—Ä–∞–≤–∫–∏ –¥–ª—è —Ç–µ—Å—Ç–æ–≤ - —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ —Ç–µ—Å—Ç–∏—Ä—É–µ–º—ã–µ –∞—Å–ø–µ–∫—Ç—ã"""
    prompt = f"""
–°–û–ó–î–ê–ô –¢–ï–û–†–ï–¢–ò–ß–ï–°–ö–£–Æ –°–ü–†–ê–í–ö–£ –î–õ–Ø –¢–ï–°–¢–ê –ü–û –¢–ï–ú–ï: "{topic}" 
–° –ê–ö–¶–ï–ù–¢–û–ú –ù–ê –ö–õ–Æ–ß–ï–í–´–ï –ê–°–ü–ï–ö–¢–´, –ö–û–¢–û–†–´–ï –ë–£–î–£–¢ –ü–†–û–í–ï–†–Ø–¢–¨–°–Ø –í –í–û–ü–†–û–°–ê–•

–ò–ù–§–û–†–ú–ê–¶–ò–Ø –ò–ó –£–ß–ï–ë–ù–ò–ö–ê:
{format_sections_for_analysis(relevant_sections) if relevant_sections else "–í —É—á–µ–±–Ω–∏–∫–µ –Ω–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–π —Ç–µ–º–µ."}

–î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ò–°–¢–û–ß–ù–ò–ö–ò:
–ò—Å–ø–æ–ª—å–∑—É–π —Å–≤–æ–∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è, —á—Ç–æ–±—ã —Å–¥–µ–ª–∞—Ç—å —Å–ø—Ä–∞–≤–∫—É –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –∏ –ø–æ–ª–µ–∑–Ω–æ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.

–°–¢–†–£–ö–¢–£–†–ê –î–õ–Ø –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:
üéØ **–û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è** (—á—Ç–æ –±—É–¥–µ—Ç –ø—Ä–æ–≤–µ—Ä—è—Ç—å—Å—è –≤ –±–∞–∑–æ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–∞—Ö)
- –ö–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
- –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã —Ä–∞–±–æ—Ç—ã

üõ†Ô∏è **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ** (—á—Ç–æ –±—É–¥–µ—Ç –ø—Ä–æ–≤–µ—Ä—è—Ç—å—Å—è –≤ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –≤–æ–ø—Ä–æ—Å–∞—Ö)  
- –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ
- –¢–∏–ø–∏—á–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è
- –ü–æ—à–∞–≥–æ–≤—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏

üöÄ **–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã** (—á—Ç–æ –±—É–¥–µ—Ç –ø—Ä–æ–≤–µ—Ä—è—Ç—å—Å—è –≤ –≤–æ–ø—Ä–æ—Å–∞—Ö –Ω–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏)
- –ù–æ–≤—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏ —Å–µ—Ä–≤–∏—Å—ã
- –ê–∫—Ç—É–∞–ª—å–Ω—ã–µ —É–≥—Ä–æ–∑—ã –∏ –∑–∞—â–∏—Ç—ã
- –ü–æ—Å–ª–µ–¥–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏ —Ç—Ä–µ–Ω–¥—ã

‚ö†Ô∏è **–í–∞–∂–Ω—ã–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è** (—á—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –≤–æ–ø—Ä–æ—Å–∞—Ö –Ω–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å)
- –†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏
- –ú–µ—Ä—ã –ø—Ä–µ–¥–æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç–∏
- –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø—Ä–æ–±–ª–µ–º

–¢–†–ï–ë–û–í–ê–ù–ò–Ø:
1. –°–¥–µ–ª–∞–π –∞–∫—Ü–µ–Ω—Ç –Ω–∞ –∞—Å–ø–µ–∫—Ç–∞—Ö, –∫–æ—Ç–æ—Ä—ã–µ –≤–∞–∂–Ω—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∑–Ω–∞–Ω–∏–π
2. –í–∫–ª—é—á–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–º–æ–∂–µ—Ç –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã
3. –°–æ—á–µ—Ç–∞–π –±–∞–∑–æ–≤—ã–µ –∑–Ω–∞–Ω–∏—è –∏–∑ —É—á–µ–±–Ω–∏–∫–∞ —Å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –ø—Ä–∞–∫—Ç–∏–∫–∞–º–∏
4. –í—ã–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã –∑–∞–ø–æ–º–Ω–∏—Ç—å—Å—è

–û–¢–í–ï–ß–ê–ô –¢–û–õ–¨–ö–û –¢–ï–ö–°–¢–û–ú –¢–ï–û–†–ï–¢–ò–ß–ï–°–ö–û–ô –°–ü–†–ê–í–ö–ò.
"""

    try:
        response = gigachat_service.client.chat(prompt)
        theory = response.choices[0].message.content.strip()
        theory = ensure_proper_paragraphs(theory)
        
        if not has_proper_paragraphs(theory):
            theory = format_beautiful_text(theory, topic)
            
        return theory
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–æ—Ä–∏–∏ –¥–ª—è —Ç–µ—Å—Ç–∞: {e}")
        return generate_contextual_theory(topic, relevant_sections)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—É—é –≤–µ—Ä—Å–∏—é



def generate_test_step_by_step(topic, relevant_sections):
    """–ü–æ—ç—Ç–∞–ø–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–∞ - –¢–û–õ–¨–ö–û –ù–ï–ô–†–û–°–ï–¢–¨–Æ"""
    logger.info(f"üîÑ –ü–æ—ç—Ç–∞–ø–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–∞ –ø–æ —Ç–µ–º–µ: {topic}")
    
    try:
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ–æ—Ä–∏—é
        theory = generate_contextual_theory(topic, relevant_sections)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤–æ–ø—Ä–æ—Å—ã –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é
        questions = generate_contextual_questions(topic, relevant_sections, theory)
        
        return {
            'topic': topic,
            'theory': theory,
            'questions': questions
        }
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ—ç—Ç–∞–ø–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        # –ü–æ–≤—Ç–æ—Ä—è–µ–º –ø–æ–ø—ã—Ç–∫—É
        return generate_test_step_by_step(topic, relevant_sections)

def generate_contextual_theory(topic, relevant_sections):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–π —Å–ø—Ä–∞–≤–∫–∏ - –°–ù–ê–ß–ê–õ–ê –£–ß–ï–ë–ù–ò–ö–ò, –ü–û–¢–û–ú –ò–ù–¢–ï–†–ù–ï–¢"""
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –º–æ–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–Ω–µ—à–Ω–∏–µ –∑–Ω–∞–Ω–∏—è
    use_external = should_use_external_knowledge(topic, relevant_sections)
    
    if use_external:
        prompt = f"""
–°–û–ó–î–ê–ô –ö–†–ê–°–ò–í–û–ï, –°–¢–†–£–ö–¢–£–†–ò–†–û–í–ê–ù–ù–û–ï –û–ë–™–Ø–°–ù–ï–ù–ò–ï –ü–û –¢–ï–ú–ï: "{topic}" –° –ß–ï–¢–ö–ò–ú–ò –ê–ë–ó–ê–¶–ê–ú–ò

–ò–ù–§–û–†–ú–ê–¶–ò–Ø –ò–ó –£–ß–ï–ë–ù–ò–ö–û–í –ü–û –¶–ò–§–†–û–í–û–ô –ì–†–ê–ú–û–¢–ù–û–°–¢–ò:
{format_sections_for_analysis(relevant_sections) if relevant_sections else "–í —É—á–µ–±–Ω–∏–∫–∞—Ö –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–π —Ç–µ–º–µ."}

–í–ê–ñ–ù–û: –í —É—á–µ–±–Ω–∏–∫–∞—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–π —Ç–µ–º–µ, –ø–æ—ç—Ç–æ–º—É –ú–û–ñ–ù–û –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–≤–æ–∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è.

–û–ß–ï–ù–¨ –í–ê–ñ–ù–´–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø:
1. ‚úÖ –°–ù–ê–ß–ê–õ–ê –ø—Ä–æ–≤–µ—Ä—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —É—á–µ–±–Ω–∏–∫–∞—Ö –≤—ã—à–µ
2. ‚úÖ –ï–°–õ–ò –≤ —É—á–µ–±–Ω–∏–∫–∞—Ö –µ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è - –∏—Å–ø–æ–ª—å–∑—É–π –µ—ë –∫–∞–∫ –æ—Å–Ω–æ–≤—É
3. ‚úÖ –ï–°–õ–ò –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ - –¥–æ–ø–æ–ª–Ω–∏ —Å–≤–æ–∏–º–∏ –∑–Ω–∞–Ω–∏—è–º–∏
4. ‚úÖ –ï–°–õ–ò –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç - –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–æ–ª–∞–≥–∞–π—Å—è –Ω–∞ —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è
5. ‚úÖ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —Ä–∞–∑–±–∏–≤–∞–π —Ç–µ–∫—Å—Ç –Ω–∞ –ê–ë–ó–ê–¶–´

–°–¢–†–£–ö–¢–£–†–ê –û–ë–™–Ø–°–ù–ï–ù–ò–Ø:
üåü **–û—Å–Ω–æ–≤–Ω–∞—è –∫–æ–Ω—Ü–µ–ø—Ü–∏—è** (1-2 –∞–±–∑–∞—Ü–∞)

üéØ **–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç** (2-3 –∞–±–∑–∞—Ü–∞ —Å –ø–æ–¥–ø—É–Ω–∫—Ç–∞–º–∏)

üõ†Ô∏è **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ** (2-3 –∞–±–∑–∞—Ü–∞ —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏)

üí° **–ü–æ–ª–µ–∑–Ω—ã–µ —Å–æ–≤–µ—Ç—ã** (1-2 –∞–±–∑–∞—Ü–∞ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏)

‚ö†Ô∏è **–í–∞–∂–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã** (1-2 –∞–±–∑–∞—Ü–∞ —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏)

–û–¢–í–ï–ß–ê–ô –¢–û–õ–¨–ö–û –û–¢–§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ù–´–ú –¢–ï–ö–°–¢–û–ú, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.
"""
    else:
        prompt = f"""
–°–û–ó–î–ê–ô –ö–†–ê–°–ò–í–û–ï, –°–¢–†–£–ö–¢–£–†–ò–†–û–í–ê–ù–ù–û–ï –û–ë–™–Ø–°–ù–ï–ù–ò–ï –ü–û –¢–ï–ú–ï: "{topic}" –° –ß–ï–¢–ö–ò–ú–ò –ê–ë–ó–ê–¶–ê–ú–ò

–ò–°–ü–û–õ–¨–ó–£–ô –¢–û–õ–¨–ö–û –ò–ù–§–û–†–ú–ê–¶–ò–Æ –ò–ó –£–ß–ï–ë–ù–ò–ö–û–í:

–ò–ù–§–û–†–ú–ê–¶–ò–Ø –ò–ó –£–ß–ï–ë–ù–ò–ö–û–í –ü–û –¶–ò–§–†–û–í–û–ô –ì–†–ê–ú–û–¢–ù–û–°–¢–ò:
{format_sections_for_analysis(relevant_sections)}

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:
1. ‚ùó –ò–°–ü–û–õ–¨–ó–£–ô –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —É—á–µ–±–Ω–∏–∫–æ–≤
2. ‚ùó –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è –∏–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞
3. ‚ùó –ù–ï –ø—Ä–∏–¥—É–º—ã–≤–∞–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
4. ‚ùó –ï—Å–ª–∏ –≤ —É—á–µ–±–Ω–∏–∫–∞—Ö –Ω–µ—Ç –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ - –æ–±—ä—è—Å–Ω–∏ —Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ –µ—Å—Ç—å
5. ‚úÖ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —Ä–∞–∑–±–∏–≤–∞–π —Ç–µ–∫—Å—Ç –Ω–∞ –ê–ë–ó–ê–¶–´

–°–¢–†–£–ö–¢–£–†–ê –û–ë–™–Ø–°–ù–ï–ù–ò–Ø:
üåü **–û—Å–Ω–æ–≤–Ω–∞—è –∫–æ–Ω—Ü–µ–ø—Ü–∏—è** (1-2 –∞–±–∑–∞—Ü–∞)

üéØ **–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç** (2-3 –∞–±–∑–∞—Ü–∞ —Å –ø–æ–¥–ø—É–Ω–∫—Ç–∞–º–∏)

üõ†Ô∏è **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ** (2-3 –∞–±–∑–∞—Ü–∞ —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏)

üí° **–ü–æ–ª–µ–∑–Ω—ã–µ —Å–æ–≤–µ—Ç—ã** (1-2 –∞–±–∑–∞—Ü–∞ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏)

‚ö†Ô∏è **–í–∞–∂–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã** (1-2 –∞–±–∑–∞—Ü–∞ —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏)

–û–¢–í–ï–ß–ê–ô –¢–û–õ–¨–ö–û –û–¢–§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ù–´–ú –¢–ï–ö–°–¢–û–ú, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.
"""

    try:
        response = gigachat_service.client.chat(prompt)
        theory = response.choices[0].message.content.strip()
    
        theory = ensure_proper_paragraphs(theory)


        if not has_proper_paragraphs(theory):

            theory = format_beautiful_text(theory, topic)
            
        return theory
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–æ—Ä–∏–∏: {e}")

        return generate_fallback_explanation(topic)

def generate_fallback_explanation(topic):
    """–°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –ø—Ä–∏ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"""
    fallback_explanations = {
        "–∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å": """
üåü **–û—Å–Ω–æ–≤–Ω–∞—è –∫–æ–Ω—Ü–µ–ø—Ü–∏—è**

–ö–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å - —ç—Ç–æ –∑–∞—â–∏—Ç–∞ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã—Ö —Å–∏—Å—Ç–µ–º, —Å–µ—Ç–µ–π –∏ –¥–∞–Ω–Ω—ã—Ö –æ—Ç —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∞—Ç–∞–∫. –û–Ω–∞ –≤–∫–ª—é—á–∞–µ—Ç –º–µ—Ç–æ–¥—ã –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –Ω–µ—Å–∞–Ω–∫—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è, —Ä–∞—Å–∫—Ä—ã—Ç–∏—è –∏ —É–Ω–∏—á—Ç–æ–∂–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.

üéØ **–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç**

–°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π –ø–æ–¥—Ö–æ–¥:

- **–ó–∞—â–∏—Ç–∞ –ø–µ—Ä–∏–º–µ—Ç—Ä–∞** - –±—Ä–∞–Ω–¥–º–∞—É—ç—Ä—ã –∏ —Å–∏—Å—Ç–µ–º—ã –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –≤—Ç–æ—Ä–∂–µ–Ω–∏–π
- **–ó–∞—â–∏—Ç–∞ –∫–æ–Ω–µ—á–Ω—ã—Ö —Ç–æ—á–µ–∫** - –∞–Ω—Ç–∏–≤–∏—Ä—É—Å—ã –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π  
- **–®–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö** - –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –Ω–µ—á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
- **–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è** - –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–ª–∏–Ω–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π

üõ†Ô∏è **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ**

–î–ª—è –æ–±—ã—á–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤–∞–∂–Ω–æ:
- –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞–¥–µ–∂–Ω—ã–µ –ø–∞—Ä–æ–ª–∏
- –û—Å—Ç–µ—Ä–µ–≥–∞—Ç—å—Å—è —Ñ–∏—à–∏–Ω–≥–æ–≤—ã—Ö –ø–∏—Å–µ–º
- –†–µ–≥—É–ª—è—Ä–Ω–æ –¥–µ–ª–∞—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏ –¥–∞–Ω–Ω—ã—Ö

üí° **–ü–æ–ª–µ–∑–Ω—ã–µ —Å–æ–≤–µ—Ç—ã**

–í—Å–µ–≥–¥–∞ –æ–±–Ω–æ–≤–ª—è–π—Ç–µ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤–µ—Ä—Å–∏–∏. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥–≤—É—Ö—Ñ–∞–∫—Ç–æ—Ä–Ω—É—é –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—é –≤–µ–∑–¥–µ, –≥–¥–µ —ç—Ç–æ –≤–æ–∑–º–æ–∂–Ω–æ.

‚ö†Ô∏è **–í–∞–∂–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã**

–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –ø–æ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–º —Å—Å—ã–ª–∫–∞–º –≤ –ø–∏—Å—å–º–∞—Ö –∏ –Ω–µ —Å–∫–∞—á–∏–≤–∞–π—Ç–µ –≤–ª–æ–∂–µ–Ω–∏—è –æ—Ç –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª–µ–π.
""",
        "—Ü–∏—Ñ—Ä–æ–≤–∞—è –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç—å": """
üåü **–û—Å–Ω–æ–≤–Ω–∞—è –∫–æ–Ω—Ü–µ–ø—Ü–∏—è**

–¶–∏—Ñ—Ä–æ–≤–∞—è –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç—å - —ç—Ç–æ —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç—å –∑–Ω–∞–Ω–∏–π –∏ –Ω–∞–≤—ã–∫–æ–≤, –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ü–∏—Ñ—Ä–æ–≤—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –≤ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–æ–π –∂–∏–∑–Ω–∏.

üéØ **–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç**

–¶–∏—Ñ—Ä–æ–≤–∞—è –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç—å –≤–∫–ª—é—á–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π:

- **–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –Ω–∞–≤—ã–∫–∏** - —Ä–∞–±–æ—Ç–∞ —Å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º–∏ –∏ –ø—Ä–æ–≥—Ä–∞–º–º–∞–º–∏
- **–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–∞—è –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç—å** - –ø–æ–∏—Å–∫ –∏ –æ—Ü–µ–Ω–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
- **–ö–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –Ω–∞–≤—ã–∫–∏** - –æ–±—â–µ–Ω–∏–µ –≤ —Ü–∏—Ñ—Ä–æ–≤–æ–π —Å—Ä–µ–¥–µ
- **–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å** - –∑–∞—â–∏—Ç–∞ –ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

üõ†Ô∏è **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ**

–û—Å–≤–æ–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤–æ–π –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç–∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç:
- –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –∫–æ–º–ø—å—é—Ç–µ—Ä–æ–º –∏ —Å–º–∞—Ä—Ç—Ñ–æ–Ω–æ–º
- –ù–∞—Ö–æ–¥–∏—Ç—å –Ω—É–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–Ω–ª–∞–π–Ω-—Å–µ—Ä–≤–∏—Å—ã –∏ –≥–æ—Å—É—Å–ª—É–≥–∏
- –û–±—â–∞—Ç—å—Å—è —á–µ—Ä–µ–∑ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä—ã –∏ —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–µ—Ç–∏

üí° **–ü–æ–ª–µ–∑–Ω—ã–µ —Å–æ–≤–µ—Ç—ã**

–ù–∞—á–∏–Ω–∞–π—Ç–µ —Å –æ—Å–Ω–æ–≤: –Ω–∞—É—á–∏—Ç–µ—Å—å —É–≤–µ—Ä–µ–Ω–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å —Å —Ñ–∞–π–ª–∞–º–∏, –ø–∞–ø–∫–∞–º–∏ –∏ –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∞–º–∏. –ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –æ—Å–≤–∞–∏–≤–∞–π—Ç–µ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ –Ω–∞–≤—ã–∫–∏.

‚ö†Ô∏è **–í–∞–∂–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã**

–ù–µ –±–æ–π—Ç–µ—Å—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å, –Ω–æ –≤—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–π—Ç–µ –≤–∞–∂–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ. –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ —Å–æ–∑–¥–∞–Ω—ã –¥–ª—è –ª—é–¥–µ–π, –∏ –∫–∞–∂–¥—ã–π –º–æ–∂–µ—Ç –Ω–∞—É—á–∏—Ç—å—Å—è –∏—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å.
"""
    }
    
    # –ò—â–µ–º –ø–æ–¥—Ö–æ–¥—è—â–µ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
    topic_lower = topic.lower()
    for key, explanation in fallback_explanations.items():
        if key in topic_lower:
            return explanation
    
    # –û–±—â–µ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ, –µ—Å–ª–∏ —Ç–µ–º–∞ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞
    return f"""
üåü **–ò–∑—É—á–µ–Ω–∏–µ —Ç–µ–º—ã: {topic}**

–≠—Ç–∞ —Ç–µ–º–∞ —Å–≤—è–∑–∞–Ω–∞ —Å —Ü–∏—Ñ—Ä–æ–≤–æ–π –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç—å—é –∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è–º–∏. –î–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥—É—é –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –∞–∫—Ç—É–∞–ª—å–Ω—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –ø—Ä–∞–∫—Ç–∏–∫–æ–≤–∞—Ç—å—Å—è –≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤.

üí° **–°–æ–≤–µ—Ç –ø–æ –∏–∑—É—á–µ–Ω–∏—é**

–ù–∞—á–Ω–∏—Ç–µ —Å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è - –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–∑—É—á–∞–µ–º—É—é —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—é –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö —Å–∏—Ç—É–∞—Ü–∏—è—Ö. –≠—Ç–æ –ø–æ–º–æ–∂–µ—Ç –ª—É—á—à–µ –ø–æ–Ω—è—Ç—å –ø—Ä–∏–Ω—Ü–∏–ø—ã —Ä–∞–±–æ—Ç—ã –∏ –∑–∞–∫—Ä–µ–ø–∏—Ç—å –∑–Ω–∞–Ω–∏—è.
"""

def should_use_external_knowledge(topic, relevant_sections):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–Ω–µ—à–Ω–∏–µ –∑–Ω–∞–Ω–∏—è - –¢–ï–ü–ï–†–¨ –°–¢–†–û–ì–ê–Ø –ü–†–û–í–ï–†–ö–ê"""
    if not relevant_sections:
        logger.info(f"üîç –ü–æ —Ç–µ–º–µ '{topic}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–∞–∑–¥–µ–ª–æ–≤ –≤ —É—á–µ–±–Ω–∏–∫–∞—Ö - –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–Ω–µ—à–Ω–∏–µ –∑–Ω–∞–Ω–∏—è")
        return True
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ —É—á–µ–±–Ω–∏–∫–∞—Ö —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º –¥–æ—Å—Ç—É–ø–æ–º
    total_content_length = 0
    for section in relevant_sections:
        content = section.get('content', '') if isinstance(section, dict) else ''
        total_content_length += len(content)
    
    # –ñ–ï–°–¢–ö–ò–ï –ö–†–ò–¢–ï–†–ò–ò –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–ª—å–∫–æ —É—á–µ–±–Ω–∏–∫–æ–≤:
    if total_content_length < 100:  # –û—á–µ–Ω—å –º–∞–ª–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        logger.info(f"üîç –ü–æ —Ç–µ–º–µ '{topic}' –º–∞–ª–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ —É—á–µ–±–Ω–∏–∫–∞—Ö ({total_content_length} chars) - –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–Ω–µ—à–Ω–∏–µ –∑–Ω–∞–Ω–∏—è")
        return True
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å - —Å—á–∏—Ç–∞–µ–º —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —Ç–µ–º—ã
    topic_lower = topic.lower()
    topic_words = [word for word in topic_lower.split() if len(word) > 2]
    
    relevance_score = 0
    for section in relevant_sections:
        content = section.get('content', '') if isinstance(section, dict) else ''
        content_lower = content.lower()
        for word in topic_words:
            relevance_score += content_lower.count(word)
    
    # –ï—Å–ª–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –æ—á–µ–Ω—å –Ω–∏–∑–∫–∞—è
    if relevance_score < 3:  # –ú–µ–Ω—å—à–µ 3 —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        logger.info(f"üîç –ü–æ —Ç–µ–º–µ '{topic}' –Ω–∏–∑–∫–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –≤ —É—á–µ–±–Ω–∏–∫–∞—Ö (score: {relevance_score}) - –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–Ω–µ—à–Ω–∏–µ –∑–Ω–∞–Ω–∏—è")
        return True
    
    # –ï—Å–ª–∏ –ø—Ä–æ—à–ª–∏ –≤—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —É—á–µ–±–Ω–∏–∫–∏
    logger.info(f"‚úÖ –ü–æ —Ç–µ–º–µ '{topic}' –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ —É—á–µ–±–Ω–∏–∫–∞—Ö ({total_content_length} chars, relevance: {relevance_score}) - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —É—á–µ–±–Ω–∏–∫–∏")
    return False

def safe_get_section_data(section, key, default=''):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ (—Ä–∞–±–æ—Ç–∞–µ—Ç —Å sqlite3.Row –∏ dict)"""
    try:
        if hasattr(section, 'keys') and key in section.keys():
            return section[key]
        elif isinstance(section, dict) and key in section:
            return section[key]
        else:
            return default
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –ø–æ–ª—é {key} –≤ —Ä–∞–∑–¥–µ–ª–µ: {e}")
        return default

def enhance_with_external_knowledge(base_explanation, topic):
    """–î–æ–ø–æ–ª–Ω—è–µ—Ç –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –≤–Ω–µ—à–Ω–∏–º–∏ –∑–Ω–∞–Ω–∏—è–º–∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏"""
    enhancement_prompt = f"""
–î–û–ü–û–õ–ù–ò –°–õ–ï–î–£–Æ–©–ï–ï –û–ë–™–Ø–°–ù–ï–ù–ò–ï –ê–ö–¢–£–ê–õ–¨–ù–û–ô –ò–ù–§–û–†–ú–ê–¶–ò–ï–ô –ò–ó –°–û–í–†–ï–ú–ï–ù–ù–´–• –ò–°–¢–û–ß–ù–ò–ö–û–í:

–¢–ï–ú–ê: {topic}

–ë–ê–ó–û–í–û–ï –û–ë–™–Ø–°–ù–ï–ù–ò–ï:
{base_explanation}

–ó–ê–î–ê–ß–ê:
- –î–æ–±–∞–≤—å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã
- –£–∫–∞–∂–∏ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã –∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ)
- –í–∫–ª—é—á–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ç–µ–Ω–¥–µ–Ω—Ü–∏—è—Ö
- –°–æ—Ö—Ä–∞–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

–í–ï–†–ù–ò –¢–û–õ–¨–ö–û –î–û–ü–û–õ–ù–ï–ù–ù–´–ô –¢–ï–ö–°–¢ –ë–ï–ó –ö–û–ú–ú–ï–ù–¢–ê–†–ò–ï–í.
"""
    
    try:
        response = gigachat_service.client.chat(enhancement_prompt)
        enhanced = response.choices[0].message.content.strip()
        return enhanced
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è –≤–Ω–µ—à–Ω–∏–º–∏ –∑–Ω–∞–Ω–∏—è–º–∏: {e}")
        return base_explanation



def has_proper_paragraphs(text):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∏–º–µ–µ—Ç –ª–∏ —Ç–µ–∫—Å—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –∞–±–∑–∞—Ü—ã"""
    if not text:
        return False
    
    # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–±–∑–∞—Ü–µ–≤ (—Ä–∞–∑–¥–µ–ª–æ–≤ –ø–æ –ø—É—Å—Ç—ã–º —Å—Ç—Ä–æ–∫–∞–º)
    paragraphs = re.split(r'\n\s*\n', text)
    non_empty_paragraphs = [p.strip() for p in paragraphs if p.strip()]
    
    # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ö–æ—Ç—è –±—ã 3 –∞–±–∑–∞—Ü–∞ –¥–ª—è —Ö–æ—Ä–æ—à–µ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    if len(non_empty_paragraphs) < 3:
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–µ—Ç –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã—Ö –∞–±–∑–∞—Ü–µ–≤
    long_paragraphs = sum(1 for p in non_empty_paragraphs if len(p) > 500)
    if long_paragraphs > 0:
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    visual_indicators = [
        r'\*\*',  # –ñ–∏—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç
        r'[üéØüí°üìö‚ö†Ô∏è‚úÖüåüüìñüõ†Ô∏è]',  # –≠–º–æ–¥–∑–∏
        r'\n-',   # –ú–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏
    ]
    
    score = sum(1 for indicator in visual_indicators if re.search(indicator, text))
    
    return score >= 2

def generate_contextual_test(topic, relevant_sections):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º - –° –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï–ú –ö–ù–ò–ì–ò –ò –í–ù–ï–®–ù–ò–• –ó–ù–ê–ù–ò–ô"""
    logger.info(f"üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–∞ –ø–æ —Ç–µ–º–µ '{topic}' (—É—á–µ–±–Ω–∏–∫ + –≤–Ω–µ—à–Ω–∏–µ –∑–Ω–∞–Ω–∏—è)...")
    
    max_retries = 3
    for attempt in range(max_retries):
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é —Ç–µ–æ—Ä–∏–∏ –¥–ª—è —Ç–µ—Å—Ç–æ–≤
            theory = generate_contextual_theory_for_test(topic, relevant_sections)
            questions = generate_contextual_questions(topic, relevant_sections, theory)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –≤–æ–ø—Ä–æ—Å–æ–≤
            if has_question_variety(questions):
                logger.info(f"‚úÖ –¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω: {len(questions)} —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤")
                return {
                    'topic': topic,
                    'theory': theory,
                    'questions': questions,
                    'sources': {
                        'textbook': len(relevant_sections) > 0,
                        'external_knowledge': should_use_external_knowledge_for_test(topic, relevant_sections)
                    }
                }
            else:
                logger.warning(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}: –≤–æ–ø—Ä–æ—Å—ã –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã")
                
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
    
    # –ï—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–π —Ç–µ—Å—Ç
    return create_quality_full_test(topic, relevant_sections)

def has_question_variety(questions):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã –≤–æ–ø—Ä–æ—Å—ã"""
    if len(questions) < 5:
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤–æ–ø—Ä–æ—Å—ã –Ω–µ —Å–ª–∏—à–∫–æ–º –ø–æ—Ö–æ–∂–∏ –¥—Ä—É–≥ –Ω–∞ –¥—Ä—É–≥–∞
    question_texts = [q['question'].lower() for q in questions]
    unique_words = set()
    
    for text in question_texts:
        words = re.findall(r'\b\w{4,}\b', text)
        unique_words.update(words)
    
    # –ï—Å–ª–∏ –≤ 5 –≤–æ–ø—Ä–æ—Å–∞—Ö –º–µ–Ω—å—à–µ 15 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã - –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
    return len(unique_words) >= 15

def generate_question_batch(topic, relevant_sections, theory, question_type, count):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∞—Ä—Ç–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤ —Å –∫—Ä–∞—Å–∏–≤–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–Ω—ã–º–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏"""
    prompt = f"""
–°–û–ó–î–ê–ô {count} –ö–ê–ß–ï–°–¢–í–ï–ù–ù–´–• –í–û–ü–†–û–°–û–í –° –ö–†–ê–°–ò–í–´–ú–ò –û–ë–™–Ø–°–ù–ï–ù–ò–Ø–ú–ò –ü–û –¢–ï–ú–ï: "{topic}"

–¢–ï–û–†–ï–¢–ò–ß–ï–°–ö–ê–Ø –°–ü–†–ê–í–ö–ê:
{theory}

–¢–ò–ü –í–û–ü–†–û–°–û–í: {question_type.upper()}

–û–°–û–ë–´–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –û–ë–™–Ø–°–ù–ï–ù–ò–Ø–ú:
–û–±—ä—è—Å–Ω–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å:
‚úÖ **–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º** - —Å —á–µ—Ç–∫–∏–º–∏ –ø—É–Ω–∫—Ç–∞–º–∏
üéØ **–ü–æ–Ω—è—Ç–Ω—ã–º** - –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º  
üí° **–ü–æ–ª–µ–∑–Ω—ã–º** - —Å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ —Å–æ–≤–µ—Ç–∞–º–∏
üìö **–û–±—É—á–∞—é—â–∏–º** - —É–≥–ª—É–±–ª—è–µ—Ç –ø–æ–Ω–∏–º–∞–Ω–∏–µ

–§–û–†–ú–ê–¢ –û–ë–™–Ø–°–ù–ï–ù–ò–Ø:
- –ù–∞—á–∏–Ω–∞–π —Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ –æ—Ç–≤–µ—Ç–∞
- –û–±—ä—è—Å–Ω–∏ –ø–æ—á–µ–º—É –æ—Ç–≤–µ—Ç –≤–µ—Ä–Ω—ã–π
- –ü—Ä–∏–≤–µ–¥–∏ –ø—Ä–∏–º–µ—Ä –∏–∑ —Ä–µ–∞–ª—å–Ω–æ–π –∂–∏–∑–Ω–∏
- –î–∞–π –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–ª–µ–∑–Ω—ã–π —Å–æ–≤–µ—Ç
- –£–∫–∞–∂–∏ —Å–≤—è–∑—å —Å —Ç–µ–æ—Ä–∏–µ–π

–ü–†–ò–ú–ï–† –•–û–†–û–®–ï–ì–û –û–ë–™–Ø–°–ù–ï–ù–ò–Ø:
"‚úÖ **–ü—Ä–∞–≤–∏–ª—å–Ω–æ!** –≠—Ç–æ—Ç –æ—Ç–≤–µ—Ç –≤–µ—Ä–Ω—ã–π, –ø–æ—Ç–æ–º—É —á—Ç–æ...

üéØ **–û—Å–Ω–æ–≤–Ω–∞—è –ø—Ä–∏—á–∏–Ω–∞:**
–°–æ–≥–ª–∞—Å–Ω–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤—É, —ç—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç –∑–∞—â–∏—Ç–∏—Ç—å –≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ...

üí° **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–∏–º–µ—Ä:**
–ü—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ, —á—Ç–æ –≤—ã —Å–æ–∑–¥–∞–µ—Ç–µ –ø–∞—Ä–æ–ª—å –¥–ª—è –ø–æ—á—Ç—ã...

üìö **–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Å–æ–≤–µ—Ç:**
–í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–∞–∑–Ω—ã–µ –ø–∞—Ä–æ–ª–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤..."

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (–¢–û–õ–¨–ö–û JSON):
{{
    "questions": [
        {{
            "question": "–¢–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞...",
            "options": ["–í–∞—Ä–∏–∞–Ω—Ç 1", "–í–∞—Ä–∏–∞–Ω—Ç 2", "–í–∞—Ä–∏–∞–Ω—Ç 3", "–í–∞—Ä–∏–∞–Ω—Ç 4"],
            "correct_answer": 0,
            "explanation": "–ö—Ä–∞—Å–∏–≤–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å —ç–º–æ–¥–∑–∏ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π..."
        }}
    ]
}}


"""

    try:
        response = gigachat_service.client.chat(prompt)
        content = response.choices[0].message.content
        


        content = re.sub(r'^```json\s*', '', content)
        content = re.sub(r'\s*```$', '', content)
        
        questions = parse_questions_json(content)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
        for question in questions:
            if 'explanation' in question:
                question['explanation'] = format_explanation_text(question['explanation'])
        
        return questions
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤ —Ç–∏–ø–∞ {question_type}: {e}")
        return []
    

def has_good_formatting(text):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞, —Ö–æ—Ä–æ—à–æ –ª–∏ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω —Ç–µ–∫—Å—Ç"""
    if not text:
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Ö–æ—Ä–æ—à–µ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    formatting_indicators = [
        r'\n\n',  # –î–≤–æ–π–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ (–∞–±–∑–∞—Ü—ã)
        r'\*\\*',  # –ñ–∏—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç
        r'[üéØüí°üìö‚ö†Ô∏è‚úÖüåüüìñüõ†Ô∏è]',  # –≠–º–æ–¥–∑–∏
        r'\d+\.',  # –ù—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏
        r'[-‚Ä¢]',   # –ú–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏
    ]
    
    score = 0
    for indicator in formatting_indicators:
        if re.search(indicator, text):
            score += 1
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É –∞–±–∑–∞—Ü–µ–≤ (–Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫)
    lines = text.split('\n')
    long_lines = sum(1 for line in lines if len(line) > 150)
    paragraph_ratio = long_lines / len(lines) if lines else 1
    
    return score >= 2 and paragraph_ratio < 0.5  # –•–æ—Ä–æ—à–µ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –∏ –º–∞–ª–æ –¥–ª–∏–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫


def format_sections_for_analysis(relevant_sections):
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º –¥–æ—Å—Ç—É–ø–æ–º"""
    formatted = []
    for i, section in enumerate(relevant_sections[:3], 1):
        # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ –¥–∞–Ω–Ω—ã–º
        title = safe_get_section_data(section, 'title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
        content = safe_get_section_data(section, 'content', '')
        guide_source = safe_get_section_data(section, 'guide_source', 'unknown')
        
        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        clean_content = clean_text_for_context(content)
        formatted.append(f"–†–ê–ó–î–ï–õ {i} [–ò—Å—Ç–æ—á–Ω–∏–∫: {guide_source}]: {title}\n{clean_content}")
    
    return "\n\n".join(formatted) if formatted else "–í —Ä–∞–∑–¥–µ–ª–∞—Ö –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —Ç–µ–º–µ."

def clean_text_for_context(text):
    """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    # –£–±–∏—Ä–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã, –æ—Å—Ç–∞–≤–ª—è–µ–º —Å–º—ã—Å–ª–æ–≤–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
    lines = text.split('\n')
    clean_lines = []
    
    for line in lines:
        line = line.strip()
        # –£–±–∏—Ä–∞–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ (–≤–æ–∑–º–æ–∂–Ω–æ, –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã)
        if len(line) < 10:
            continue
        # –£–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏, —Å–æ—Å—Ç–æ—è—â–∏–µ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –∏–∑ —Ü–∏—Ñ—Ä –∏ —Å–∏–º–≤–æ–ª–æ–≤
        if re.match(r'^[\d\s\.\-]+$', line):
            continue
        # –£–±–∏—Ä–∞–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Ñ—Ä–∞–∑—ã
        if line in clean_lines:
            continue
            
        clean_lines.append(line)
    
    return ' '.join(clean_lines[:500])  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É

def parse_questions_json(content):
    """–ü–∞—Ä—Å–∏–Ω–≥ JSON —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ - –£–õ–£–ß–®–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
    try:
        # –û—á–∏—â–∞–µ–º JSON –±–æ–ª–µ–µ —Ç—â–∞—Ç–µ–ª—å–Ω–æ
        cleaned = clean_json_string(content)
        
        # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ markdown-–±–ª–æ–∫–∏ –∫–æ–¥–∞
        cleaned = re.sub(r'```json\s*', '', cleaned)
        cleaned = re.sub(r'```\s*', '', cleaned)
        
        # –ò—â–µ–º JSON —Å—Ç—Ä—É–∫—Ç—É—Ä—É - –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π –º–µ—Ç–æ–¥
        json_pattern = r'\{(?:[^{}]|(?:\{(?:[^{}]|(?:\{[^{}]*\}))*\}))*\}'
        matches = re.findall(json_pattern, cleaned, re.DOTALL)
        
        if not matches:
            logger.warning("‚ùå JSON —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –æ—Ç–≤–µ—Ç–µ")
            return []
            
        # –ü—Ä–æ–±—É–µ–º –∫–∞–∂–¥—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π JSON
        for json_str in matches:
            try:
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
                json_str = json_str.strip()
                if not json_str.startswith('{'):
                    continue
                    
                data = json.loads(json_str)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                if 'questions' in data and isinstance(data['questions'], list):
                    questions = data['questions']
                    validated_questions = []
                    
                    for i, q in enumerate(questions):
                        if validate_question_quality(q):
                            validated_questions.append({
                                'id': i,
                                'question': q['question'],
                                'options': q['options'][:4],  # –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º 4 –≤–∞—Ä–∏–∞–Ω—Ç–∞
                                'correct_answer': min(q.get('correct_answer', 0), 3),  # –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∏–Ω–¥–µ–∫—Å
                                'explanation': q.get('explanation', '–û–±—ä—è—Å–Ω–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞.')
                            })
                    
                    logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–æ {len(validated_questions)} –≤–æ–ø—Ä–æ—Å–æ–≤")
                    return validated_questions
                    
            except json.JSONDecodeError as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON: {e}")
                continue
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ JSON: {e}")
                continue
        
        logger.error("‚ùå –ù–∏ –æ–¥–∏–Ω JSON –Ω–µ –ø—Ä–æ—à–µ–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é")
        return []
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤–æ–ø—Ä–æ—Å–æ–≤: {e}")
        return []

def validate_question_quality(question):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –≤–æ–ø—Ä–æ—Å–∞"""
    if not isinstance(question, dict):
        return False
        
    required = ['question', 'options']
    if not all(field in question for field in required):
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤–æ–ø—Ä–æ—Å –Ω–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
    if len(question['question']) < 10:
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤
    options = question['options']
    if not isinstance(options, list) or len(options) != 4:
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ä–∞–∑–Ω—ã–µ
    if len(set(options)) < 3:
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤–æ–ø—Ä–æ—Å –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π (–Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
    if is_meaningless_question(question['question']):
        return False
        
    return True

def is_meaningless_question(question):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –≤–æ–ø—Ä–æ—Å –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã–º"""
    meaningless_patterns = [
        r'—Å–∫–æ–ª—å–∫–æ.*–∫–Ω–æ–ø–æ–∫',
        r'–∫–∞–∫–æ–≥–æ.*—Ü–≤–µ—Ç–∞',
        r'—á—Ç–æ —Ç–∞–∫–æ–µ.*\?$',
        r'–∫–∞–∫ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è.*\?$',
        r'—É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –ª–∏.*\?$'
    ]
    
    question_lower = question.lower()
    for pattern in meaningless_patterns:
        if re.search(pattern, question_lower):
            return True
    
    return False

def is_low_quality_theory(theory):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–π —Å–ø—Ä–∞–≤–∫–∏"""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É
    if len(theory) < 150:
        return True
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–ø–∏—Å–∫–æ–≤ –∏ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–π (–ø—Ä–∏–∑–Ω–∞–∫ –Ω–∏–∑–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞)
    if theory.count('-') > 3 or theory.count('‚Ä¢') > 3:
        return True
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –ø—Ä–æ—Å—Ç–æ –Ω–∞–±–æ—Ä —Ñ–∞–∫—Ç–æ–≤
    sentences = re.split(r'[.!?]+', theory)
    if len(sentences) < 4:
        return True
    
    return False



def create_meaningful_theory(topic, relevant_sections):
    """–°–æ–∑–¥–∞–Ω–∏–µ –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–π —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–π —Å–ø—Ä–∞–≤–∫–∏ –≤—Ä—É—á–Ω—É—é"""
    if not relevant_sections:
        return f"–¢–µ–º–∞ '{topic}' —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è –≤ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ –ø–æ —Ü–∏—Ñ—Ä–æ–≤–æ–π –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç–∏. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏–∑—É—á–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ä–∞–∑–¥–µ–ª—ã –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–∞–≤—ã–∫–æ–≤."
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–æ–≤ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
    key_concepts = extract_key_concepts(relevant_sections, topic)
    
    if key_concepts:
        theory = f"–í —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è —Ç–µ–º–∞ '{topic}' –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ {key_concepts[0]}. "
        if len(key_concepts) > 1:
            theory += f"–û—Å–Ω–æ–≤–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ —É–¥–µ–ª—è–µ—Ç—Å—è {', '.join(key_concepts[1:3])}. "
        theory += "–≠—Ç–∏ –∑–Ω–∞–Ω–∏—è –ø–æ–º–æ–≥—É—Ç –≤–∞–º —É–≤–µ—Ä–µ–Ω–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–º–ø—å—é—Ç–µ—Ä –≤ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö."
    else:
        theory = f"–¢–µ–º–∞ '{topic}' –≤–∞–∂–Ω–∞ –¥–ª—è –æ—Å–≤–æ–µ–Ω–∏—è —Ü–∏—Ñ—Ä–æ–≤–æ–π –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç–∏. –í —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –≤ –±—ã—Ç–æ–≤—ã—Ö —Å–∏—Ç—É–∞—Ü–∏—è—Ö."
    
    return theory

def extract_key_concepts(relevant_sections, topic):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–Ω—Ü–µ–ø—Ü–∏–π –∏–∑ —Ä–∞–∑–¥–µ–ª–æ–≤"""
    concepts = set()
    
    for section in relevant_sections[:2]:
        content = section['content'].lower()
        
        # –ò—â–µ–º —Å–º—ã—Å–ª–æ–≤—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
        sentences = re.split(r'[.!?]+', content)
        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) > 30 and topic.lower() in sentence:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–∑—ã
                words = re.findall(r'\b[\w]{5,}\b', sentence)
                if len(words) > 3:
                    concept = ' '.join(words[:3])
                    concepts.add(concept)
    
    return list(concepts)[:5]




def clean_json_string(json_string):
    """–û—á–∏—Å—Ç–∫–∞ JSON —Å—Ç—Ä–æ–∫–∏"""
    replacements = {
        '‚Äú': '"', '‚Äù': '"', '‚Äû': '"', '¬´': '"', '¬ª': '"',
        '‚Äò': "'", '‚Äô': "'", '`': "'", '¬¥': "'",
        '‚Äú': '"', '‚Äù': '"', '¬´': '"', '¬ª': '"',
        '‚Äò': "'", '‚Äô': "'", '`': "'",
        '¬†': ' ', '\\"': '"', "\\'": "'"
    }
    
    cleaned = json_string
    for wrong, correct in replacements.items():
        cleaned = cleaned.replace(wrong, correct)
    
    return cleaned

def get_relevant_sections(topic):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤ –∏–∑ –í–°–ï–• —É—á–µ–±–Ω–∏–∫–æ–≤ –ø–æ —Ç–µ–º–µ"""
    try:
        sections = db.get_guide_sections(limit=300)
        relevant = []
        
        topic_lower = topic.lower()
        topic_words = [word for word in topic_lower.split() if len(word) > 2]
        
        logger.info(f"üîç –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ —Ç–µ–º–µ '{topic}' –≤–æ –≤—Å–µ—Ö —É—á–µ–±–Ω–∏–∫–∞—Ö: –ø—Ä–æ–≤–µ—Ä—è–µ–º {len(sections)} —Ä–∞–∑–¥–µ–ª–æ–≤")
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏–Ω–æ–Ω–∏–º—ã –¥–ª—è –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ç–µ–º
        topic_synonyms = get_topic_synonyms(topic)
        all_search_terms = [topic_lower] + topic_synonyms
        
        for section in sections:
            # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ –¥–∞–Ω–Ω—ã–º
            title = safe_get_section_data(section, 'section_title', '').lower()
            content = safe_get_section_data(section, 'section_content', '').lower()
            guide_source = safe_get_section_data(section, 'guide_source', 'unknown')
            
            score = 0
            
            # –ü–æ–≤—ã—à–∞–µ–º –≤–µ—Å, –µ—Å–ª–∏ —Ç–µ–º–∞ –µ—Å—Ç—å –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ
            for search_term in all_search_terms:
            
                if search_term in title:
                    score += 30
            
            
                if search_term in content:
                    score += 10
                    
            # –£—á–∏—Ç—ã–≤–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
            for word in topic_words:
                if word in title:
                    score += 8
                if word in content:
                    score += 3
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–∞–ª–ª—ã –∑–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫—É
            if any(source in guide_source.lower() for source in ['horizont', 'guide_2']):
                score += 5
            
            # –°–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è
            if score >= 1:
                relevant.append({
                    'title': safe_get_section_data(section, 'section_title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'),
                    'content': safe_get_section_data(section, 'section_content', ''),
                    'score': score,
                    'page': safe_get_section_data(section, 'page_number', 0),
                    'guide_source': guide_source
                })
        
        relevant.sort(key=lambda x: x['score'], reverse=True)
        
        logger.info(f"üìö –ü–æ —Ç–µ–º–µ '{topic}' –Ω–∞–π–¥–µ–Ω–æ —Ä–∞–∑–¥–µ–ª–æ–≤: {len(relevant)}")
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        sources_used = set()
        for section in relevant[:10]:
            source = section.get('guide_source', 'unknown') if isinstance(section, dict) else 'unknown'
            sources_used.add(source)
        logger.info(f"üìñ –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {sources_used}")
        
        for section in relevant[:3]:
            logger.info(f"   - '{section['title']}' (–∏—Å—Ç–æ—á–Ω–∏–∫: {section.get('guide_source', 'unknown')}, score: {section.get('score', 0)})")
        
        return relevant[:8]
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Ä–∞–∑–¥–µ–ª–æ–≤: {e}")
        return []
    
@app.route('/api/check-full-test', methods=['POST'])
def check_full_test():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ–≥–æ —Ç–µ—Å—Ç–∞ –∏–∑ 5 –≤–æ–ø—Ä–æ—Å–æ–≤"""
    try:
        data = request.get_json()
        user_answers = data.get('user_answers', [])
        test_data = data.get('test_data', {})
        
        if not user_answers or not test_data:
            return jsonify({'error': '–î–∞–Ω–Ω—ã–µ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã'}), 400
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π –æ—Ç–≤–µ—Ç
        results = []
        correct_count = 0
        
        for i, user_answer in enumerate(user_answers):
            question = test_data['questions'][i]
            is_correct = (user_answer == question['correct_answer'])
            
            if is_correct:
                correct_count += 1
                
            results.append({
                'question_index': i,
                'question': question['question'],
                'options': question['options'],  # –î–æ–±–∞–≤–ª—è–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤
                'user_answer': user_answer,
                'correct_answer': question['correct_answer'],
                'is_correct': is_correct,
                'explanation': question.get('explanation', '–û–±—ä—è—Å–Ω–µ–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')
            })
        
        # –°—á–∏—Ç–∞–µ–º –æ—Ü–µ–Ω–∫—É
        total_questions = len(test_data['questions'])
        score = int((correct_count / total_questions) * 100)
        
        return jsonify({
            'status': 'success',
            'results': results,
            'score': score,
            'correct_count': correct_count,
            'total_questions': total_questions
        })
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞: {e}")
        return jsonify({'error': str(e)}), 500


def check_textbook_coverage(topic, relevant_sections):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ —É—á–µ–±–Ω–∏–∫–∞—Ö –¥–ª—è —Ç–µ–º—ã"""
    if not relevant_sections:
        return False, "–ù–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ —É—á–µ–±–Ω–∏–∫–∞—Ö"
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º –¥–æ—Å—Ç—É–ø–æ–º –∫ –ø–æ–ª—è–º
    total_chars = 0
    unique_sources = set()
    
    for section in relevant_sections:
        # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ –ø–æ–ª—é content
        content = section.get('content', '') if isinstance(section, dict) else ''
        total_chars += len(content)
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ –ø–æ–ª—é guide_source
        guide_source = section.get('guide_source', 'unknown') if isinstance(section, dict) else 'unknown'
        unique_sources.add(guide_source)
    
    # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    if total_chars < 200:
        return False, f"–ú–∞–ª–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ ({total_chars} —Å–∏–º–≤–æ–ª–æ–≤)"
    
    if len(unique_sources) < 1:
        return False, "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –∏–∑ –æ–¥–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–ª—É–±–∏–Ω—É –ø–æ–∫—Ä—ã—Ç–∏—è —Ç–µ–º—ã
    topic_words = set(topic.lower().split())
    coverage_score = 0
    
    for section in relevant_sections:
        content = section.get('content', '') if isinstance(section, dict) else ''
        content_lower = content.lower()
        for word in topic_words:
            if word in content_lower:
                coverage_score += 1
    
    if coverage_score < len(topic_words):
        return False, f"–ù–µ–ø–æ–ª–Ω–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ–º—ã (score: {coverage_score})"
    
    return True, f"–î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ ({total_chars} —Å–∏–º–≤–æ–ª–æ–≤, {len(unique_sources)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤)"



def get_relevant_sections(topic):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤ –∏–∑ –ë–î –ø–æ —Ç–µ–º–µ - –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
    try:
        sections = db.get_guide_sections(limit=200)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç
        relevant = []
        
        topic_lower = topic.lower()
        topic_words = [word for word in topic_lower.split() if len(word) > 2]
        
        logger.info(f"üîç –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ —Ç–µ–º–µ '{topic}': –ø—Ä–æ–≤–µ—Ä—è–µ–º {len(sections)} —Ä–∞–∑–¥–µ–ª–æ–≤")
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏–Ω–æ–Ω–∏–º—ã –¥–ª—è –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ç–µ–º
        topic_synonyms = get_topic_synonyms(topic)
        all_search_terms = [topic_lower] + topic_synonyms
        
        for section in sections:
            title = section['section_title'].lower()
            content = section['section_content'].lower()
            
            score = 0
            
            # –ü–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º —Ç–µ—Ä–º–∏–Ω–∞–º (–æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–º–µ –∏ —Å–∏–Ω–æ–Ω–∏–º–∞–º)
            for search_term in all_search_terms:
                # –ü–æ–≤—ã—à–∞–µ–º –≤–µ—Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
                if search_term in title:
                    score += 25
                if search_term in content:
                    score += 10
                    
            # –£—á–∏—Ç—ã–≤–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
            for word in topic_words:
                if word in title:
                    score += 8
                if word in content:
                    score += 3
            
            # –°–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –µ—â–µ –±–æ–ª—å—à–µ
            if score >= 1:
                relevant.append({
                    'title': section['section_title'],
                    'content': section['section_content'],
                    'score': score,
                    'page': section['page_number']
                })
        
        relevant.sort(key=lambda x: x['score'], reverse=True)
        
        logger.info(f"üìö –ü–æ —Ç–µ–º–µ '{topic}' –Ω–∞–π–¥–µ–Ω–æ —Ä–∞–∑–¥–µ–ª–æ–≤: {len(relevant)}")
        for section in relevant[:5]:
            logger.info(f"   - '{section['title']}' (score: {section['score']}, {len(section['content'])} chars)")
        
        return relevant[:5]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-5 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Ä–∞–∑–¥–µ–ª–æ–≤: {e}")
        return []

def get_topic_synonyms(topic):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –¥–ª—è —Ç–µ–º—ã"""
    synonyms_map = {
        '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç': ['–∏–Ω—Ç–µ—Ä–Ω–µ—Ç', '—Å–µ—Ç—å', 'online', '–±—Ä–∞—É–∑–µ—Ä', '–≤–µ–±', '—Å–∞–π—Ç', '–ø—Ä–æ–≤–æ–¥–Ω–∏–∫'],
        '–∫–æ–º–ø—å—é—Ç–µ—Ä': ['–∫–æ–º–ø—å—é—Ç–µ—Ä', '–ø–∫', '–Ω–æ—É—Ç–±—É–∫', '—Å–∏—Å—Ç–µ–º–Ω—ã–π –±–ª–æ–∫', '–º–æ–Ω–∏—Ç–æ—Ä'],
        '–º—ã—à—å': ['–º—ã—à—å', '–º—ã—à–∫–∞', '–∫—É—Ä—Å–æ—Ä', '–º–∞–Ω–∏–ø—É–ª—è—Ç–æ—Ä'],
        '–∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞': ['–∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞', '–∫–ª–∞–≤–∏—à–∏', '–≤–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞'],
        '–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': ['–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å', '–∑–∞—â–∏—Ç–∞', '–∞–Ω—Ç–∏–≤–∏—Ä—É—Å', '–ø–∞—Ä–æ–ª—å', '–≤–∏—Ä—É—Å'],
        '—Ñ–∞–π–ª—ã': ['—Ñ–∞–π–ª—ã', '–¥–æ–∫—É–º–µ–Ω—Ç—ã', '–ø–∞–ø–∫–∏', '—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ'],
        '–ø—Ä–æ–≥—Ä–∞–º–º—ã': ['–ø—Ä–æ–≥—Ä–∞–º–º—ã', '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è', '—Å–æ—Ñ—Ç', '—É—Å—Ç–∞–Ω–æ–≤–∫–∞']
    }
    
    topic_lower = topic.lower()
    return synonyms_map.get(topic_lower, [])

def create_learning_prompt(topic, relevant_sections):
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –æ–¥–Ω–æ–≥–æ —É—Ä–æ–∫–∞"""
    
    concrete_texts = []
    for i, section in enumerate(relevant_sections[:2], 1):
        concrete_text = section['content'][:500]
        concrete_texts.append(f"–†–ê–ó–î–ï–õ {i} '{section['title']}':\n{concrete_text}")
    
    concrete_content = "\n\n".join(concrete_texts)
    
    prompt = f"""
    –ò–°–ü–û–õ–¨–ó–£–ô –¢–û–õ–¨–ö–û –≠–¢–£ –ò–ù–§–û–†–ú–ê–¶–ò–Æ –ò–ó –†–£–ö–û–í–û–î–°–¢–í–ê:

    {concrete_content}

    –ó–ê–ü–†–ï–©–ï–ù–û:
    - –ü—Ä–∏–¥—É–º—ã–≤–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è
    - –î–∞–≤–∞—Ç—å –æ–±—â–∏–µ —Ñ—Ä–∞–∑—ã

    –ó–ê–î–ê–ß–ê 1: –û–ë–™–Ø–°–ù–ï–ù–ò–ï –¢–ï–ú–´ "{topic.upper()}"
    - –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ñ–∞–∫—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ –≤—ã—à–µ
    - –¶–∏—Ç–∏—Ä—É–π –ö–û–ù–ö–†–ï–¢–ù–´–ï —Ñ—Ä–∞–∑—ã –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞
    - –û–±—ä—è—Å–Ω–µ–Ω–∏–µ: 3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è

    –ó–ê–î–ê–ß–ê 2: –¢–ï–°–¢–û–í–´–ô –í–û–ü–†–û–°
    - –í–æ–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω –ø—Ä–æ–≤–µ—Ä—è—Ç—å –ö–û–ù–ö–†–ï–¢–ù–´–ô —Ñ–∞–∫—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞
    - –í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ—Å–Ω–æ–≤–∞–Ω—ã –Ω–∞ —Ç–µ–∫—Å—Ç–µ
    - –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ç–æ—á–Ω–æ–π —Ü–∏—Ç–∞—Ç–æ–π –∏–ª–∏ –ø—Ä—è–º—ã–º —Å–ª–µ–¥—Å—Ç–≤–∏–µ–º –∏–∑ —Ç–µ–∫—Å—Ç–∞

    –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (–¢–û–õ–¨–ö–û JSON):
    {{
        "explanation": "–¢–≤–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å –¶–ò–¢–ê–¢–ê–ú–ò –∏–∑ —Ç–µ–∫—Å—Ç–∞...",
        "quiz": {{
            "question": "–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å –ø–æ —Ç–µ–∫—Å—Ç—É –≤—ã—à–µ...",
            "options": ["–≤–∞—Ä–∏–∞–Ω—Ç1", "–≤–∞—Ä–∏–∞–Ω—Ç2", "–≤–∞—Ä–∏–∞–Ω—Ç3", "–≤–∞—Ä–∏–∞–Ω—Ç4"],
            "correct_answer": 0,
            "explanation": "–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç - –≤–∞—Ä–∏–∞–Ω—Ç X, –ø–æ—Ç–æ–º—É —á—Ç–æ –≤ —Ç–µ–∫—Å—Ç–µ —Å–∫–∞–∑–∞–Ω–æ: '–¶–ò–¢–ê–¢–ê –ò–ó –†–£–ö–û–í–û–î–°–¢–í–ê'."
        }}
    }}

    –ù–ê–ß–ò–ù–ê–ô –û–¢–í–ï–¢ –° {{"
    """
    
    return prompt

def parse_learning_response(response, topic, relevant_sections):
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
    try:
        cleaned_response = response.strip()
        logger.info(f"üîß Raw GigaChat response: {cleaned_response[:500]}...")
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º "—É–º–Ω—ã–µ" –∫–∞–≤—ã—á–∫–∏ –ø–µ—Ä–µ–¥ –ø–∞—Ä—Å–∏–Ω–≥–æ–º JSON
        cleaned_response = clean_json_string(cleaned_response)
        
        start = cleaned_response.find('{')
        end = cleaned_response.rfind('}') + 1
        
        if start == -1 or end == 0:
            raise ValueError("JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ")
            
        json_str = cleaned_response[start:end]
        data = json.loads(json_str)
        
        explanation = data.get('explanation', '')
        
        # –ü–†–û–í–ï–†–ö–ê: –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ–∞–∫—Ç—ã –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞
        if not contains_concrete_info(explanation, relevant_sections):
            logger.warning("‚ö†Ô∏è GigaChat –¥–∞–ª –æ–±—â–µ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –±–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∏!")
            explanation = create_quality_explanation(topic, relevant_sections)
        
        quiz_data = data.get('quiz')
        if not quiz_data:
            return explanation, None
            
        quiz = validate_and_fix_quiz(quiz_data, topic, relevant_sections)
        
        return explanation, quiz
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞: {e}")
        return create_quality_explanation(topic, relevant_sections), create_quality_quiz(topic, relevant_sections)

def create_full_test_prompt(topic, relevant_sections):
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ –∏–∑ 10 –≤–æ–ø—Ä–æ—Å–æ–≤"""
    
    concrete_texts = []
    for i, section in enumerate(relevant_sections[:3], 1):
        concrete_text = section['content'][:800]  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –æ–±—ä–µ–º –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        concrete_texts.append(f"–†–ê–ó–î–ï–õ {i} '{section['title']}':\n{concrete_text}")
    
    concrete_content = "\n\n".join(concrete_texts)
    
    prompt = f"""
    –¢–´ - –≠–ö–°–ü–ï–†–¢ –ü–û –°–û–ó–î–ê–ù–ò–Æ –¢–ï–°–¢–û–í. –°–û–ó–î–ê–ô –¢–ï–°–¢ –ò–ó 5 –í–û–ü–†–û–°–û–í –ü–û –¢–ï–ú–ï "{topic.upper()}".

    –ò–°–ü–û–õ–¨–ó–£–ô –¢–û–õ–¨–ö–û –≠–¢–£ –ò–ù–§–û–†–ú–ê–¶–ò–Æ –ò–ó –†–£–ö–û–í–û–î–°–¢–í–ê:

    {concrete_content}

    –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:
    1. –ù–ï –ø—Ä–∏–¥—É–º—ã–≤–∞–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é - –∏—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç –≤—ã—à–µ
    2. –ö–∞–∂–¥—ã–π –≤–æ–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω –ø—Ä–æ–≤–µ—Ä—è—Ç—å –ö–û–ù–ö–†–ï–¢–ù–´–ô —Ñ–∞–∫—Ç –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞
    3. –í—Å–µ 4 –≤–∞—Ä–∏–∞–Ω—Ç–∞ –æ—Ç–≤–µ—Ç–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –†–ê–ó–ù–´–ú–ò –∏ –û–°–ú–´–°–õ–ï–ù–ù–´–ú–ò
    4. –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ü–†–ê–í–ò–õ–¨–ù–´–ú
    5. –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –æ–±—â–∏–µ —Ñ—Ä–∞–∑—ã –∏–ª–∏ —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è

    –°–¢–†–£–ö–¢–£–†–ê –¢–ï–°–¢–ê:

    1. –¢–ï–û–†–ï–¢–ò–ß–ï–°–ö–ê–Ø –°–ü–†–ê–í–ö–ê (5-7 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π):
       - –ö—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ç–µ–º—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞
       - –ò—Å–ø–æ–ª—å–∑—É–π –ö–û–ù–ö–†–ï–¢–ù–´–ï —Ñ–∞–∫—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞
       - –¶–∏—Ç–∏—Ä—É–π –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã

    2. 10 –í–û–ü–†–û–°–û–í:
       - –ö–∞–∂–¥—ã–π –≤–æ–ø—Ä–æ—Å = 4 —Ä–∞–∑–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–∞ –æ—Ç–≤–µ—Ç–∞
       - –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç = —Ç–æ—á–Ω–∞—è —Ü–∏—Ç–∞—Ç–∞ –∏–ª–∏ –ø—Ä—è–º–æ–µ —Å–ª–µ–¥—Å—Ç–≤–∏–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞
       - –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã = –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–Ω—ã–µ, –Ω–æ –Ω–µ–≤–µ—Ä–Ω—ã–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
       - –í–æ–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã –æ—Ö–≤–∞—Ç—ã–≤–∞—Ç—å –†–ê–ó–ù–´–ï –∞—Å–ø–µ–∫—Ç—ã —Ç–µ–º—ã

    –ü–†–ò–ú–ï–† –ü–†–ê–í–ò–õ–¨–ù–û–ì–û –í–û–ü–†–û–°–ê:
    –í–æ–ø—Ä–æ—Å: "–î–ª—è —á–µ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–ª–∞–≤–∏—à–∞ Enter —Å–æ–≥–ª–∞—Å–Ω–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤—É?"
    –í–∞—Ä–∏–∞–Ω—Ç—ã: [
        "–î–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –≤–≤–æ–¥–∞ –∫–æ–º–∞–Ω–¥",
        "–î–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞", 
        "–î–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è caps lock",
        "–î–ª—è –≤—ã–∑–æ–≤–∞ –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞ –∑–∞–¥–∞—á"
    ]
    –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç: 0

    –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (–°–¢–†–û–ì–û –°–û–ë–õ–Æ–î–ê–ô):

    {{
        "theory": "–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è —Å–ø—Ä–∞–≤–∫–∞ —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ —Ñ–∞–∫—Ç–∞–º–∏ –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞...",
        "questions": [
            {{
                "question": "–í–æ–ø—Ä–æ—Å 1...",
                "options": ["–≤–∞—Ä–∏–∞–Ω—Ç1", "–≤–∞—Ä–∏–∞–Ω—Ç2", "–≤–∞—Ä–∏–∞–Ω—Ç3", "–≤–∞—Ä–∏–∞–Ω—Ç4"],
                "correct_answer": 0,
                "explanation": "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å —Ü–∏—Ç–∞—Ç–æ–π –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞"
            }},
            {{
                "question": "–í–æ–ø—Ä–æ—Å 2...",
                "options": ["–≤–∞—Ä–∏–∞–Ω—Ç1", "–≤–∞—Ä–∏–∞–Ω—Ç2", "–≤–∞—Ä–∏–∞–Ω—Ç3", "–≤–∞—Ä–∏–∞–Ω—Ç4"],
                "correct_answer": 1,
                "explanation": "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å —Ü–∏—Ç–∞—Ç–æ–π –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞"
            }}
            // ... –µ—â–µ 8 –≤–æ–ø—Ä–æ—Å–æ–≤
        ]
    }}

    –í–ê–ñ–ù–û: –î–æ–ª–∂–Ω–æ –±—ã—Ç—å –†–û–í–ù–û 10 –≤–æ–ø—Ä–æ—Å–æ–≤ —Å –†–ê–ó–ù–´–ú–ò –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ –æ—Ç–≤–µ—Ç–æ–≤!
    """
    
    return prompt

def parse_learning_response(response, topic, relevant_sections):
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
    try:
        cleaned_response = response.strip()
        logger.info(f"üîß Raw GigaChat response: {cleaned_response[:500]}...")
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º "—É–º–Ω—ã–µ" –∫–∞–≤—ã—á–∫–∏ –ø–µ—Ä–µ–¥ –ø–∞—Ä—Å–∏–Ω–≥–æ–º JSON
        cleaned_response = clean_json_string(cleaned_response)
        
        start = cleaned_response.find('{')
        end = cleaned_response.rfind('}') + 1
        
        if start == -1 or end == 0:
            raise ValueError("JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ")
            
        json_str = cleaned_response[start:end]
        data = json.loads(json_str)
        
        explanation = data.get('explanation', '')
        
        # –ü–†–û–í–ï–†–ö–ê: –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ–∞–∫—Ç—ã –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞
        if not contains_concrete_info(explanation, relevant_sections):
            logger.warning("‚ö†Ô∏è GigaChat –¥–∞–ª –æ–±—â–µ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –±–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∏!")
            explanation = create_quality_explanation(topic, relevant_sections)
        
        quiz_data = data.get('quiz')
        if not quiz_data:
            return explanation, None
            
        quiz = validate_and_fix_quiz(quiz_data, topic, relevant_sections)
        
        return explanation, quiz
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞: {e}")
        return create_quality_explanation(topic, relevant_sections), create_quality_quiz(topic, relevant_sections)

def parse_full_test_response(response, topic, relevant_sections):
    """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ - –¢–û–õ–¨–ö–û –ù–ï–ô–†–û–°–ï–¢–¨–Æ"""
    try:
        cleaned_response = response.strip()
        cleaned_response = clean_json_string(cleaned_response)
        
        json_data = extract_json_from_text(cleaned_response)
        
        if not json_data:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞")
            # –í–º–µ—Å—Ç–æ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ –ø—Ä–æ–±—É–µ–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é
            return generate_contextual_test(topic, relevant_sections)
        
        theory = json_data.get('theory', '')
        questions = json_data.get('questions', [])
        
        # –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å–æ–≤ –º–µ–Ω—å—à–µ 5, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –µ—â–µ –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é
        if len(questions) < 5:
            logger.warning(f"‚ö†Ô∏è –í –æ—Ç–≤–µ—Ç–µ —Ç–æ–ª—å–∫–æ {len(questions)} –≤–æ–ø—Ä–æ—Å–æ–≤, –¥–æ–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é")
            additional_questions = generate_contextual_questions(topic, relevant_sections, theory)
            questions.extend(additional_questions)
        
        return {
            'topic': topic,
            'theory': theory,
            'questions': questions[:5]  # –¢–æ—á–Ω–æ 5 –≤–æ–ø—Ä–æ—Å–æ–≤
        }
    
    
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞: {e}")
        # –í–º–µ—Å—Ç–æ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ –ø—Ä–æ–±—É–µ–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é
        return generate_contextual_test(topic, relevant_sections)
    
def extract_json_from_text(text):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ JSON –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Ä–∞–∑–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏"""
    methods = [
        extract_json_direct,
        extract_json_with_regex,
        extract_json_with_ast
    ]
    
    for method in methods:
        try:
            result = method(text)
            if result:
                logger.info(f"‚úÖ JSON –∏–∑–≤–ª–µ—á–µ–Ω –º–µ—Ç–æ–¥–æ–º: {method.__name__}")
                return result
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ú–µ—Ç–æ–¥ {method.__name__} –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
            continue
    
    return None

def extract_json_direct(text):
    """–ü—Ä—è–º–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ JSON"""
    start = text.find('{')
    end = text.rfind('}') + 1
    
    if start == -1 or end == 0:
        return None
        
    json_str = text[start:end]
    return json.loads(json_str)

def extract_json_with_regex(text):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ JSON —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π"""
    import re
    # –ò—â–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É JSON
    json_pattern = r'\{(?:[^{}]|(?:\{(?:[^{}]|(?:\{[^{}]*\}))*\}))*\}'
    matches = re.findall(json_pattern, text, re.DOTALL)
    
    for match in matches:
        try:
            return json.loads(match)
        except:
            continue
    
    return None

def extract_json_with_ast(text):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ JSON —Å –ø–æ–º–æ—â—å—é ast (–¥–ª—è Python-–ø–æ–¥–æ–±–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä)"""
    try:
        # –ü—ã—Ç–∞–µ–º—Å—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ Python dict
        parsed = ast.literal_eval(text)
        if isinstance(parsed, dict):
            return parsed
    except:
        pass
    
    return None

def clean_json_string(json_string):
    """–û—á–∏—Å—Ç–∫–∞ JSON —Å—Ç—Ä–æ–∫–∏ –æ—Ç '—É–º–Ω—ã—Ö' –∫–∞–≤—ã—á–µ–∫ –∏ –¥—Ä—É–≥–∏—Ö –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
    replacements = {
        '‚Äú': '"', '‚Äù': '"', '‚Äû': '"', '¬´': '"', '¬ª': '"',
        '‚Äò': "'", '‚Äô': "'", '`': "'", '¬¥': "'",
        '‚Äú': '"', '‚Äù': '"', '¬´': '"', '¬ª': '"',
        '‚Äò': "'", '‚Äô': "'", '`': "'",
        '¬†': ' ', '\\"': '"', "\\'": "'"
    }
    
    cleaned = json_string
    for wrong, correct in replacements.items():
        cleaned = cleaned.replace(wrong, correct)
    
    return cleaned

def validate_question(question, question_id, topic, relevant_sections):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–∞"""

    required_fields = ['question', 'options', 'correct_answer']

    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º options
    options = question.get('options', [])
    if not isinstance(options, list) or len(options) != 4:
        options = create_quality_options(question_id, topic, relevant_sections)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ä–∞–∑–Ω—ã–µ
    if len(set(options)) < 3:  # –ú–∏–Ω–∏–º—É–º 3 —Ä–∞–∑–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–∞
        options = create_quality_options(question_id, topic, relevant_sections)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º correct_answer
    correct_answer = question.get('correct_answer', 0)
    if not isinstance(correct_answer, int) or not 0 <= correct_answer <= 3:
        correct_answer = 0
    
    return {
        'id': question_id,
        'question': question.get('question', f'–í–æ–ø—Ä–æ—Å {question_id + 1} –ø–æ —Ç–µ–º–µ "{topic}"'),
        'options': options,
        'correct_answer': correct_answer,
        'explanation': question.get('explanation', '–û–±—ä—è—Å–Ω–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞.')
    }

def create_quality_full_test(topic, relevant_sections):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö –ø–∞—Ä—Å–∏–Ω–≥–∞ - –¢–û–õ–¨–ö–û –ù–ï–ô–†–û–°–ï–¢–¨–Æ"""
    try:
        theory = generate_contextual_theory(topic, relevant_sections)
        questions = generate_contextual_questions(topic, relevant_sections, theory)
        
        return {
            'topic': topic,
            'theory': theory,
            'questions': questions
        }
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞: {e}")
        # –ü–æ–≤—Ç–æ—Ä—è–µ–º –ø–æ–ø—ã—Ç–∫—É
        return create_quality_full_test(topic, relevant_sections)

def create_quality_explanation(topic, relevant_sections):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î"""
    if not relevant_sections:
        return f"–í —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ –µ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Ç–µ–º–µ '{topic}', –Ω–æ –æ–Ω–∞ —Ç—Ä–µ–±—É–µ—Ç –∏–∑—É—á–µ–Ω–∏—è."
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ä–∞–∑–¥–µ–ª–æ–≤
    explanations = []
    for section in relevant_sections[:2]:
        content = section['content']
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        sentences = re.split(r'[.!?]+', content)
        meaningful_sentences = [s.strip() for s in sentences if len(s.strip()) > 30][:2]
        if meaningful_sentences:
            explanations.extend(meaningful_sentences)
    
    if explanations:
        explanation = " ".join(explanations[:3])
        if len(explanation) > 500:
            explanation = explanation[:500] + "..."
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–µ –∞–±–∑–∞—Ü—ã –∏–∑ —Ä–∞–∑–¥–µ–ª–æ–≤
        explanation_parts = []
        for section in relevant_sections[:2]:
            content = section['content']
            if len(content) > 100:
                explanation_parts.append(content[:200] + "...")
        
        explanation = " ".join(explanation_parts) if explanation_parts else f"–¢–µ–º–∞ '{topic}' —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è –≤ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ –ø–æ —Ü–∏—Ñ—Ä–æ–≤–æ–π –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç–∏."
    
    return explanation

def create_detailed_explanation(topic, section, correct_idx):
    """–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø–æ—è—Å–Ω–µ–Ω–∏—è –¥–ª—è –æ—Ç–≤–µ—Ç–∞"""
    section_preview = section['content'][:150] + "..." if len(section['content']) > 150 else section['content']
    
    explanations = [
        f"‚úÖ –≠—Ç–æ—Ç –æ—Ç–≤–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π, –ø–æ—Ç–æ–º—É —á—Ç–æ –æ–Ω —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ '{section['title']}' (—Å—Ç—Ä–∞–Ω–∏—Ü–∞ {section['page']}). –í —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ —É–∫–∞–∑–∞–Ω–æ: '{section_preview}'",
        
        f"üìö –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞. –í —Ä–∞–∑–¥–µ–ª–µ '{section['title']}' –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {section['page']} –æ–±—ä—è—Å–Ω—è–µ—Ç—Å—è: '{section_preview}'",
        
        f"üéØ –≠—Ç–æ—Ç –≤–∞—Ä–∏–∞–Ω—Ç –≤–µ—Ä–Ω—ã–π, —Ç–∞–∫ –∫–∞–∫ –æ–Ω —Ç–æ—á–Ω–æ –æ—Ç—Ä–∞–∂–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞. –°–æ–≥–ª–∞—Å–Ω–æ —Ä–∞–∑–¥–µ–ª—É '{section['title']}': '{section_preview}'",
        
        f"üí° –î–∞, —ç—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç! –í —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ –ø–æ —Ü–∏—Ñ—Ä–æ–≤–æ–π –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç–∏ –≤ —Ä–∞–∑–¥–µ–ª–µ '{section['title']}' (—Å—Ç—Ä. {section['page']}) –≥–æ–≤–æ—Ä–∏—Ç—Å—è: '{section_preview}'",
        
        f"üåü –í–µ—Ä–Ω–æ! –≠—Ç–æ—Ç –æ—Ç–≤–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞. –í —Ä–∞–∑–¥–µ–ª–µ '{section['title']}' –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {section['page']} —É–∫–∞–∑–∞–Ω–æ: '{section_preview}'"
    ]
    
    import random
    return random.choice(explanations)



def create_quality_options(question_id, topic, relevant_sections):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ—Ç–≤–µ—Ç–æ–≤"""
    return [
        "–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ",
        "–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç, –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤—É", 
        "–û—à–∏–±–æ—á–Ω–æ–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–µ—Ç –≤ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ",
        "–ù–µ–≤–µ—Ä–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∞—â–∞—è —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤—É"
    ]



def contains_concrete_info(explanation, relevant_sections):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞"""
    if not explanation:
        return False
        
    guide_keywords = set()
    for section in relevant_sections:
        content_lower = section['content'].lower()
        words = set(re.findall(r'\b\w{4,}\b', content_lower))
        guide_keywords.update(words)
    
    explanation_lower = explanation.lower()
    matches = sum(1 for word in guide_keywords if word in explanation_lower)
    
    logger.info(f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∏: {matches} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π —Å —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ–º")
    return matches > 2

def validate_and_fix_quiz(quiz_data, topic, relevant_sections):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–µ—Å—Ç–∞"""
    try:
        required_fields = ['question', 'options', 'correct_answer', 'explanation']
        for field in required_fields:
            if field not in quiz_data:
                raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ: {field}")
        
        if not isinstance(quiz_data['options'], list) or len(quiz_data['options']) != 4:
            quiz_data['options'] = ["–í–∞—Ä–∏–∞–Ω—Ç 1", "–í–∞—Ä–∏–∞–Ω—Ç 2", "–í–∞—Ä–∏–∞–Ω—Ç 3", "–í–∞—Ä–∏–∞–Ω—Ç 4"]
        
        if not isinstance(quiz_data['correct_answer'], int) or not 0 <= quiz_data['correct_answer'] <= 3:
            quiz_data['correct_answer'] = 0
            
        quiz = {
            'id': f'quiz_{hash(topic)}',
            'question': quiz_data['question'],
            'options': quiz_data['options'],
            'correct_answer': quiz_data['correct_answer'],
            'explanation': quiz_data['explanation']
        }
        
        return quiz
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ç–µ—Å—Ç–∞: {e}")
        return create_quality_quiz(topic, relevant_sections)

def create_quality_quiz(topic, relevant_sections):
    """–°–æ–∑–¥–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö"""
    first_section = relevant_sections[0] if relevant_sections else None
    
    if first_section:
        content = first_section['content']
        sentences = re.split(r'[.!?]+', content)
        meaningful_sentences = [s.strip() for s in sentences if len(s.strip()) > 30]
        
        if meaningful_sentences:
            correct_answer = meaningful_sentences[0]
        else:
            correct_answer = content[:100]
        
        quiz = {
            'id': 'quality_quiz',
            'question': f'–ß—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç—Å—è –≤ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ –æ —Ç–µ–º–µ "{topic}"?',
            'options': [
                correct_answer[:80] + "...",
                "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤—É",
                "–≠—Ç–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω–æ–µ –∑–∞–±–ª—É–∂–¥–µ–Ω–∏–µ", 
                "–î–∞–Ω–Ω—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ"
            ],
            'correct_answer': 0,
            'explanation': f'–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ "{first_section["title"]}" —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞.'
        }
    else:
        quiz = {
            'id': 'fallback_quiz',
            'question': f'–í–æ–ø—Ä–æ—Å –ø–æ —Ç–µ–º–µ "{topic}":',
            'options': [
                "–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç",
                "–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç",
                "–û—à–∏–±–æ—á–Ω–æ–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ",
                "–ù–µ–≤–µ—Ä–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"
            ],
            'correct_answer': 0,
            'explanation': '–≠—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–Ω–∞–Ω–∏—è –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–π —Ç–µ–º–µ.'
        }
    
    return quiz



@app.route('/api/debug-sections')
def debug_sections():
    """–û—Ç–ª–∞–¥–æ—á–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤"""
    if not db:
        return jsonify({'error': '–ë–î –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞'}), 500
        
    sections = db.get_guide_sections(limit=10)
    result = []
    
    for section in sections:
        result.append({
            'id': section['id'],
            'title': section['section_title'],
            'content_preview': section['section_content'][:200] + '...',
            'page': section['page_number'],
            'category': section['category'],
            'content_length': len(section['section_content'])
        })
    
    return jsonify({
        'status': 'success',
        'sections_count': len(sections),
        'sections': result
    })

@app.route('/api/debug-topic-search')
def debug_topic_search():
    """–û—Ç–ª–∞–¥–æ—á–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ —Ç–µ–º–µ"""
    topic = request.args.get('topic', '–∫–æ–º–ø—å—é—Ç–µ—Ä')
    
    sections = db.get_guide_sections(limit=20)
    relevant = get_relevant_sections(topic)
    
    result = {
        'topic': topic,
        'total_sections': len(sections),
        'relevant_sections': len(relevant),
        'relevant_details': []
    }
    
    for section in relevant:
        result['relevant_details'].append({
            'title': section['title'],
            'score': section['score'],
            'content_preview': section['content'][:300] + '...',
            'content_length': len(section['content'])
        })
    
    return jsonify(result)



def generate_deep_context_explanation(topic, relevant_sections):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–ª—É–±–æ–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è - –° –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï–ú"""
    
    prompt = f"""
–¢–´ - –≠–ö–°–ü–ï–†–¢-–ü–†–ï–ü–û–î–ê–í–ê–¢–ï–õ–¨ –ü–û –¶–ò–§–†–û–í–û–ô –ì–†–ê–ú–û–¢–ù–û–°–¢–ò. –î–ê–ô –ö–ê–ß–ï–°–¢–í–ï–ù–ù–û–ï –û–ë–™–Ø–°–ù–ï–ù–ò–ï –ü–û –¢–ï–ú–ï: "{topic.upper()}"

–ö–û–ù–ö–†–ï–¢–ù–´–ô –ú–ê–¢–ï–†–ò–ê–õ –ò–ó –†–£–ö–û–í–û–î–°–¢–í–ê:
{format_concrete_sections(relevant_sections)}
–¢–í–û–Ø –ó–ê–î–ê–ß–ê:
–°–û–°–¢–ê–í–¨ –°–¢–†–£–ö–¢–£–†–ò–†–û–í–ê–ù–ù–û–ï –û–ë–™–Ø–°–ù–ï–ù–ò–ï –° –ß–ï–¢–ö–û–ô –°–¢–†–£–ö–¢–£–†–û–ô:

–û—Å–Ω–æ–≤–Ω–∞—è –∫–æ–Ω—Ü–µ–ø—Ü–∏—è:
- –ö—Ä–∞—Ç–∫–æ –æ–±—ä—è—Å–Ω–∏ —Å—É—Ç—å —Ç–µ–º—ã

–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç:
- –û–ø–∏—à–∏ –º–µ—Ö–∞–Ω–∏–∑–º —Ä–∞–±–æ—Ç—ã
- –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞

–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:
- –ö–∞–∫ –∏–º–µ–Ω–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ
- –ü–æ—à–∞–≥–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

–í–∞–∂–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã:
- –ö–ª—é—á–µ–≤—ã–µ –∞—Å–ø–µ–∫—Ç—ã –¥–ª—è –∑–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è
- –ß–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏ –∏ –∫–∞–∫ –∏—Ö –∏–∑–±–µ–∂–∞—Ç—å

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –§–û–†–ú–ê–¢–£:
- –ò—Å–ø–æ–ª—å–∑—É–π –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å –¥–≤–æ–µ—Ç–æ—á–∏–µ–º –≤ –∫–æ–Ω—Ü–µ
- –ò—Å–ø–æ–ª—å–∑—É–π –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏ —á–µ—Ä–µ–∑ –¥–µ—Ñ–∏—Å
- –í—ã–¥–µ–ª—è–π **–≤–∞–∂–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã** –¥–≤–æ–π–Ω—ã–º–∏ –∑–≤–µ–∑–¥–æ—á–∫–∞–º–∏
- –†–∞–∑–¥–µ–ª—è–π –±–ª–æ–∫–∏ –ø—É—Å—Ç—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏
- –î–∞–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞

–û–¢–í–ï–ß–ê–ô –¢–û–õ–¨–ö–û –¢–ï–ö–°–¢–û–ú –û–ë–™–Ø–°–ù–ï–ù–ò–Ø, –±–µ–∑ –≤—Å—Ç—É–ø–ª–µ–Ω–∏–π –∏ –∑–∞–∫–ª—é—á–µ–Ω–∏–π.
"""
    
    try:
        # –£–ë–ï–†–ò–¢–ï max_tokens - —ç—Ç–æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
        response = gigachat_service.client.chat(prompt)
        explanation = response.choices[0].message.content.strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ —É–ª—É—á—à–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
        explanation = enhance_explanation_quality(explanation, topic, relevant_sections)
        
        return explanation
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è: {e}")
        return create_specific_explanation(topic, relevant_sections)

def format_concrete_sections(relevant_sections):
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ö–û–ù–ö–†–ï–¢–ù–´–• —Ä–∞–∑–¥–µ–ª–æ–≤ —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º —Å–º—ã—Å–ª–∞"""
    concrete_parts = []
    
    for i, section in enumerate(relevant_sections[:4], 1):
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —Ç–µ–º–µ
        specific_content = extract_specific_content(section['content'])
        if specific_content:
            concrete_parts.append(f"--- –†–ê–ó–î–ï–õ {i}: {section['title']} ---\n{specific_content}")
    
    return "\n\n".join(concrete_parts) if concrete_parts else "–í —Ä–∞–∑–¥–µ–ª–∞—Ö –µ—Å—Ç—å –æ–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Ç–µ–º–µ."

def extract_specific_content(text):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
    sentences = re.split(r'[.!?]+', text)
    relevant_sentences = []
    
    for sentence in sentences:
        sentence = sentence.strip()
        # –û—Ç–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        if (len(sentence) > 25 and 
            not re.match(r'^[\\d\\s\\-\\.]+$', sentence) and
            '–æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ' not in sentence.lower() and
            '—Å—Ç—Ä–∞–Ω–∏—Ü–∞' not in sentence.lower()):
            relevant_sentences.append(sentence)
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, –Ω–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
    return '. '.join(relevant_sentences[:8]) + '.'

def analyze_topic_specifics(topic, relevant_sections):
    """–ê–Ω–∞–ª–∏–∑ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∏ —Ç–µ–º—ã –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    all_content = " ".join([section['content'] for section in relevant_sections[:3]])
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º, –æ —á–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –≥–æ–≤–æ—Ä–∏—Ç—Å—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Ç–µ–º—ã
    analysis_parts = []
    
    # –ò—â–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è
    usage_patterns = [
        r'–¥–ª—è —á–µ–≥–æ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è|–ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è)[^.!?]*' + re.escape(topic),
        r'–∫–∞–∫ (—Ä–∞–±–æ—Ç–∞–µ—Ç|–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å)[^.!?]*' + re.escape(topic),
        r'—Ñ—É–Ω–∫—Ü–∏–∏[^.!?]*' + re.escape(topic),
        topic + r' (–ø–æ–∑–≤–æ–ª—è–µ—Ç|–Ω—É–∂–µ–Ω|–ø–æ–º–æ–≥–∞–µ—Ç)[^.!?]*'
    ]
    
    for pattern in usage_patterns:
        matches = re.findall(pattern, all_content.lower())
        if matches:
            analysis_parts.append(f"–ù–∞–π–¥–µ–Ω–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: {matches[0][:100]}...")
    
    # –ò—â–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
    instruction_patterns = [
        r'–∫–∞–∫ (–Ω–∞—Å—Ç—Ä–æ–∏—Ç—å|—É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å|–ø–æ–¥–∫–ª—é—á–∏—Ç—å)[^.!?]*' + re.escape(topic),
        r'–ø—Ä–∞–≤–∏–ª–∞?[^.!?]*' + re.escape(topic),
        r'—Å–æ–≤–µ—Ç—ã?[^.!?]*' + re.escape(topic)
    ]
    
    for pattern in instruction_patterns:
        if re.search(pattern, all_content.lower()):
            analysis_parts.append("–ï—Å—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")
            break
    
    return "; ".join(analysis_parts) if analysis_parts else "–û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–µ–º–µ"

def enhance_explanation_quality(explanation, topic, relevant_sections):
    """–£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è"""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É
    if len(explanation) < 150:
        logger.warning("‚ö†Ô∏è –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ, –¥–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª–∏")
        explanation = add_specific_details(explanation, topic, relevant_sections)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫—É
    if not has_specific_details(explanation):
        logger.warning("‚ö†Ô∏è –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –æ–±—â–µ–µ, –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫—É")
        explanation = create_specific_explanation(topic, relevant_sections)
    
    # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
    explanation = clean_text_response(explanation)
    
    return explanation

def has_specific_details(text):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π"""
    # –ò—â–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –≥–ª–∞–≥–æ–ª—ã –∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
    specific_indicators = [
        '–Ω–∞–∂–∞—Ç—å', '–≤—ã–±—Ä–∞—Ç—å', '–ø–µ—Ä–µ—Ç–∞—â–∏—Ç—å', '—â–µ–ª–∫–Ω—É—Ç—å', '–æ—Ç–∫—Ä—ã—Ç—å',
        '–∑–∞–∫—Ä—ã—Ç—å', '–Ω–∞—Å—Ç—Ä–æ–∏—Ç—å', '–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å', '–ø–æ–¥–∫–ª—é—á–∏—Ç—å',
        '–ª–µ–≤–∞—è –∫–Ω–æ–ø–∫–∞', '–ø—Ä–∞–≤–∞—è –∫–Ω–æ–ø–∫–∞', '–∫–æ–ª–µ—Å–∏–∫–æ', '–∫—É—Ä—Å–æ—Ä'
    ]
    
    text_lower = text.lower()
    return any(indicator in text_lower for indicator in specific_indicators)

def add_specific_details(explanation, topic, relevant_sections):
    """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π –∫ –æ–±—ä—è—Å–Ω–µ–Ω–∏—é"""
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ–∞–∫—Ç—ã –∏–∑ —Ä–∞–∑–¥–µ–ª–æ–≤
    specific_facts = extract_specific_facts(topic, relevant_sections)
    
    if specific_facts:
        return explanation + " " + " ".join(specific_facts[:2])
    else:
        return create_specific_explanation(topic, relevant_sections)

def extract_specific_facts(topic, relevant_sections):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ñ–∞–∫—Ç–æ–≤ –ø–æ —Ç–µ–º–µ"""
    facts = []
    
    for section in relevant_sections[:2]:
        content = section['content']
        sentences = re.split(r'[.!?]+', content)
        
        for sentence in sentences:
            sentence = sentence.strip()
            if (len(sentence) > 30 and 
                topic.lower() in sentence.lower() and
                any(keyword in sentence.lower() for keyword in ['–∫–Ω–æ–ø–∫–∞', '–º–µ–Ω—é', '—Ñ–∞–π–ª', '–ø–∞–ø–∫–∞', '–æ–∫–Ω–æ', '—ç–∫—Ä–∞–Ω'])):
                facts.append(sentence)
    
    return facts[:3]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–µ –±–æ–ª–µ–µ 3 —Ñ–∞–∫—Ç–æ–≤

def create_specific_explanation(topic, relevant_sections):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö"""
    if not relevant_sections:
        return f"–í —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è —Ç–µ–º–∞ '{topic}'. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏–∑—É—á–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ä–∞–∑–¥–µ–ª—ã –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."
    
    # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–µ—Ç–∞–ª–∏ –∏–∑ —Ä–∞–∑–¥–µ–ª–æ–≤
    specific_details = []
    
    for section in relevant_sections[:2]:
        # –ò—â–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –¥–µ–π—Å—Ç–≤–∏—è–º–∏
        sentences = re.split(r'[.!?]+', section['content'])
        for sentence in sentences:
            if (topic.lower() in sentence.lower() and 
                len(sentence) > 40 and
                any(verb in sentence.lower() for verb in ['–Ω–∞–∂–∞—Ç—å', '–≤—ã–±—Ä–∞—Ç—å', '–æ—Ç–∫—Ä—ã—Ç—å', '–∑–∞–∫—Ä—ã—Ç—å', '–ø–µ—Ä–µ–π—Ç–∏'])):
                specific_details.append(sentence.strip())
    
    if specific_details:
        base = f"–°–æ–≥–ª–∞—Å–Ω–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤—É, {topic} –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º: "
        return base + " ".join(specific_details[:2])
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Ä–∞–∑–¥–µ–ª–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        sections_context = ", ".join([section['title'] for section in relevant_sections[:2]])
        return f"–¢–µ–º–∞ '{topic}' —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è –≤ —Ä–∞–∑–¥–µ–ª–∞—Ö {sections_context}. –í —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–∞–±–æ—Ç–µ —Å —ç—Ç–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–º."

def clean_text_response(text):
    """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"""
    # –£–±–∏—Ä–∞–µ–º HTML-—Ç–µ–≥–∏
    text = re.sub(r'<[^>]+>', '', text)
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    text = re.sub(r'\s+', ' ', text)
    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–ª–µ–º—ã —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π (–∑–∞–º–µ–Ω—è–µ–º —Å—Ç—Ä–∞–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã)
    text = re.sub(r'[^\w\s–∞-—è–ê-–Ø—ë–Å.,!?;:()-]', '', text)
    return text.strip()

def format_sections_for_deep_analysis(relevant_sections):
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–æ–≤ –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    formatted = []
    for i, section in enumerate(relevant_sections[:3], 1):
        # –ë–µ—Ä–µ–º –±–æ–ª—å—à–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        meaningful_content = extract_meaningful_content(section['content'])
        formatted.append(f"–†–ê–ó–î–ï–õ {i}: {section['title']}\n{meaningful_content}")
    
    return "\n\n" + "="*50 + "\n\n".join(formatted) + "\n" + "="*50

def extract_meaningful_content(text, max_length=800):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    sentences = re.split(r'[.!?]+', text)
    meaningful_sentences = []
    
    for sentence in sentences:
        sentence = sentence.strip()
        # –û—Ç–±–∏—Ä–∞–µ–º —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (–Ω–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∏ –Ω–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –º—É—Å–æ—Ä)
        if (len(sentence) > 20 and 
            not re.match(r'^[\d\s\-\.]+$', sentence) and
            not any(word in sentence.lower() for word in ['–æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ', '—Å—Ç—Ä–∞–Ω–∏—Ü–∞', '–≥–ª–∞–≤–∞'])):
            meaningful_sentences.append(sentence)
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º, –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—è –¥–ª–∏–Ω—É
    result = '. '.join(meaningful_sentences[:15]) + '.'
    if len(result) > max_length:
        result = result[:max_length] + "..."
    
    return result

def clean_explanation_text(text):
    """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –æ—Ç HTML –∏ –ª–∏—à–Ω–µ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    # –£–±–∏—Ä–∞–µ–º HTML-—Ç–µ–≥–∏
    text = re.sub(r'<[^>]+>', '', text)
    # –£–±–∏—Ä–∞–µ–º –º–∞—Ä–∫–µ—Ä—ã JSON
    text = re.sub(r'[{}[\]"]', '', text)
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    text = re.sub(r'\s+', ' ', text)
    # –£–±–∏—Ä–∞–µ–º —Ñ—Ä–∞–∑—ã –ø—Ä–æ JSON
    text = re.sub(r'json\s*:', '', text, flags=re.IGNORECASE)
    
    return text.strip()

def is_low_quality_explanation(explanation):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è"""
    if len(explanation) < 200:
        return True
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–µ —Ñ–∞–∫—Ç–æ–≤ –±–µ–∑ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
    sentences = re.split(r'[.!?]+', explanation)
    if len(sentences) < 5:
        return True
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –≥–ª—É–±–æ–∫–∏—Ö –æ–±—ä—è—Å–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π
    deep_patterns = [
        r'–ø–æ–º–æ–≥–∞–µ—Ç', r'–ø–æ–∑–≤–æ–ª—è–µ—Ç', r'–Ω—É–∂–Ω–æ —á—Ç–æ–±—ã', r'–≤–∞–∂–Ω–æ –ø–æ—Ç–æ–º—É —á—Ç–æ',
        r'–∫–∞–∫ –µ—Å–ª–∏ –±—ã', r'–ø—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ —á—Ç–æ', r'—ç—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞'
    ]
    
    explanation_lower = explanation.lower()
    deep_matches = sum(1 for pattern in deep_patterns if re.search(pattern, explanation_lower))
    
    return deep_matches < 2

def create_quality_context_explanation(topic, relevant_sections):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö"""
    if not relevant_sections:
        return f"–¢–µ–º–∞ '{topic}' —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è –≤ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ –ø–æ —Ü–∏—Ñ—Ä–æ–≤–æ–π –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç–∏. –≠—Ç–æ –≤–∞–∂–Ω—ã–π –∞—Å–ø–µ–∫—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–∂–µ—Ç –≤–∞–º –ª—É—á—à–µ –ø–æ–Ω–∏–º–∞—Ç—å —Ä–∞–±–æ—Ç—É —Å –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã–º–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è–º–∏."
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
    context_keywords = analyze_context_keywords(relevant_sections, topic)
    
    if context_keywords:
        explanation = f"–í —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ —Ç–µ–º–∞ '{topic}' —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ {context_keywords['primary_context']}. "
        explanation += f"–û—Å–Ω–æ–≤–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ —É–¥–µ–ª—è–µ—Ç—Å—è {context_keywords['key_aspects']}. "
        explanation += f"–≠—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º {context_keywords['practical_benefit']}. "
        explanation += "–ü–æ–Ω–∏–º–∞–Ω–∏–µ —ç—Ç–æ–π —Ç–µ–º—ã —Å–¥–µ–ª–∞–µ—Ç —Ä–∞–±–æ—Ç—É —Å –∫–æ–º–ø—å—é—Ç–µ—Ä–æ–º –±–æ–ª–µ–µ –∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ–π –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π."
    else:
        explanation = f"–¢–µ–º–∞ '{topic}' - –≤–∞–∂–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç —Ü–∏—Ñ—Ä–æ–≤–æ–π –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç–∏. –í —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é —ç—Ç–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –≤ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö, —á—Ç–æ –ø–æ–º–æ–∂–µ—Ç –≤–∞–º —Å—Ç–∞—Ç—å –±–æ–ª–µ–µ —É–≤–µ—Ä–µ–Ω–Ω—ã–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º."
    
    return explanation

def analyze_context_keywords(relevant_sections, topic):
    """–ê–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    all_content = " ".join([section['content'] for section in relevant_sections[:2]])
    content_lower = all_content.lower()
    
    # –ò—â–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    patterns = {
        'primary_context': find_primary_context(content_lower, topic),
        'key_aspects': find_key_aspects(content_lower, topic),
        'practical_benefit': find_practical_benefit(content_lower, topic)
    }
    
    return patterns

def find_primary_context(content, topic):
    """–ü–æ–∏—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    context_indicators = [
        r'–¥–ª—è\s+\w+\s+–Ω—É–∂–Ω–æ', r'–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è\s+–¥–ª—è', r'–ø–æ–∑–≤–æ–ª—è–µ—Ç',
        r'—Å\s+–ø–æ–º–æ—â—å—é', r'–ø—Ä–∏\s+—Ä–∞–±–æ—Ç–µ'
    ]
    
    for indicator in context_indicators:
        matches = re.findall(f"{indicator}[^.!?]*{topic}[^.!?]*[.!?]", content)
        if matches:
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∏ –æ—á–∏—â–∞–µ–º
            match = matches[0]
            return clean_context_phrase(match)
    
    return "—Ä–∞–±–æ—Ç—ã —Å –∫–æ–º–ø—å—é—Ç–µ—Ä–æ–º"

def find_key_aspects(content, topic):
    """–ü–æ–∏—Å–∫ –∫–ª—é—á–µ–≤—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤"""
    # –ò—â–µ–º –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—è –∏ —Å–ø–∏—Å–∫–∏
    list_indicators = [r'–≤–æ-–ø–µ—Ä–≤—ã—Ö[^.!?]*', r'—Ç–∞–∫–∂–µ[^.!?]*', r'–∫—Ä–æ–º–µ —Ç–æ–≥–æ[^.!?]*']
    
    aspects = []
    for indicator in list_indicators:
        pattern = f"{indicator}[^.!?]*{topic}[^.!?]*[.!?]"
        matches = re.findall(pattern, content)
        for match in matches:
            aspect = clean_context_phrase(match)
            if aspect and aspect not in aspects:
                aspects.append(aspect)
    
    if aspects:
        return ", ".join(aspects[:2])
    
    return "–æ—Å–Ω–æ–≤–Ω—ã–º –ø—Ä–∏–Ω—Ü–∏–ø–∞–º –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–º—É –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é"

def find_practical_benefit(content, topic):
    """–ü–æ–∏—Å–∫ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π –ø–æ–ª—å–∑—ã"""
    benefit_indicators = [
        r'–ø–æ–º–æ–≥–∞–µ—Ç[^.!?]*', r'—É–ø—Ä–æ—â–∞–µ—Ç[^.!?]*', r'—É—Å–∫–æ—Ä—è–µ—Ç[^.!?]*',
        r'–ø–æ–∑–≤–æ–ª—è–µ—Ç[^.!?]*', r'–¥–∞–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å[^.!?]*'
    ]
    
    for indicator in benefit_indicators:
        pattern = f"{indicator}[^.!?]*{topic}[^.!?]*[.!?]"
        matches = re.findall(pattern, content)
        if matches:
            benefit = clean_context_phrase(matches[0])
            return benefit.replace(topic, "—ç—Ç–æ–≥–æ")
    
    return "—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —Ä–µ—à–∞—Ç—å –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏"

def clean_context_phrase(phrase):
    """–û—á–∏—Å—Ç–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π —Ñ—Ä–∞–∑—ã"""
    phrase = re.sub(r'\s+', ' ', phrase)
    phrase = phrase.strip()
    # –£–±–∏—Ä–∞–µ–º —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã
    if len(phrase) > 100:
        words = phrase.split()
        return ' '.join(words[:15]) + '...'
    return phrase



@app.route('/api/status')
def status():
    """–°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã"""
    sections_count = 0
    if db:
        try:
            sections = db.get_guide_sections(limit=1)
            sections_count = len(sections)
        except:
            sections_count = 0
    
    return jsonify({
        'status': 'running',
        'gigachat_available': GIGACHAT_AVAILABLE,
        'sections_loaded': sections_count
    })

def initialize_system():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã - –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ô –ü–ê–†–°–ò–ù–ì –í–°–ï–• –£–ß–ï–ë–ù–ò–ö–û–í"""
    logger.info("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã —Ç—Ä–µ–Ω–∞–∂–µ—Ä–∞...")
    
    Config.init_directories()
    
    # –ü–†–Ø–ú–ê–Ø –ü–†–û–í–ï–†–ö–ê –í–°–ï–• –§–ê–ô–õ–û–í
    guide_files = Config.GUIDE_FILES
    logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—á–µ–±–Ω–∏–∫–æ–≤:")
    
    for guide_file in guide_files:
        guide_path = f"guide/{guide_file}"
        exists = os.path.exists(guide_path)
        logger.info(f"   - {guide_file}: {exists} ({os.path.abspath(guide_path)})")
    
    if db:
        db.init_db()
        
        from services.pdf_parser import GuideParser
        parser = GuideParser()
        
        # –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ô –ü–ê–†–°–ò–ù–ì –í–°–ï–• PDF
        logger.info("üîÑ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö —É—á–µ–±–Ω–∏–∫–æ–≤...")
        db.clear_guide_data()  # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
        
        sections_count = parser.parse_all_guides()
        
        if sections_count > 0:
            logger.info(f"‚úÖ –í—Å–µ —É—á–µ–±–Ω–∏–∫–∏ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω—ã: {sections_count} —Å—Ç—Ä–∞–Ω–∏—Ü")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            sections = db.get_guide_sections(limit=10)
            total_sections = len(db.get_guide_sections(limit=1000))
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —É—á–µ–±–Ω–∏–∫–∞–º
            sources = {}
            for section in sections:
                source = section['guide_source'] if 'guide_source' in section.keys() else 'unknown'
                if source not in sources:
                    sources[source] = 0
                sources[source] += 1
            
            logger.info(f"üìñ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ë–î: –∑–∞–≥—Ä—É–∂–µ–Ω–æ —Ä–∞–∑–¥–µ–ª–æ–≤ –≤—Å–µ–≥–æ: {total_sections}")
            logger.info(f"üìö –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —É—á–µ–±–Ω–∏–∫–∞–º: {sources}")
                
            # –¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
            test_sections = get_relevant_sections("–∫–æ–º–ø—å—é—Ç–µ—Ä")
            logger.info(f"üîç –¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ '–∫–æ–º–ø—å—é—Ç–µ—Ä': –Ω–∞–π–¥–µ–Ω–æ {len(test_sections)} —Ä–∞–∑–¥–µ–ª–æ–≤")
        else:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å —É—á–µ–±–Ω–∏–∫–∏")
    
    logger.info("‚úÖ –°–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")



@app.route('/api/learn-topic', methods=['POST'])
def learn_topic():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è - –° –ü–†–û–í–ï–†–ö–û–ô –û–ü–ï–ß–ê–¢–û–ö"""
    if not GIGACHAT_AVAILABLE:
        return jsonify({'status': 'error', 'error': 'GigaChat –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω'}), 503

    try:
        data = request.get_json()
        original_topic = data.get('topic', '').strip()
        
        if not original_topic:
            return jsonify({'status': 'error', 'error': '–¢–µ–º–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç–æ–π'}), 400

        logger.info(f"üéØ –ó–∞–ø—Ä–æ—Å –Ω–∞ –∏–∑—É—á–µ–Ω–∏–µ —Ç–µ–º—ã: '{original_topic}'")

        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –æ–ø–µ—á–∞—Ç–∫–∏
        if spell_checker:
            corrected_topic, was_corrected = spell_checker.correct_spelling(original_topic)
            correction_message = spell_checker.format_correction_message(original_topic, corrected_topic, was_corrected)
        else:
            corrected_topic = original_topic
            was_corrected = False
            correction_message = ""

        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã –ø–æ –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ô —Ç–µ–º–µ
        relevant_sections = get_relevant_sections(corrected_topic)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–∫—Ä—ã—Ç–∏–µ —É—á–µ–±–Ω–∏–∫–æ–≤
        try:
            textbook_ok, coverage_info = check_textbook_coverage(corrected_topic, relevant_sections)
            use_external = not textbook_ok
        except Exception as e:
           
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–∫—Ä—ã—Ç–∏—è —É—á–µ–±–Ω–∏–∫–æ–≤: {e}")
           
            textbook_ok, coverage_info = False, f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}"
            use_external = True

        logger.info(f"üìö –ü–æ–∫—Ä—ã—Ç–∏–µ —É—á–µ–±–Ω–∏–∫–æ–≤: {coverage_info}")
        logger.info(f"üîç –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤–Ω–µ—à–Ω–∏—Ö –∑–Ω–∞–Ω–∏–π: {use_external}")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ô —Ç–µ–º–µ
        explanation = generate_contextual_theory(corrected_topic, relevant_sections)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        
        if not has_proper_paragraphs(explanation):
            explanation = format_beautiful_text(explanation, corrected_topic)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º
        full_explanation = correction_message + explanation
        
        logger.info(f"‚úÖ –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ: {len(explanation)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        return jsonify({
            'status': 'success',
            'explanation': full_explanation,
            'correction_info': {
                'was_corrected': was_corrected,
                'original_topic': original_topic,
                'corrected_topic': corrected_topic
            },
            'sources_used': {
                'textbooks': len(relevant_sections) > 0,
                'external_knowledge': use_external,
                'coverage_info': coverage_info,
                'sections_found': len(relevant_sections)
            }
        })

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è: {e}", exc_info=True)
        return jsonify({'status': 'error', 'error': '–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è'}), 500

spell_checker = None
if GIGACHAT_AVAILABLE:
    spell_checker = SpellChecker(gigachat_service)
    logger.info("‚úÖ SpellChecker –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
else:
    logger.warning("‚ö†Ô∏è SpellChecker –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - GigaChat –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

if __name__ == '__main__':
    initialize_system()
    
    logger.info("üöÄ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ç—Ä–µ–Ω–∞–∂–µ—Ä –∑–∞–ø—É—â–µ–Ω!")
    logger.info("üîç –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å: http://localhost:5000/")
    
    app.run(debug=True, host='0.0.0.0', port=5000, use_reloader=False)