from flask import Flask, render_template, request, jsonify
import os
import json
import logging
import re
import ast
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

from config import Config
from services.gigachat_service import GigaChatService
from database.db_connection import Database

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
app.config['SECRET_KEY'] = 'digital-trainer-secret-2024'
app.config.from_object(Config)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–æ–≤
try:
    gigachat_service = GigaChatService()
    db = Database()
    GIGACHAT_AVAILABLE = True
    logger.info("‚úÖ GigaChat –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ")
except Exception as e:
    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ GigaChat: {e}")
    GIGACHAT_AVAILABLE = False
    gigachat_service = None
    db = None

# –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ç–µ–º—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –≤—ã–±–æ—Ä–∞
POPULAR_TOPICS = [
    "–∫–æ–º–ø—å—é—Ç–µ—Ä", "–∏–Ω—Ç–µ—Ä–Ω–µ—Ç", "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å", "–∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞", "–º—ã—à—å",
    "–ø—Ä–æ–≥—Ä–∞–º–º—ã", "—Ñ–∞–π–ª—ã", "–ø–∞–ø–∫–∏", "—ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –ø–æ—á—Ç–∞", "—Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–µ—Ç–∏",
    "–ø–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏", "–æ–Ω–ª–∞–π–Ω-–ø–æ–∫—É–ø–∫–∏", "–±–∞–Ω–∫–æ–≤—Å–∫–∏–µ –∫–∞—Ä—Ç—ã", "–ø–∞—Ä–æ–ª–∏",
    "–∞–Ω—Ç–∏–≤–∏—Ä—É—Å", "Wi-Fi", "–±—Ä–∞—É–∑–µ—Ä", "—Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ä–µ–¥–∞–∫—Ç–æ—Ä", "—Ç–∞–±–ª–∏—Ü—ã"
]

@app.route('/')
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Ç—Ä–µ–Ω–∞–∂–µ—Ä–∞"""
    return render_template('index.html', 
                         GIGACHAT_AVAILABLE=GIGACHAT_AVAILABLE,
                         POPULAR_TOPICS=POPULAR_TOPICS)

@app.route('/api/generate-full-test', methods=['POST'])
def generate_full_test():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ –∏–∑ 5 –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ —Ç–µ–º–µ"""
    if not GIGACHAT_AVAILABLE:
        return jsonify({
            'status': 'error',
            'error': 'GigaChat –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω'
        }), 503

    try:
        data = request.get_json()
        topic = data.get('topic', '').strip()
        
        if not topic:
            return jsonify({
                'status': 'error',
                'error': '–¢–µ–º–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç–æ–π'
            }), 400

        logger.info(f"üéØ –ó–∞–ø—Ä–æ—Å –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –ø–æ–ª–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ –ø–æ —Ç–µ–º–µ: {topic}")

        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã –∏–∑ –ë–î
        relevant_sections = get_relevant_sections(topic)
        logger.info(f"üìö –ù–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤: {len(relevant_sections)}")
        
        if not relevant_sections:
            return jsonify({
                'status': 'error',
                'error': f'–í —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —Ç–µ–º–µ "{topic}". –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é —Ç–µ–º—É.'
            })

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –ø–æ–¥—Ö–æ–¥–æ–º
        test_data = generate_contextual_test(topic, relevant_sections)
        
        logger.info(f"‚úÖ –ü–æ–ª–Ω—ã–π —Ç–µ—Å—Ç —Å–æ–∑–¥–∞–Ω: {len(test_data['questions'])} –≤–æ–ø—Ä–æ—Å–æ–≤")
        
        return jsonify({
            'status': 'success',
            'test_data': test_data
        })

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞: {e}")
        return jsonify({
            'status': 'error',
            'error': '–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ç–µ—Å—Ç–∞'
        }), 500

def generate_contextual_test(topic, relevant_sections):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º"""
    # –°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–µ–º —Ç–µ–æ—Ä–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    theory = generate_contextual_theory(topic, relevant_sections)
    
    # –ó–∞—Ç–µ–º –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤–æ–ø—Ä–æ—Å—ã —Å –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    questions = generate_contextual_questions(topic, relevant_sections, theory)
    
    return {
        'topic': topic,
        'theory': theory,
        'questions': questions
    }

def generate_contextual_questions(topic, relevant_sections, theory):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ —Ç–µ–º–µ - –¢–ï–ü–ï–†–¨ 5 –í–û–ü–†–û–°–û–í"""
    try:
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤–æ–ø—Ä–æ—Å—ã —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤
        understanding_questions = generate_question_batch(topic, relevant_sections, theory, "understanding", 3)
        application_questions = generate_question_batch(topic, relevant_sections, theory, "application", 2)
        
        questions = understanding_questions + application_questions
        
        # –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –¥–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ
        if len(questions) < 5:
            logger.warning(f"‚ö†Ô∏è –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —Ç–æ–ª—å–∫–æ {len(questions)} –≤–æ–ø—Ä–æ—Å–æ–≤, –¥–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ")
            for i in range(len(questions), 5):
                questions.append(create_meaningful_question(i, topic, relevant_sections))
        
        return questions[:5]  # –í—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º 5 –≤–æ–ø—Ä–æ—Å–æ–≤
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤: {e}")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã
        return [create_meaningful_question(i, topic, relevant_sections) for i in range(5)]

def generate_test_step_by_step(topic, relevant_sections):
    """–ü–æ—ç—Ç–∞–ø–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–∞ - —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥ - –¢–ï–ü–ï–†–¨ 5 –í–û–ü–†–û–°–û–í"""
    logger.info(f"üîÑ –ü–æ—ç—Ç–∞–ø–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–∞ –ø–æ —Ç–µ–º–µ: {topic}")
    
    try:
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ–æ—Ä–∏—é
        theory = generate_contextual_theory(topic, relevant_sections)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤–æ–ø—Ä–æ—Å—ã –ø–æ—ç—Ç–∞–ø–Ω–æ
        questions = []
        
        # –ü–µ—Ä–≤–∞—è –ø–∞—Ä—Ç–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤
        try:
            batch1 = generate_question_batch(topic, relevant_sections, theory, "understanding", 3)
            questions.extend(batch1)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–≤–æ–π –ø–∞—Ä—Ç–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤: {e}")
            for i in range(len(questions), len(questions) + 3):
                questions.append(create_meaningful_question(i, topic, relevant_sections))
        
        # –í—Ç–æ—Ä–∞—è –ø–∞—Ä—Ç–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤
        try:
            batch2 = generate_question_batch(topic, relevant_sections, theory, "application", 2)
            questions.extend(batch2)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—Ç–æ—Ä–æ–π –ø–∞—Ä—Ç–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤: {e}")
            for i in range(len(questions), len(questions) + 2):
                questions.append(create_meaningful_question(i, topic, relevant_sections))
        
        # –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º —Ä–æ–≤–Ω–æ 5 –≤–æ–ø—Ä–æ—Å–æ–≤
        if len(questions) > 5:
            questions = questions[:5]
        elif len(questions) < 5:
            for i in range(len(questions), 5):
                questions.append(create_meaningful_question(i, topic, relevant_sections))
        
        return {
            'topic': topic,
            'theory': theory,
            'questions': questions
        }
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ—ç—Ç–∞–ø–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        # –ü–æ–ª–Ω–æ—Å—Ç—å—é —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥
        return create_quality_full_test(topic, relevant_sections)

def generate_contextual_theory(topic, relevant_sections):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–π —Å–ø—Ä–∞–≤–∫–∏ —Å –∞–Ω–∞–ª–∏–∑–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    prompt = f"""
–ü–†–û–ê–ù–ê–õ–ò–ó–ò–†–£–ô –°–û–î–ï–†–ñ–ê–ù–ò–ï –†–£–ö–û–í–û–î–°–¢–í–ê –ò –°–û–°–¢–ê–í–¨ –ö–†–ê–¢–ö–£–Æ –¢–ï–û–†–ï–¢–ò–ß–ï–°–ö–£–Æ –°–ü–†–ê–í–ö–£ –ü–û –¢–ï–ú–ï: "{topic}"

–ò–°–•–û–î–ù–´–ô –¢–ï–ö–°–¢ –ò–ó –†–£–ö–û–í–û–î–°–¢–í–ê:
{format_sections_for_analysis(relevant_sections)}

–ó–ê–î–ê–ß–ê:
1. –ü–†–û–ß–ò–¢–ê–ô –∏ –ü–û–ù–Ø–¢–¨ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∫–∞–∂–¥–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞
2. –í–´–î–ï–õ–ò –æ—Å–Ω–æ–≤–Ω—ã–µ –∏–¥–µ–∏ –∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –ø–æ —Ç–µ–º–µ "{topic}"
3. –°–û–°–¢–ê–í–¨ —Å–≤—è–∑–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ (5-7 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π), –∫–æ—Ç–æ—Ä–æ–µ:
   - –û–±—ä—è—Å–Ω—è–µ—Ç –°–£–¢–¨ —Ç–µ–º—ã, –∞ –Ω–µ –ø–µ—Ä–µ—á–∏—Å–ª—è–µ—Ç —Ñ–∞–∫—Ç—ã
   - –°–≤—è–∑—ã–≤–∞–µ—Ç —Ä–∞–∑–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã —Ç–µ–º—ã –º–µ–∂–¥—É —Å–æ–±–æ–π
   - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ï–°–¢–ï–°–¢–í–ï–ù–ù–´–ô —è–∑—ã–∫ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
   - –ü–æ–º–æ–≥–∞–µ—Ç –ø–æ–Ω—è—Ç—å, –ö–ê–ö –ø—Ä–∏–º–µ–Ω—è—Ç—å –∑–Ω–∞–Ω–∏—è –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ

–ü–†–ò–ú–ï–† –ü–õ–û–•–û–ì–û –û–ë–™–Ø–°–ù–ï–ù–ò–Ø (–ù–ï –î–ï–õ–ê–ô –¢–ê–ö):
"–ö–æ–º–ø—å—é—Ç–µ—Ä —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞, –º–æ–Ω–∏—Ç–æ—Ä–∞, –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã. –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. –ú–æ–Ω–∏—Ç–æ—Ä –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é."

–ü–†–ò–ú–ï–† –•–û–†–û–®–ï–ì–û –û–ë–™–Ø–°–ù–ï–ù–ò–Ø (–î–ï–õ–ê–ô –¢–ê–ö):
"–ö–æ–º–ø—å—é—Ç–µ—Ä - —ç—Ç–æ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ, –∫–æ—Ç–æ—Ä–æ–µ –ø–æ–º–æ–≥–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∑–∞–¥–∞—á–∏. –° –µ–≥–æ –ø–æ–º–æ—â—å—é –º–æ–∂–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏, –∏—Å–∫–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –∏ –æ–±—â–∞—Ç—å—Å—è —Å –ª—é–¥—å–º–∏. –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∫–æ–º–ø—å—é—Ç–µ—Ä–∞ —Ä–∞–±–æ—Ç–∞—é—Ç –≤–º–µ—Å—Ç–µ: –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ, –º–æ–Ω–∏—Ç–æ—Ä –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –∞ –∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –∏ –º—ã—à—å –ø–æ–∑–≤–æ–ª—è—é—Ç —É–ø—Ä–∞–≤–ª—è—Ç—å –ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏. –ü–æ–Ω–∏–º–∞–Ω–∏–µ —ç—Ç–∏—Ö –æ—Å–Ω–æ–≤ –ø–æ–º–æ–≥–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–º–ø—å—é—Ç–µ—Ä –≤ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–æ–π –∂–∏–∑–Ω–∏."

–§–û–†–ú–ê–¢: –ü—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç –æ–±—ä—è—Å–Ω–µ–Ω–∏—è, –±–µ–∑ JSON –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤.
"""
    
    try:
        response = gigachat_service.client.chat(prompt)
        theory = response.choices[0].message.content.strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Ç–µ–æ—Ä–∏–∏
        if len(theory) < 100 or is_low_quality_theory(theory):
            theory = create_meaningful_theory(topic, relevant_sections)
            
        return theory
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–æ—Ä–∏–∏: {e}")
        return create_meaningful_theory(topic, relevant_sections)

def generate_contextual_test(topic, relevant_sections):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º - —É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è"""
    logger.info(f"üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–∞ –ø–æ —Ç–µ–º–µ '{topic}'...")
    
    try:
        # –ü—ã—Ç–∞–µ–º—Å—è –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥
        theory = generate_contextual_theory(topic, relevant_sections)
        questions = generate_contextual_questions(topic, relevant_sections, theory)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤
        quality_questions = [q for q in questions if validate_question_quality(q)]
        
        if len(quality_questions) < 5:  # –ï—Å–ª–∏ –º–∞–ª–æ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
            logger.warning("‚ö†Ô∏è –ú–∞–ª–æ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—é –ø–æ—ç—Ç–∞–ø–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é")
            return generate_test_step_by_step(topic, relevant_sections)
        
        return {
            'topic': topic,
            'theory': theory,
            'questions': quality_questions[:10]
        }
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –º–µ—Ç–æ–¥–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥
        return generate_test_step_by_step(topic, relevant_sections)

def generate_question_batch(topic, relevant_sections, theory, question_type, count):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∞—Ä—Ç–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞ - –° –£–õ–£–ß–®–ï–ù–ù–´–ú–ò –ü–û–Ø–°–ù–ï–ù–ò–Ø–ú–ò"""
    prompt = f"""
–°–û–ó–î–ê–ô {count} –ö–ê–ß–ï–°–¢–í–ï–ù–ù–´–• –í–û–ü–†–û–°–û–í –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –ü–û–ù–ò–ú–ê–ù–ò–Ø –¢–ï–ú–´: "{topic}"

–¢–ï–û–†–ï–¢–ò–ß–ï–°–ö–ê–Ø –°–ü–†–ê–í–ö–ê:
{theory}

–¢–ò–ü –í–û–ü–†–û–°–û–í: {question_type.upper()}
{"- –í–æ–ø—Ä–æ—Å—ã –Ω–∞ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Å—É—Ç–∏ –∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π" if question_type == "understanding" else "- –í–æ–ø—Ä–æ—Å—ã –Ω–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∑–Ω–∞–Ω–∏–π –≤ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —Å–∏—Ç—É–∞—Ü–∏—è—Ö"}

–í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:
1. –í–û–ó–í–†–ê–©–ê–ô –¢–û–õ–¨–ö–û –í–ê–õ–ò–î–ù–´–ô JSON –ë–ï–ó –õ–Æ–ë–´–• –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–• –¢–ï–ö–°–¢–û–í
2. correct_answer –î–û–õ–ñ–ï–ù –ë–´–¢–¨ –ß–ò–°–õ–û–ú –æ—Ç 0 –¥–æ 3
3. options –î–û–õ–ñ–ï–ù –°–û–î–ï–†–ñ–ê–¢–¨ –†–û–í–ù–û 4 –í–ê–†–ò–ê–ù–¢–ê
4. –û–±—ä—è—Å–Ω–µ–Ω–∏–µ (explanation) –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–º –∏ –ø–æ–ª–µ–∑–Ω—ã–º –¥–ª—è –æ–±—É—á–µ–Ω–∏—è

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –û–ë–™–Ø–°–ù–ï–ù–ò–Ø–ú:
- –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –ø–æ–º–æ—á—å –ø–æ–Ω—è—Ç—å, –ü–û–ß–ï–ú–£ –æ—Ç–≤–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π
- –£–∫–∞–∂–∏—Ç–µ, –ö–ê–ö–ò–ï –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –∑–Ω–∞–Ω–∏—è –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç –æ—Ç–≤–µ—Ç
- –î–∞–π—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é —Ü–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —Ç–µ–º–µ
- –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–æ–Ω—è—Ç–Ω—ã–º –∏ –æ–±—É—á–∞—é—â–∏–º

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (–¢–û–õ–¨–ö–û JSON):
{{
    "questions": [
        {{
            "question": "–¢–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞...",
            "options": ["–í–∞—Ä–∏–∞–Ω—Ç 1", "–í–∞—Ä–∏–∞–Ω—Ç 2", "–í–∞—Ä–∏–∞–Ω—Ç 3", "–í–∞—Ä–∏–∞–Ω—Ç 4"],
            "correct_answer": 0,
            "explanation": "–î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –ø–æ–º–æ–∂–µ—Ç –ø–æ–Ω—è—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª. –£–∫–∞–∂–∏—Ç–µ, –ø–æ—á–µ–º—É —ç—Ç–æ—Ç –æ—Ç–≤–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∏ –∫–∞–∫–∏–µ –∑–Ω–∞–Ω–∏—è –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞ –µ–≥–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç."
        }}
    ]
}}

–ù–ï –î–û–ë–ê–í–õ–Ø–ô –ö–û–ú–ú–ï–ù–¢–ê–†–ò–ò, –û–ë–™–Ø–°–ù–ï–ù–ò–Ø –ò–õ–ò –î–†–£–ì–û–ô –¢–ï–ö–°–¢ –í–ù–ï JSON –°–¢–†–£–ö–¢–£–†–´!
"""
    
    try:
        response = gigachat_service.client.chat(prompt)
        content = response.choices[0].message.content
        
        # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ markdown-–æ–±–µ—Ä—Ç–∫–∏
        content = re.sub(r'^```json\s*', '', content)
        content = re.sub(r'\s*```$', '', content)
        
        return parse_questions_json(content)
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤ —Ç–∏–ø–∞ {question_type}: {e}")
        return []

def format_sections_for_analysis(relevant_sections):
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    formatted = []
    for i, section in enumerate(relevant_sections[:3], 1):
        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        clean_content = clean_text_for_context(section['content'])
        formatted.append(f"–†–ê–ó–î–ï–õ {i}: {section['title']}\n{clean_content}")
    
    return "\n\n".join(formatted)

def clean_text_for_context(text):
    """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    # –£–±–∏—Ä–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã, –æ—Å—Ç–∞–≤–ª—è–µ–º —Å–º—ã—Å–ª–æ–≤–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
    lines = text.split('\n')
    clean_lines = []
    
    for line in lines:
        line = line.strip()
        # –£–±–∏—Ä–∞–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ (–≤–æ–∑–º–æ–∂–Ω–æ, –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã)
        if len(line) < 10:
            continue
        # –£–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏, —Å–æ—Å—Ç–æ—è—â–∏–µ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –∏–∑ —Ü–∏—Ñ—Ä –∏ —Å–∏–º–≤–æ–ª–æ–≤
        if re.match(r'^[\d\s\.\-]+$', line):
            continue
        # –£–±–∏—Ä–∞–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Ñ—Ä–∞–∑—ã
        if line in clean_lines:
            continue
            
        clean_lines.append(line)
    
    return ' '.join(clean_lines[:500])  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É

def parse_questions_json(content):
    """–ü–∞—Ä—Å–∏–Ω–≥ JSON —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ - –£–õ–£–ß–®–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
    try:
        # –û—á–∏—â–∞–µ–º JSON –±–æ–ª–µ–µ —Ç—â–∞—Ç–µ–ª—å–Ω–æ
        cleaned = clean_json_string(content)
        
        # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ markdown-–±–ª–æ–∫–∏ –∫–æ–¥–∞
        cleaned = re.sub(r'```json\s*', '', cleaned)
        cleaned = re.sub(r'```\s*', '', cleaned)
        
        # –ò—â–µ–º JSON —Å—Ç—Ä—É–∫—Ç—É—Ä—É - –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π –º–µ—Ç–æ–¥
        json_pattern = r'\{(?:[^{}]|(?:\{(?:[^{}]|(?:\{[^{}]*\}))*\}))*\}'
        matches = re.findall(json_pattern, cleaned, re.DOTALL)
        
        if not matches:
            logger.warning("‚ùå JSON —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –æ—Ç–≤–µ—Ç–µ")
            return []
            
        # –ü—Ä–æ–±—É–µ–º –∫–∞–∂–¥—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π JSON
        for json_str in matches:
            try:
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
                json_str = json_str.strip()
                if not json_str.startswith('{'):
                    continue
                    
                data = json.loads(json_str)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                if 'questions' in data and isinstance(data['questions'], list):
                    questions = data['questions']
                    validated_questions = []
                    
                    for i, q in enumerate(questions):
                        if validate_question_quality(q):
                            validated_questions.append({
                                'id': i,
                                'question': q['question'],
                                'options': q['options'][:4],  # –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º 4 –≤–∞—Ä–∏–∞–Ω—Ç–∞
                                'correct_answer': min(q.get('correct_answer', 0), 3),  # –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∏–Ω–¥–µ–∫—Å
                                'explanation': q.get('explanation', '–û–±—ä—è—Å–Ω–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞.')
                            })
                    
                    logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–æ {len(validated_questions)} –≤–æ–ø—Ä–æ—Å–æ–≤")
                    return validated_questions
                    
            except json.JSONDecodeError as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON: {e}")
                continue
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ JSON: {e}")
                continue
        
        logger.error("‚ùå –ù–∏ –æ–¥–∏–Ω JSON –Ω–µ –ø—Ä–æ—à–µ–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é")
        return []
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤–æ–ø—Ä–æ—Å–æ–≤: {e}")
        return []

def validate_question_quality(question):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –≤–æ–ø—Ä–æ—Å–∞"""
    if not isinstance(question, dict):
        return False
        
    required = ['question', 'options']
    if not all(field in question for field in required):
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤–æ–ø—Ä–æ—Å –Ω–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
    if len(question['question']) < 10:
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤
    options = question['options']
    if not isinstance(options, list) or len(options) != 4:
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ä–∞–∑–Ω—ã–µ
    if len(set(options)) < 3:
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤–æ–ø—Ä–æ—Å –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π (–Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
    if is_meaningless_question(question['question']):
        return False
        
    return True

def is_meaningless_question(question):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –≤–æ–ø—Ä–æ—Å –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã–º"""
    meaningless_patterns = [
        r'—Å–∫–æ–ª—å–∫–æ.*–∫–Ω–æ–ø–æ–∫',
        r'–∫–∞–∫–æ–≥–æ.*—Ü–≤–µ—Ç–∞',
        r'—á—Ç–æ —Ç–∞–∫–æ–µ.*\?$',
        r'–∫–∞–∫ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è.*\?$',
        r'—É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –ª–∏.*\?$'
    ]
    
    question_lower = question.lower()
    for pattern in meaningless_patterns:
        if re.search(pattern, question_lower):
            return True
    
    return False

def is_low_quality_theory(theory):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–π —Å–ø—Ä–∞–≤–∫–∏"""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É
    if len(theory) < 150:
        return True
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–ø–∏—Å–∫–æ–≤ –∏ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–π (–ø—Ä–∏–∑–Ω–∞–∫ –Ω–∏–∑–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞)
    if theory.count('-') > 3 or theory.count('‚Ä¢') > 3:
        return True
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –ø—Ä–æ—Å—Ç–æ –Ω–∞–±–æ—Ä —Ñ–∞–∫—Ç–æ–≤
    sentences = re.split(r'[.!?]+', theory)
    if len(sentences) < 4:
        return True
    
    return False

def create_robust_question_batch(topic, relevant_sections, theory, question_type, count):
    """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–∞–¥–µ–∂–Ω–æ–π –ø–∞—Ä—Ç–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    max_retries = 2
    for attempt in range(max_retries):
        try:
            questions = generate_question_batch(topic, relevant_sections, theory, question_type, count)
            if questions and len(questions) >= count:
                return questions
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
            if attempt == max_retries - 1:
                logger.error(f"‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ —Å–æ–∑–¥–∞–Ω–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤ —Ç–∏–ø–∞ {question_type} –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å")
    
    # –†–µ–∑–µ—Ä–≤–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã
    return [create_meaningful_question(i, topic, relevant_sections) for i in range(count)]

def create_meaningful_theory(topic, relevant_sections):
    """–°–æ–∑–¥–∞–Ω–∏–µ –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–π —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–π —Å–ø—Ä–∞–≤–∫–∏ –≤—Ä—É—á–Ω—É—é"""
    if not relevant_sections:
        return f"–¢–µ–º–∞ '{topic}' —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è –≤ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ –ø–æ —Ü–∏—Ñ—Ä–æ–≤–æ–π –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç–∏. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏–∑—É—á–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ä–∞–∑–¥–µ–ª—ã –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–∞–≤—ã–∫–æ–≤."
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–æ–≤ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
    key_concepts = extract_key_concepts(relevant_sections, topic)
    
    if key_concepts:
        theory = f"–í —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è —Ç–µ–º–∞ '{topic}' –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ {key_concepts[0]}. "
        if len(key_concepts) > 1:
            theory += f"–û—Å–Ω–æ–≤–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ —É–¥–µ–ª—è–µ—Ç—Å—è {', '.join(key_concepts[1:3])}. "
        theory += "–≠—Ç–∏ –∑–Ω–∞–Ω–∏—è –ø–æ–º–æ–≥—É—Ç –≤–∞–º —É–≤–µ—Ä–µ–Ω–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–º–ø—å—é—Ç–µ—Ä –≤ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö."
    else:
        theory = f"–¢–µ–º–∞ '{topic}' –≤–∞–∂–Ω–∞ –¥–ª—è –æ—Å–≤–æ–µ–Ω–∏—è —Ü–∏—Ñ—Ä–æ–≤–æ–π –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç–∏. –í —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –≤ –±—ã—Ç–æ–≤—ã—Ö —Å–∏—Ç—É–∞—Ü–∏—è—Ö."
    
    return theory

def extract_key_concepts(relevant_sections, topic):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–Ω—Ü–µ–ø—Ü–∏–π –∏–∑ —Ä–∞–∑–¥–µ–ª–æ–≤"""
    concepts = set()
    
    for section in relevant_sections[:2]:
        content = section['content'].lower()
        
        # –ò—â–µ–º —Å–º—ã—Å–ª–æ–≤—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
        sentences = re.split(r'[.!?]+', content)
        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) > 30 and topic.lower() in sentence:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–∑—ã
                words = re.findall(r'\b[\w]{5,}\b', sentence)
                if len(words) > 3:
                    concept = ' '.join(words[:3])
                    concepts.add(concept)
    
    return list(concepts)[:5]

def create_meaningful_question(question_id, topic, relevant_sections):
    """–°–æ–∑–¥–∞–Ω–∏–µ –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –≤—Ä—É—á–Ω—É—é"""
    question_types = [
        f"–ö–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å {topic} —Å–æ–≥–ª–∞—Å–Ω–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤—É?",
        f"–ß—Ç–æ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–µ–ª–∞—Ç—å –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å {topic}?",
        f"–ö–∞–∫–æ–π —Å–ø–æ—Å–æ–± —Ä–∞–±–æ—Ç—ã —Å {topic} —Å—á–∏—Ç–∞–µ—Ç—Å—è –Ω–∞–∏–±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–º?",
        f"–ß—Ç–æ –≤–∞–∂–Ω–æ —É—á–∏—Ç—ã–≤–∞—Ç—å –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ {topic}?",
        f"–ö–∞–∫ –∏–∑–±–µ–∂–∞—Ç—å —Ç–∏–ø–∏—á–Ω—ã—Ö –æ—à–∏–±–æ–∫ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å {topic}?",
        f"–î–ª—è —á–µ–≥–æ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {topic}?",
        f"–ß—Ç–æ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º —Ä–∞–±–æ—Ç—ã —Å {topic}?",
        f"–ö–∞–∫ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ {topic} —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ?",
        f"–ß—Ç–æ –¥–µ–ª–∞—Ç—å, –µ—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã —Å {topic}?",
        f"–ö–∞–∫–∏–µ –º–µ—Ä—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –≤–∞–∂–Ω—ã –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å {topic}?"
    ]
    
    question_text = question_types[question_id % len(question_types)]
    
    return {
        'id': question_id,
        'question': question_text,
        'options': [
            "–°–ª–µ–¥–æ–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞",
            "–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π", 
            "–û–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ —Å–ª—É—á–∞–π–Ω—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º",
            "–ü—Ä–µ–∫—Ä–∞—Ç–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ"
        ],
        'correct_answer': 0,
        'explanation': f"–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è—Ö –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞ –ø–æ —Ü–∏—Ñ—Ä–æ–≤–æ–π –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç–∏."
    }

def clean_json_string(json_string):
    """–û—á–∏—Å—Ç–∫–∞ JSON —Å—Ç—Ä–æ–∫–∏"""
    replacements = {
        '‚Äú': '"', '‚Äù': '"', '‚Äû': '"', '¬´': '"', '¬ª': '"',
        '‚Äò': "'", '‚Äô': "'", '`': "'", '¬¥': "'",
        '‚Äú': '"', '‚Äù': '"', '¬´': '"', '¬ª': '"',
        '‚Äò': "'", '‚Äô': "'", '`': "'",
        '¬†': ' ', '\\"': '"', "\\'": "'"
    }
    
    cleaned = json_string
    for wrong, correct in replacements.items():
        cleaned = cleaned.replace(wrong, correct)
    
    return cleaned

def get_relevant_sections(topic):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤ –∏–∑ –ë–î –ø–æ —Ç–µ–º–µ"""
    try:
        sections = db.get_guide_sections(limit=100)
        relevant = []
        
        topic_lower = topic.lower()
        topic_words = [word for word in topic_lower.split() if len(word) > 2]
        
        logger.info(f"üîç –ü–æ–∏—Å–∫ –ø–æ —Ç–µ–º–µ '{topic}': –ø—Ä–æ–≤–µ—Ä—è–µ–º {len(sections)} —Ä–∞–∑–¥–µ–ª–æ–≤")
        
        for section in sections:
            title = section['section_title'].lower()
            content = section['section_content'].lower()
            
            score = 0
            
            # –ü–æ–≤—ã—à–∞–µ–º –≤–µ—Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
            if topic_lower in title:
                score += 20
            if topic_lower in content:
                score += 8
                
            # –£—á–∏—Ç—ã–≤–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
            for word in topic_words:
                if word in title:
                    score += 5
                if word in content:
                    score += 2
            
            # –°–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
            if score >= 1:
                relevant.append({
                    'title': section['section_title'],
                    'content': section['section_content'],
                    'score': score,
                    'page': section['page_number']
                })
        
        relevant.sort(key=lambda x: x['score'], reverse=True)
        
        logger.info(f"üìö –ü–æ —Ç–µ–º–µ '{topic}' –Ω–∞–π–¥–µ–Ω–æ —Ä–∞–∑–¥–µ–ª–æ–≤: {len(relevant)}")
        for section in relevant[:3]:
            logger.info(f"   - '{section['title']}' (score: {section['score']})")
        
        return relevant[:3]
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Ä–∞–∑–¥–µ–ª–æ–≤: {e}")
        return []

@app.route('/api/check-full-test', methods=['POST'])
def check_full_test():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ–≥–æ —Ç–µ—Å—Ç–∞ –∏–∑ 5 –≤–æ–ø—Ä–æ—Å–æ–≤"""
    try:
        data = request.get_json()
        user_answers = data.get('user_answers', [])
        test_data = data.get('test_data', {})
        
        if not user_answers or not test_data:
            return jsonify({'error': '–î–∞–Ω–Ω—ã–µ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã'}), 400
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π –æ—Ç–≤–µ—Ç
        results = []
        correct_count = 0
        
        for i, user_answer in enumerate(user_answers):
            question = test_data['questions'][i]
            is_correct = (user_answer == question['correct_answer'])
            
            if is_correct:
                correct_count += 1
                
            results.append({
                'question_index': i,
                'question': question['question'],
                'options': question['options'],  # –î–æ–±–∞–≤–ª—è–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤
                'user_answer': user_answer,
                'correct_answer': question['correct_answer'],
                'is_correct': is_correct,
                'explanation': question.get('explanation', '–û–±—ä—è—Å–Ω–µ–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')
            })
        
        # –°—á–∏—Ç–∞–µ–º –æ—Ü–µ–Ω–∫—É
        total_questions = len(test_data['questions'])
        score = int((correct_count / total_questions) * 100)
        
        return jsonify({
            'status': 'success',
            'results': results,
            'score': score,
            'correct_count': correct_count,
            'total_questions': total_questions
        })
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞: {e}")
        return jsonify({'error': str(e)}), 500

def get_relevant_sections(topic):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤ –∏–∑ –ë–î –ø–æ —Ç–µ–º–µ - –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
    try:
        sections = db.get_guide_sections(limit=200)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç
        relevant = []
        
        topic_lower = topic.lower()
        topic_words = [word for word in topic_lower.split() if len(word) > 2]
        
        logger.info(f"üîç –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ —Ç–µ–º–µ '{topic}': –ø—Ä–æ–≤–µ—Ä—è–µ–º {len(sections)} —Ä–∞–∑–¥–µ–ª–æ–≤")
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏–Ω–æ–Ω–∏–º—ã –¥–ª—è –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ç–µ–º
        topic_synonyms = get_topic_synonyms(topic)
        all_search_terms = [topic_lower] + topic_synonyms
        
        for section in sections:
            title = section['section_title'].lower()
            content = section['section_content'].lower()
            
            score = 0
            
            # –ü–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º —Ç–µ—Ä–º–∏–Ω–∞–º (–æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–º–µ –∏ —Å–∏–Ω–æ–Ω–∏–º–∞–º)
            for search_term in all_search_terms:
                # –ü–æ–≤—ã—à–∞–µ–º –≤–µ—Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
                if search_term in title:
                    score += 25
                if search_term in content:
                    score += 10
                    
            # –£—á–∏—Ç—ã–≤–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
            for word in topic_words:
                if word in title:
                    score += 8
                if word in content:
                    score += 3
            
            # –°–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –µ—â–µ –±–æ–ª—å—à–µ
            if score >= 1:
                relevant.append({
                    'title': section['section_title'],
                    'content': section['section_content'],
                    'score': score,
                    'page': section['page_number']
                })
        
        relevant.sort(key=lambda x: x['score'], reverse=True)
        
        logger.info(f"üìö –ü–æ —Ç–µ–º–µ '{topic}' –Ω–∞–π–¥–µ–Ω–æ —Ä–∞–∑–¥–µ–ª–æ–≤: {len(relevant)}")
        for section in relevant[:5]:
            logger.info(f"   - '{section['title']}' (score: {section['score']}, {len(section['content'])} chars)")
        
        return relevant[:5]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-5 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Ä–∞–∑–¥–µ–ª–æ–≤: {e}")
        return []

def get_topic_synonyms(topic):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –¥–ª—è —Ç–µ–º—ã"""
    synonyms_map = {
        '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç': ['–∏–Ω—Ç–µ—Ä–Ω–µ—Ç', '—Å–µ—Ç—å', 'online', '–±—Ä–∞—É–∑–µ—Ä', '–≤–µ–±', '—Å–∞–π—Ç', '–ø—Ä–æ–≤–æ–¥–Ω–∏–∫'],
        '–∫–æ–º–ø—å—é—Ç–µ—Ä': ['–∫–æ–º–ø—å—é—Ç–µ—Ä', '–ø–∫', '–Ω–æ—É—Ç–±—É–∫', '—Å–∏—Å—Ç–µ–º–Ω—ã–π –±–ª–æ–∫', '–º–æ–Ω–∏—Ç–æ—Ä'],
        '–º—ã—à—å': ['–º—ã—à—å', '–º—ã—à–∫–∞', '–∫—É—Ä—Å–æ—Ä', '–º–∞–Ω–∏–ø—É–ª—è—Ç–æ—Ä'],
        '–∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞': ['–∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞', '–∫–ª–∞–≤–∏—à–∏', '–≤–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞'],
        '–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': ['–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å', '–∑–∞—â–∏—Ç–∞', '–∞–Ω—Ç–∏–≤–∏—Ä—É—Å', '–ø–∞—Ä–æ–ª—å', '–≤–∏—Ä—É—Å'],
        '—Ñ–∞–π–ª—ã': ['—Ñ–∞–π–ª—ã', '–¥–æ–∫—É–º–µ–Ω—Ç—ã', '–ø–∞–ø–∫–∏', '—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ'],
        '–ø—Ä–æ–≥—Ä–∞–º–º—ã': ['–ø—Ä–æ–≥—Ä–∞–º–º—ã', '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è', '—Å–æ—Ñ—Ç', '—É—Å—Ç–∞–Ω–æ–≤–∫–∞']
    }
    
    topic_lower = topic.lower()
    return synonyms_map.get(topic_lower, [])

def create_learning_prompt(topic, relevant_sections):
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –æ–¥–Ω–æ–≥–æ —É—Ä–æ–∫–∞"""
    
    concrete_texts = []
    for i, section in enumerate(relevant_sections[:2], 1):
        concrete_text = section['content'][:500]
        concrete_texts.append(f"–†–ê–ó–î–ï–õ {i} '{section['title']}':\n{concrete_text}")
    
    concrete_content = "\n\n".join(concrete_texts)
    
    prompt = f"""
    –ò–°–ü–û–õ–¨–ó–£–ô –¢–û–õ–¨–ö–û –≠–¢–£ –ò–ù–§–û–†–ú–ê–¶–ò–Æ –ò–ó –†–£–ö–û–í–û–î–°–¢–í–ê:

    {concrete_content}

    –ó–ê–ü–†–ï–©–ï–ù–û:
    - –ü—Ä–∏–¥—É–º—ã–≤–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è
    - –î–∞–≤–∞—Ç—å –æ–±—â–∏–µ —Ñ—Ä–∞–∑—ã

    –ó–ê–î–ê–ß–ê 1: –û–ë–™–Ø–°–ù–ï–ù–ò–ï –¢–ï–ú–´ "{topic.upper()}"
    - –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ñ–∞–∫—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ –≤—ã—à–µ
    - –¶–∏—Ç–∏—Ä—É–π –ö–û–ù–ö–†–ï–¢–ù–´–ï —Ñ—Ä–∞–∑—ã –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞
    - –û–±—ä—è—Å–Ω–µ–Ω–∏–µ: 3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è

    –ó–ê–î–ê–ß–ê 2: –¢–ï–°–¢–û–í–´–ô –í–û–ü–†–û–°
    - –í–æ–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω –ø—Ä–æ–≤–µ—Ä—è—Ç—å –ö–û–ù–ö–†–ï–¢–ù–´–ô —Ñ–∞–∫—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞
    - –í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ—Å–Ω–æ–≤–∞–Ω—ã –Ω–∞ —Ç–µ–∫—Å—Ç–µ
    - –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ç–æ—á–Ω–æ–π —Ü–∏—Ç–∞—Ç–æ–π –∏–ª–∏ –ø—Ä—è–º—ã–º —Å–ª–µ–¥—Å—Ç–≤–∏–µ–º –∏–∑ —Ç–µ–∫—Å—Ç–∞

    –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (–¢–û–õ–¨–ö–û JSON):
    {{
        "explanation": "–¢–≤–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å –¶–ò–¢–ê–¢–ê–ú–ò –∏–∑ —Ç–µ–∫—Å—Ç–∞...",
        "quiz": {{
            "question": "–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å –ø–æ —Ç–µ–∫—Å—Ç—É –≤—ã—à–µ...",
            "options": ["–≤–∞—Ä–∏–∞–Ω—Ç1", "–≤–∞—Ä–∏–∞–Ω—Ç2", "–≤–∞—Ä–∏–∞–Ω—Ç3", "–≤–∞—Ä–∏–∞–Ω—Ç4"],
            "correct_answer": 0,
            "explanation": "–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç - –≤–∞—Ä–∏–∞–Ω—Ç X, –ø–æ—Ç–æ–º—É —á—Ç–æ –≤ —Ç–µ–∫—Å—Ç–µ —Å–∫–∞–∑–∞–Ω–æ: '–¶–ò–¢–ê–¢–ê –ò–ó –†–£–ö–û–í–û–î–°–¢–í–ê'."
        }}
    }}

    –ù–ê–ß–ò–ù–ê–ô –û–¢–í–ï–¢ –° {{"
    """
    
    return prompt

def parse_learning_response(response, topic, relevant_sections):
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
    try:
        cleaned_response = response.strip()
        logger.info(f"üîß Raw GigaChat response: {cleaned_response[:500]}...")
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º "—É–º–Ω—ã–µ" –∫–∞–≤—ã—á–∫–∏ –ø–µ—Ä–µ–¥ –ø–∞—Ä—Å–∏–Ω–≥–æ–º JSON
        cleaned_response = clean_json_string(cleaned_response)
        
        start = cleaned_response.find('{')
        end = cleaned_response.rfind('}') + 1
        
        if start == -1 or end == 0:
            raise ValueError("JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ")
            
        json_str = cleaned_response[start:end]
        data = json.loads(json_str)
        
        explanation = data.get('explanation', '')
        
        # –ü–†–û–í–ï–†–ö–ê: –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ–∞–∫—Ç—ã –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞
        if not contains_concrete_info(explanation, relevant_sections):
            logger.warning("‚ö†Ô∏è GigaChat –¥–∞–ª –æ–±—â–µ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –±–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∏!")
            explanation = create_quality_explanation(topic, relevant_sections)
        
        quiz_data = data.get('quiz')
        if not quiz_data:
            return explanation, None
            
        quiz = validate_and_fix_quiz(quiz_data, topic, relevant_sections)
        
        return explanation, quiz
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞: {e}")
        return create_quality_explanation(topic, relevant_sections), create_quality_quiz(topic, relevant_sections)

def create_full_test_prompt(topic, relevant_sections):
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ –∏–∑ 10 –≤–æ–ø—Ä–æ—Å–æ–≤"""
    
    concrete_texts = []
    for i, section in enumerate(relevant_sections[:3], 1):
        concrete_text = section['content'][:800]  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –æ–±—ä–µ–º –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        concrete_texts.append(f"–†–ê–ó–î–ï–õ {i} '{section['title']}':\n{concrete_text}")
    
    concrete_content = "\n\n".join(concrete_texts)
    
    prompt = f"""
    –¢–´ - –≠–ö–°–ü–ï–†–¢ –ü–û –°–û–ó–î–ê–ù–ò–Æ –¢–ï–°–¢–û–í. –°–û–ó–î–ê–ô –¢–ï–°–¢ –ò–ó 5 –í–û–ü–†–û–°–û–í –ü–û –¢–ï–ú–ï "{topic.upper()}".

    –ò–°–ü–û–õ–¨–ó–£–ô –¢–û–õ–¨–ö–û –≠–¢–£ –ò–ù–§–û–†–ú–ê–¶–ò–Æ –ò–ó –†–£–ö–û–í–û–î–°–¢–í–ê:

    {concrete_content}

    –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:
    1. –ù–ï –ø—Ä–∏–¥—É–º—ã–≤–∞–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é - –∏—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç –≤—ã—à–µ
    2. –ö–∞–∂–¥—ã–π –≤–æ–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω –ø—Ä–æ–≤–µ—Ä—è—Ç—å –ö–û–ù–ö–†–ï–¢–ù–´–ô —Ñ–∞–∫—Ç –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞
    3. –í—Å–µ 4 –≤–∞—Ä–∏–∞–Ω—Ç–∞ –æ—Ç–≤–µ—Ç–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –†–ê–ó–ù–´–ú–ò –∏ –û–°–ú–´–°–õ–ï–ù–ù–´–ú–ò
    4. –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ü–†–ê–í–ò–õ–¨–ù–´–ú
    5. –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –æ–±—â–∏–µ —Ñ—Ä–∞–∑—ã –∏–ª–∏ —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è

    –°–¢–†–£–ö–¢–£–†–ê –¢–ï–°–¢–ê:

    1. –¢–ï–û–†–ï–¢–ò–ß–ï–°–ö–ê–Ø –°–ü–†–ê–í–ö–ê (5-7 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π):
       - –ö—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ç–µ–º—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞
       - –ò—Å–ø–æ–ª—å–∑—É–π –ö–û–ù–ö–†–ï–¢–ù–´–ï —Ñ–∞–∫—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞
       - –¶–∏—Ç–∏—Ä—É–π –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã

    2. 10 –í–û–ü–†–û–°–û–í:
       - –ö–∞–∂–¥—ã–π –≤–æ–ø—Ä–æ—Å = 4 —Ä–∞–∑–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–∞ –æ—Ç–≤–µ—Ç–∞
       - –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç = —Ç–æ—á–Ω–∞—è —Ü–∏—Ç–∞—Ç–∞ –∏–ª–∏ –ø—Ä—è–º–æ–µ —Å–ª–µ–¥—Å—Ç–≤–∏–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞
       - –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã = –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–Ω—ã–µ, –Ω–æ –Ω–µ–≤–µ—Ä–Ω—ã–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
       - –í–æ–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã –æ—Ö–≤–∞—Ç—ã–≤–∞—Ç—å –†–ê–ó–ù–´–ï –∞—Å–ø–µ–∫—Ç—ã —Ç–µ–º—ã

    –ü–†–ò–ú–ï–† –ü–†–ê–í–ò–õ–¨–ù–û–ì–û –í–û–ü–†–û–°–ê:
    –í–æ–ø—Ä–æ—Å: "–î–ª—è —á–µ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–ª–∞–≤–∏—à–∞ Enter —Å–æ–≥–ª–∞—Å–Ω–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤—É?"
    –í–∞—Ä–∏–∞–Ω—Ç—ã: [
        "–î–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –≤–≤–æ–¥–∞ –∫–æ–º–∞–Ω–¥",
        "–î–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞", 
        "–î–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è caps lock",
        "–î–ª—è –≤—ã–∑–æ–≤–∞ –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞ –∑–∞–¥–∞—á"
    ]
    –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç: 0

    –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (–°–¢–†–û–ì–û –°–û–ë–õ–Æ–î–ê–ô):

    {{
        "theory": "–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è —Å–ø—Ä–∞–≤–∫–∞ —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ —Ñ–∞–∫—Ç–∞–º–∏ –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞...",
        "questions": [
            {{
                "question": "–í–æ–ø—Ä–æ—Å 1...",
                "options": ["–≤–∞—Ä–∏–∞–Ω—Ç1", "–≤–∞—Ä–∏–∞–Ω—Ç2", "–≤–∞—Ä–∏–∞–Ω—Ç3", "–≤–∞—Ä–∏–∞–Ω—Ç4"],
                "correct_answer": 0,
                "explanation": "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å —Ü–∏—Ç–∞—Ç–æ–π –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞"
            }},
            {{
                "question": "–í–æ–ø—Ä–æ—Å 2...",
                "options": ["–≤–∞—Ä–∏–∞–Ω—Ç1", "–≤–∞—Ä–∏–∞–Ω—Ç2", "–≤–∞—Ä–∏–∞–Ω—Ç3", "–≤–∞—Ä–∏–∞–Ω—Ç4"],
                "correct_answer": 1,
                "explanation": "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å —Ü–∏—Ç–∞—Ç–æ–π –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞"
            }}
            // ... –µ—â–µ 8 –≤–æ–ø—Ä–æ—Å–æ–≤
        ]
    }}

    –í–ê–ñ–ù–û: –î–æ–ª–∂–Ω–æ –±—ã—Ç—å –†–û–í–ù–û 10 –≤–æ–ø—Ä–æ—Å–æ–≤ —Å –†–ê–ó–ù–´–ú–ò –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ –æ—Ç–≤–µ—Ç–æ–≤!
    """
    
    return prompt

def parse_learning_response(response, topic, relevant_sections):
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
    try:
        cleaned_response = response.strip()
        logger.info(f"üîß Raw GigaChat response: {cleaned_response[:500]}...")
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º "—É–º–Ω—ã–µ" –∫–∞–≤—ã—á–∫–∏ –ø–µ—Ä–µ–¥ –ø–∞—Ä—Å–∏–Ω–≥–æ–º JSON
        cleaned_response = clean_json_string(cleaned_response)
        
        start = cleaned_response.find('{')
        end = cleaned_response.rfind('}') + 1
        
        if start == -1 or end == 0:
            raise ValueError("JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ")
            
        json_str = cleaned_response[start:end]
        data = json.loads(json_str)
        
        explanation = data.get('explanation', '')
        
        # –ü–†–û–í–ï–†–ö–ê: –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ–∞–∫—Ç—ã –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞
        if not contains_concrete_info(explanation, relevant_sections):
            logger.warning("‚ö†Ô∏è GigaChat –¥–∞–ª –æ–±—â–µ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –±–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∏!")
            explanation = create_quality_explanation(topic, relevant_sections)
        
        quiz_data = data.get('quiz')
        if not quiz_data:
            return explanation, None
            
        quiz = validate_and_fix_quiz(quiz_data, topic, relevant_sections)
        
        return explanation, quiz
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞: {e}")
        return create_quality_explanation(topic, relevant_sections), create_quality_quiz(topic, relevant_sections)

def parse_full_test_response(response, topic, relevant_sections):
    """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ - –£–õ–£–ß–®–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø - –¢–ï–ü–ï–†–¨ 5 –í–û–ü–†–û–°–û–í"""
    try:
        cleaned_response = response.strip()
        cleaned_response = clean_json_string(cleaned_response)
        
        json_data = extract_json_from_text(cleaned_response)
        
        if not json_data:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞")
            return create_quality_full_test(topic, relevant_sections)
        
        theory = json_data.get('theory', '')
        questions = json_data.get('questions', [])
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Ç–µ–æ—Ä–∏–∏
        if not theory or len(theory) < 50:
            theory = create_quality_explanation(topic, relevant_sections)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ–º –≤–æ–ø—Ä–æ—Å—ã
        validated_questions = []
        for i, question in enumerate(questions[:5]):  # –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º—É–º 5 –≤–æ–ø—Ä–æ—Å–æ–≤
            try:
                validated_question = validate_question(question, i, topic, relevant_sections)
                if validated_question:
                    validated_questions.append(validated_question)
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–∞ {i}: {e}")
                continue
        
        # –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å–æ–≤ –º–µ–Ω—å—à–µ 5, –¥–æ–±–∞–≤–ª—è–µ–º –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã
        while len(validated_questions) < 5:  # –ò–∑–º–µ–Ω–∏–ª–∏ —Å 10 –Ω–∞ 5
            i = len(validated_questions)
            quality_question = create_quality_question(i, topic, relevant_sections)
            validated_questions.append(quality_question)
        
        test_data = {
            'topic': topic,
            'theory': theory,
            'questions': validated_questions[:5]  # –¢–æ—á–Ω–æ 5 –≤–æ–ø—Ä–æ—Å–æ–≤
        }
        
        logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–æ {len(validated_questions)} –≤–æ–ø—Ä–æ—Å–æ–≤")
        return test_data
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞: {e}")
        return create_quality_full_test(topic, relevant_sections)
    
def extract_json_from_text(text):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ JSON –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Ä–∞–∑–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏"""
    methods = [
        extract_json_direct,
        extract_json_with_regex,
        extract_json_with_ast
    ]
    
    for method in methods:
        try:
            result = method(text)
            if result:
                logger.info(f"‚úÖ JSON –∏–∑–≤–ª–µ—á–µ–Ω –º–µ—Ç–æ–¥–æ–º: {method.__name__}")
                return result
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ú–µ—Ç–æ–¥ {method.__name__} –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
            continue
    
    return None

def extract_json_direct(text):
    """–ü—Ä—è–º–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ JSON"""
    start = text.find('{')
    end = text.rfind('}') + 1
    
    if start == -1 or end == 0:
        return None
        
    json_str = text[start:end]
    return json.loads(json_str)

def extract_json_with_regex(text):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ JSON —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π"""
    import re
    # –ò—â–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É JSON
    json_pattern = r'\{(?:[^{}]|(?:\{(?:[^{}]|(?:\{[^{}]*\}))*\}))*\}'
    matches = re.findall(json_pattern, text, re.DOTALL)
    
    for match in matches:
        try:
            return json.loads(match)
        except:
            continue
    
    return None

def extract_json_with_ast(text):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ JSON —Å –ø–æ–º–æ—â—å—é ast (–¥–ª—è Python-–ø–æ–¥–æ–±–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä)"""
    try:
        # –ü—ã—Ç–∞–µ–º—Å—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ Python dict
        parsed = ast.literal_eval(text)
        if isinstance(parsed, dict):
            return parsed
    except:
        pass
    
    return None

def clean_json_string(json_string):
    """–û—á–∏—Å—Ç–∫–∞ JSON —Å—Ç—Ä–æ–∫–∏ –æ—Ç '—É–º–Ω—ã—Ö' –∫–∞–≤—ã—á–µ–∫ –∏ –¥—Ä—É–≥–∏—Ö –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
    replacements = {
        '‚Äú': '"', '‚Äù': '"', '‚Äû': '"', '¬´': '"', '¬ª': '"',
        '‚Äò': "'", '‚Äô': "'", '`': "'", '¬¥': "'",
        '‚Äú': '"', '‚Äù': '"', '¬´': '"', '¬ª': '"',
        '‚Äò': "'", '‚Äô': "'", '`': "'",
        '¬†': ' ', '\\"': '"', "\\'": "'"
    }
    
    cleaned = json_string
    for wrong, correct in replacements.items():
        cleaned = cleaned.replace(wrong, correct)
    
    return cleaned

def validate_question(question, question_id, topic, relevant_sections):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–∞"""
    if not isinstance(question, dict):
        return create_quality_question(question_id, topic, relevant_sections)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
    required_fields = ['question', 'options', 'correct_answer']
    for field in required_fields:
        if field not in question:
            return create_quality_question(question_id, topic, relevant_sections)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º options
    options = question.get('options', [])
    if not isinstance(options, list) or len(options) != 4:
        options = create_quality_options(question_id, topic, relevant_sections)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ä–∞–∑–Ω—ã–µ
    if len(set(options)) < 3:  # –ú–∏–Ω–∏–º—É–º 3 —Ä–∞–∑–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–∞
        options = create_quality_options(question_id, topic, relevant_sections)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º correct_answer
    correct_answer = question.get('correct_answer', 0)
    if not isinstance(correct_answer, int) or not 0 <= correct_answer <= 3:
        correct_answer = 0
    
    return {
        'id': question_id,
        'question': question.get('question', f'–í–æ–ø—Ä–æ—Å {question_id + 1} –ø–æ —Ç–µ–º–µ "{topic}"'),
        'options': options,
        'correct_answer': correct_answer,
        'explanation': question.get('explanation', '–û–±—ä—è—Å–Ω–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞.')
    }

def create_quality_full_test(topic, relevant_sections):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö –ø–∞—Ä—Å–∏–Ω–≥–∞ - –¢–ï–ü–ï–†–¨ 5 –í–û–ü–†–û–°–û–í"""
    questions = []
    for i in range(5):  # –ò–∑–º–µ–Ω–∏–ª–∏ —Å 10 –Ω–∞ 5
        questions.append(create_quality_question(i, topic, relevant_sections))
    
    return {
        'topic': topic,
        'theory': create_quality_explanation(topic, relevant_sections),
        'questions': questions
    }

def create_quality_explanation(topic, relevant_sections):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î"""
    if not relevant_sections:
        return f"–í —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ –µ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Ç–µ–º–µ '{topic}', –Ω–æ –æ–Ω–∞ —Ç—Ä–µ–±—É–µ—Ç –∏–∑—É—á–µ–Ω–∏—è."
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ä–∞–∑–¥–µ–ª–æ–≤
    explanations = []
    for section in relevant_sections[:2]:
        content = section['content']
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        sentences = re.split(r'[.!?]+', content)
        meaningful_sentences = [s.strip() for s in sentences if len(s.strip()) > 30][:2]
        if meaningful_sentences:
            explanations.extend(meaningful_sentences)
    
    if explanations:
        explanation = " ".join(explanations[:3])
        if len(explanation) > 500:
            explanation = explanation[:500] + "..."
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–µ –∞–±–∑–∞—Ü—ã –∏–∑ —Ä–∞–∑–¥–µ–ª–æ–≤
        explanation_parts = []
        for section in relevant_sections[:2]:
            content = section['content']
            if len(content) > 100:
                explanation_parts.append(content[:200] + "...")
        
        explanation = " ".join(explanation_parts) if explanation_parts else f"–¢–µ–º–∞ '{topic}' —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è –≤ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ –ø–æ —Ü–∏—Ñ—Ä–æ–≤–æ–π –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç–∏."
    
    return explanation

def create_detailed_explanation(topic, section, correct_idx):
    """–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø–æ—è—Å–Ω–µ–Ω–∏—è –¥–ª—è –æ—Ç–≤–µ—Ç–∞"""
    section_preview = section['content'][:150] + "..." if len(section['content']) > 150 else section['content']
    
    explanations = [
        f"‚úÖ –≠—Ç–æ—Ç –æ—Ç–≤–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π, –ø–æ—Ç–æ–º—É —á—Ç–æ –æ–Ω —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ '{section['title']}' (—Å—Ç—Ä–∞–Ω–∏—Ü–∞ {section['page']}). –í —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ —É–∫–∞–∑–∞–Ω–æ: '{section_preview}'",
        
        f"üìö –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞. –í —Ä–∞–∑–¥–µ–ª–µ '{section['title']}' –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {section['page']} –æ–±—ä—è—Å–Ω—è–µ—Ç—Å—è: '{section_preview}'",
        
        f"üéØ –≠—Ç–æ—Ç –≤–∞—Ä–∏–∞–Ω—Ç –≤–µ—Ä–Ω—ã–π, —Ç–∞–∫ –∫–∞–∫ –æ–Ω —Ç–æ—á–Ω–æ –æ—Ç—Ä–∞–∂–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞. –°–æ–≥–ª–∞—Å–Ω–æ —Ä–∞–∑–¥–µ–ª—É '{section['title']}': '{section_preview}'",
        
        f"üí° –î–∞, —ç—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç! –í —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ –ø–æ —Ü–∏—Ñ—Ä–æ–≤–æ–π –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç–∏ –≤ —Ä–∞–∑–¥–µ–ª–µ '{section['title']}' (—Å—Ç—Ä. {section['page']}) –≥–æ–≤–æ—Ä–∏—Ç—Å—è: '{section_preview}'",
        
        f"üåü –í–µ—Ä–Ω–æ! –≠—Ç–æ—Ç –æ—Ç–≤–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞. –í —Ä–∞–∑–¥–µ–ª–µ '{section['title']}' –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {section['page']} —É–∫–∞–∑–∞–Ω–æ: '{section_preview}'"
    ]
    
    import random
    return random.choice(explanations)

def create_quality_question(question_id, topic, relevant_sections):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ —Å —Ä–∞–∑–Ω—ã–º–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ –æ—Ç–≤–µ—Ç–æ–≤ –∏ –ø–æ—è—Å–Ω–µ–Ω–∏—è–º–∏"""
    if not relevant_sections:
        return create_fallback_question(question_id, topic)
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
    section_index = question_id % len(relevant_sections)
    section = relevant_sections[section_index]
    content = section['content']
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤
    sentences = re.split(r'[.!?]+', content)
    meaningful_sentences = [s.strip() for s in sentences if len(s.strip()) > 20]
    
    if meaningful_sentences:
        # –°–æ–∑–¥–∞–µ–º –±–æ–ª–µ–µ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤
        correct_answer = f"–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞"
        wrong_answers = [
            "–ù–µ–≤–µ—Ä–Ω–æ–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—Ç —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤—É",
            "–†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω–æ–µ –∑–∞–±–ª—É–∂–¥–µ–Ω–∏–µ, –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–µ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º", 
            "–ù–µ—Ç–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, —Ç—Ä–µ–±—É—é—â–∞—è —É—Ç–æ—á–Ω–µ–Ω–∏—è –≤ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ"
        ]
        
        # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã
        import random
        options = [correct_answer] + wrong_answers
        correct_idx = 0
        
        # –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω–æ–µ –ø–æ—è—Å–Ω–µ–Ω–∏–µ
        explanation = create_detailed_explanation(topic, section, correct_idx)
        
    else:
        # Fallback –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ö–æ—Ä–æ—à–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        return create_fallback_question(question_id, topic)
    
    return {
        'id': question_id,
        'question': f'–í–æ–ø—Ä–æ—Å {question_id + 1}: –ß—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç—Å—è –≤ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ –æ —Ç–µ–º–µ "{topic}"?',
        'options': options,
        'correct_answer': correct_idx,
        'explanation': explanation
    }

def create_quality_options(question_id, topic, relevant_sections):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ—Ç–≤–µ—Ç–æ–≤"""
    return [
        "–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ",
        "–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç, –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤—É", 
        "–û—à–∏–±–æ—á–Ω–æ–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–µ—Ç –≤ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ",
        "–ù–µ–≤–µ—Ä–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∞—â–∞—è —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤—É"
    ]

def create_fallback_question(question_id, topic):
    """–°–æ–∑–¥–∞–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–∞-–∑–∞–≥–ª—É—à–∫–∏"""
    return {
        'id': question_id,
        'question': f'–í–æ–ø—Ä–æ—Å {question_id + 1} –ø–æ —Ç–µ–º–µ "{topic}":',
        'options': [
            "–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤—É",
            "–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç",
            "–û—à–∏–±–æ—á–Ω–æ–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ",
            "–ù–µ–≤–µ—Ä–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"
        ],
        'correct_answer': 0,
        'explanation': '–≠—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–Ω–∞–Ω–∏—è –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–π —Ç–µ–º–µ.'
    }

def contains_concrete_info(explanation, relevant_sections):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞"""
    if not explanation:
        return False
        
    guide_keywords = set()
    for section in relevant_sections:
        content_lower = section['content'].lower()
        words = set(re.findall(r'\b\w{4,}\b', content_lower))
        guide_keywords.update(words)
    
    explanation_lower = explanation.lower()
    matches = sum(1 for word in guide_keywords if word in explanation_lower)
    
    logger.info(f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∏: {matches} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π —Å —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ–º")
    return matches > 2

def validate_and_fix_quiz(quiz_data, topic, relevant_sections):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–µ—Å—Ç–∞"""
    try:
        required_fields = ['question', 'options', 'correct_answer', 'explanation']
        for field in required_fields:
            if field not in quiz_data:
                raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ: {field}")
        
        if not isinstance(quiz_data['options'], list) or len(quiz_data['options']) != 4:
            quiz_data['options'] = ["–í–∞—Ä–∏–∞–Ω—Ç 1", "–í–∞—Ä–∏–∞–Ω—Ç 2", "–í–∞—Ä–∏–∞–Ω—Ç 3", "–í–∞—Ä–∏–∞–Ω—Ç 4"]
        
        if not isinstance(quiz_data['correct_answer'], int) or not 0 <= quiz_data['correct_answer'] <= 3:
            quiz_data['correct_answer'] = 0
            
        quiz = {
            'id': f'quiz_{hash(topic)}',
            'question': quiz_data['question'],
            'options': quiz_data['options'],
            'correct_answer': quiz_data['correct_answer'],
            'explanation': quiz_data['explanation']
        }
        
        return quiz
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ç–µ—Å—Ç–∞: {e}")
        return create_quality_quiz(topic, relevant_sections)

def create_quality_quiz(topic, relevant_sections):
    """–°–æ–∑–¥–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö"""
    first_section = relevant_sections[0] if relevant_sections else None
    
    if first_section:
        content = first_section['content']
        sentences = re.split(r'[.!?]+', content)
        meaningful_sentences = [s.strip() for s in sentences if len(s.strip()) > 30]
        
        if meaningful_sentences:
            correct_answer = meaningful_sentences[0]
        else:
            correct_answer = content[:100]
        
        quiz = {
            'id': 'quality_quiz',
            'question': f'–ß—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç—Å—è –≤ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ –æ —Ç–µ–º–µ "{topic}"?',
            'options': [
                correct_answer[:80] + "...",
                "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤—É",
                "–≠—Ç–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω–æ–µ –∑–∞–±–ª—É–∂–¥–µ–Ω–∏–µ", 
                "–î–∞–Ω–Ω—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ"
            ],
            'correct_answer': 0,
            'explanation': f'–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ "{first_section["title"]}" —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞.'
        }
    else:
        quiz = {
            'id': 'fallback_quiz',
            'question': f'–í–æ–ø—Ä–æ—Å –ø–æ —Ç–µ–º–µ "{topic}":',
            'options': [
                "–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç",
                "–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç",
                "–û—à–∏–±–æ—á–Ω–æ–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ",
                "–ù–µ–≤–µ—Ä–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"
            ],
            'correct_answer': 0,
            'explanation': '–≠—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–Ω–∞–Ω–∏—è –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–π —Ç–µ–º–µ.'
        }
    
    return quiz



@app.route('/api/debug-sections')
def debug_sections():
    """–û—Ç–ª–∞–¥–æ—á–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤"""
    if not db:
        return jsonify({'error': '–ë–î –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞'}), 500
        
    sections = db.get_guide_sections(limit=10)
    result = []
    
    for section in sections:
        result.append({
            'id': section['id'],
            'title': section['section_title'],
            'content_preview': section['section_content'][:200] + '...',
            'page': section['page_number'],
            'category': section['category'],
            'content_length': len(section['section_content'])
        })
    
    return jsonify({
        'status': 'success',
        'sections_count': len(sections),
        'sections': result
    })

@app.route('/api/debug-topic-search')
def debug_topic_search():
    """–û—Ç–ª–∞–¥–æ—á–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ —Ç–µ–º–µ"""
    topic = request.args.get('topic', '–∫–æ–º–ø—å—é—Ç–µ—Ä')
    
    sections = db.get_guide_sections(limit=20)
    relevant = get_relevant_sections(topic)
    
    result = {
        'topic': topic,
        'total_sections': len(sections),
        'relevant_sections': len(relevant),
        'relevant_details': []
    }
    
    for section in relevant:
        result['relevant_details'].append({
            'title': section['title'],
            'score': section['score'],
            'content_preview': section['content'][:300] + '...',
            'content_length': len(section['content'])
        })
    
    return jsonify(result)

@app.route('/api/learn-topic', methods=['POST'])
def learn_topic():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –ø–æ —Ç–µ–º–µ - –£–õ–£–ß–®–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
    if not GIGACHAT_AVAILABLE:
        return jsonify({
            'status': 'error', 
            'error': 'GigaChat –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω'
        }), 503

    try:
        data = request.get_json()
        topic = data.get('topic', '').strip()
        
        if not topic:
            return jsonify({
                'status': 'error',
                'error': '–¢–µ–º–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç–æ–π'
            }), 400

        logger.info(f"üéØ –ó–∞–ø—Ä–æ—Å –Ω–∞ –∏–∑—É—á–µ–Ω–∏–µ —Ç–µ–º—ã: {topic}")

        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã –∏–∑ –ë–î
        relevant_sections = get_relevant_sections(topic)
        logger.info(f"üìö –ù–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤: {len(relevant_sections)}")
        
        if not relevant_sections:
            return jsonify({
                'status': 'error',
                'error': f'–í —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —Ç–µ–º–µ "{topic}". –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é —Ç–µ–º—É.'
            })

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å –≥–ª—É–±–æ–∫–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        logger.info("üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è...")
        explanation = generate_deep_context_explanation(topic, relevant_sections)
        
        logger.info(f"‚úÖ –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ: {len(explanation)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        return jsonify({
            'status': 'success',
            'explanation': explanation
        })

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è: {e}")
        return jsonify({
            'status': 'error',
            'error': '–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è'
        }), 500

def generate_deep_context_explanation(topic, relevant_sections):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–ª—É–±–æ–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è - –° –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï–ú"""
    
    prompt = f"""
–¢–´ - –≠–ö–°–ü–ï–†–¢-–ü–†–ï–ü–û–î–ê–í–ê–¢–ï–õ–¨ –ü–û –¶–ò–§–†–û–í–û–ô –ì–†–ê–ú–û–¢–ù–û–°–¢–ò. –î–ê–ô –ö–ê–ß–ï–°–¢–í–ï–ù–ù–û–ï –û–ë–™–Ø–°–ù–ï–ù–ò–ï –ü–û –¢–ï–ú–ï: "{topic.upper()}"

–ö–û–ù–ö–†–ï–¢–ù–´–ô –ú–ê–¢–ï–†–ò–ê–õ –ò–ó –†–£–ö–û–í–û–î–°–¢–í–ê:
{format_concrete_sections(relevant_sections)}
–¢–í–û–Ø –ó–ê–î–ê–ß–ê:
–°–û–°–¢–ê–í–¨ –°–¢–†–£–ö–¢–£–†–ò–†–û–í–ê–ù–ù–û–ï –û–ë–™–Ø–°–ù–ï–ù–ò–ï –° –ß–ï–¢–ö–û–ô –°–¢–†–£–ö–¢–£–†–û–ô:

–û—Å–Ω–æ–≤–Ω–∞—è –∫–æ–Ω—Ü–µ–ø—Ü–∏—è:
- –ö—Ä–∞—Ç–∫–æ –æ–±—ä—è—Å–Ω–∏ —Å—É—Ç—å —Ç–µ–º—ã

–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç:
- –û–ø–∏—à–∏ –º–µ—Ö–∞–Ω–∏–∑–º —Ä–∞–±–æ—Ç—ã
- –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞

–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:
- –ö–∞–∫ –∏–º–µ–Ω–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ
- –ü–æ—à–∞–≥–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

–í–∞–∂–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã:
- –ö–ª—é—á–µ–≤—ã–µ –∞—Å–ø–µ–∫—Ç—ã –¥–ª—è –∑–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è
- –ß–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏ –∏ –∫–∞–∫ –∏—Ö –∏–∑–±–µ–∂–∞—Ç—å

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –§–û–†–ú–ê–¢–£:
- –ò—Å–ø–æ–ª—å–∑—É–π –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å –¥–≤–æ–µ—Ç–æ—á–∏–µ–º –≤ –∫–æ–Ω—Ü–µ
- –ò—Å–ø–æ–ª—å–∑—É–π –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏ —á–µ—Ä–µ–∑ –¥–µ—Ñ–∏—Å
- –í—ã–¥–µ–ª—è–π **–≤–∞–∂–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã** –¥–≤–æ–π–Ω—ã–º–∏ –∑–≤–µ–∑–¥–æ—á–∫–∞–º–∏
- –†–∞–∑–¥–µ–ª—è–π –±–ª–æ–∫–∏ –ø—É—Å—Ç—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏
- –î–∞–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞

–û–¢–í–ï–ß–ê–ô –¢–û–õ–¨–ö–û –¢–ï–ö–°–¢–û–ú –û–ë–™–Ø–°–ù–ï–ù–ò–Ø, –±–µ–∑ –≤—Å—Ç—É–ø–ª–µ–Ω–∏–π –∏ –∑–∞–∫–ª—é—á–µ–Ω–∏–π.
"""
    
    try:
        # –£–ë–ï–†–ò–¢–ï max_tokens - —ç—Ç–æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
        response = gigachat_service.client.chat(prompt)
        explanation = response.choices[0].message.content.strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ —É–ª—É—á—à–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
        explanation = enhance_explanation_quality(explanation, topic, relevant_sections)
        
        return explanation
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è: {e}")
        return create_specific_explanation(topic, relevant_sections)

def format_concrete_sections(relevant_sections):
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ö–û–ù–ö–†–ï–¢–ù–´–• —Ä–∞–∑–¥–µ–ª–æ–≤ —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º —Å–º—ã—Å–ª–∞"""
    concrete_parts = []
    
    for i, section in enumerate(relevant_sections[:4], 1):
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —Ç–µ–º–µ
        specific_content = extract_specific_content(section['content'])
        if specific_content:
            concrete_parts.append(f"--- –†–ê–ó–î–ï–õ {i}: {section['title']} ---\n{specific_content}")
    
    return "\n\n".join(concrete_parts) if concrete_parts else "–í —Ä–∞–∑–¥–µ–ª–∞—Ö –µ—Å—Ç—å –æ–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Ç–µ–º–µ."

def extract_specific_content(text):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
    sentences = re.split(r'[.!?]+', text)
    relevant_sentences = []
    
    for sentence in sentences:
        sentence = sentence.strip()
        # –û—Ç–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        if (len(sentence) > 25 and 
            not re.match(r'^[\\d\\s\\-\\.]+$', sentence) and
            '–æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ' not in sentence.lower() and
            '—Å—Ç—Ä–∞–Ω–∏—Ü–∞' not in sentence.lower()):
            relevant_sentences.append(sentence)
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, –Ω–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
    return '. '.join(relevant_sentences[:8]) + '.'

def analyze_topic_specifics(topic, relevant_sections):
    """–ê–Ω–∞–ª–∏–∑ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∏ —Ç–µ–º—ã –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    all_content = " ".join([section['content'] for section in relevant_sections[:3]])
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º, –æ —á–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –≥–æ–≤–æ—Ä–∏—Ç—Å—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Ç–µ–º—ã
    analysis_parts = []
    
    # –ò—â–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è
    usage_patterns = [
        r'–¥–ª—è —á–µ–≥–æ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è|–ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è)[^.!?]*' + re.escape(topic),
        r'–∫–∞–∫ (—Ä–∞–±–æ—Ç–∞–µ—Ç|–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å)[^.!?]*' + re.escape(topic),
        r'—Ñ—É–Ω–∫—Ü–∏–∏[^.!?]*' + re.escape(topic),
        topic + r' (–ø–æ–∑–≤–æ–ª—è–µ—Ç|–Ω—É–∂–µ–Ω|–ø–æ–º–æ–≥–∞–µ—Ç)[^.!?]*'
    ]
    
    for pattern in usage_patterns:
        matches = re.findall(pattern, all_content.lower())
        if matches:
            analysis_parts.append(f"–ù–∞–π–¥–µ–Ω–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: {matches[0][:100]}...")
    
    # –ò—â–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
    instruction_patterns = [
        r'–∫–∞–∫ (–Ω–∞—Å—Ç—Ä–æ–∏—Ç—å|—É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å|–ø–æ–¥–∫–ª—é—á–∏—Ç—å)[^.!?]*' + re.escape(topic),
        r'–ø—Ä–∞–≤–∏–ª–∞?[^.!?]*' + re.escape(topic),
        r'—Å–æ–≤–µ—Ç—ã?[^.!?]*' + re.escape(topic)
    ]
    
    for pattern in instruction_patterns:
        if re.search(pattern, all_content.lower()):
            analysis_parts.append("–ï—Å—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")
            break
    
    return "; ".join(analysis_parts) if analysis_parts else "–û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–µ–º–µ"

def enhance_explanation_quality(explanation, topic, relevant_sections):
    """–£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è"""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É
    if len(explanation) < 150:
        logger.warning("‚ö†Ô∏è –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ, –¥–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª–∏")
        explanation = add_specific_details(explanation, topic, relevant_sections)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫—É
    if not has_specific_details(explanation):
        logger.warning("‚ö†Ô∏è –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –æ–±—â–µ–µ, –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫—É")
        explanation = create_specific_explanation(topic, relevant_sections)
    
    # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
    explanation = clean_text_response(explanation)
    
    return explanation

def has_specific_details(text):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π"""
    # –ò—â–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –≥–ª–∞–≥–æ–ª—ã –∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
    specific_indicators = [
        '–Ω–∞–∂–∞—Ç—å', '–≤—ã–±—Ä–∞—Ç—å', '–ø–µ—Ä–µ—Ç–∞—â–∏—Ç—å', '—â–µ–ª–∫–Ω—É—Ç—å', '–æ—Ç–∫—Ä—ã—Ç—å',
        '–∑–∞–∫—Ä—ã—Ç—å', '–Ω–∞—Å—Ç—Ä–æ–∏—Ç—å', '–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å', '–ø–æ–¥–∫–ª—é—á–∏—Ç—å',
        '–ª–µ–≤–∞—è –∫–Ω–æ–ø–∫–∞', '–ø—Ä–∞–≤–∞—è –∫–Ω–æ–ø–∫–∞', '–∫–æ–ª–µ—Å–∏–∫–æ', '–∫—É—Ä—Å–æ—Ä'
    ]
    
    text_lower = text.lower()
    return any(indicator in text_lower for indicator in specific_indicators)

def add_specific_details(explanation, topic, relevant_sections):
    """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π –∫ –æ–±—ä—è—Å–Ω–µ–Ω–∏—é"""
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ–∞–∫—Ç—ã –∏–∑ —Ä–∞–∑–¥–µ–ª–æ–≤
    specific_facts = extract_specific_facts(topic, relevant_sections)
    
    if specific_facts:
        return explanation + " " + " ".join(specific_facts[:2])
    else:
        return create_specific_explanation(topic, relevant_sections)

def extract_specific_facts(topic, relevant_sections):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ñ–∞–∫—Ç–æ–≤ –ø–æ —Ç–µ–º–µ"""
    facts = []
    
    for section in relevant_sections[:2]:
        content = section['content']
        sentences = re.split(r'[.!?]+', content)
        
        for sentence in sentences:
            sentence = sentence.strip()
            if (len(sentence) > 30 and 
                topic.lower() in sentence.lower() and
                any(keyword in sentence.lower() for keyword in ['–∫–Ω–æ–ø–∫–∞', '–º–µ–Ω—é', '—Ñ–∞–π–ª', '–ø–∞–ø–∫–∞', '–æ–∫–Ω–æ', '—ç–∫—Ä–∞–Ω'])):
                facts.append(sentence)
    
    return facts[:3]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–µ –±–æ–ª–µ–µ 3 —Ñ–∞–∫—Ç–æ–≤

def create_specific_explanation(topic, relevant_sections):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö"""
    if not relevant_sections:
        return f"–í —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è —Ç–µ–º–∞ '{topic}'. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏–∑—É—á–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ä–∞–∑–¥–µ–ª—ã –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."
    
    # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–µ—Ç–∞–ª–∏ –∏–∑ —Ä–∞–∑–¥–µ–ª–æ–≤
    specific_details = []
    
    for section in relevant_sections[:2]:
        # –ò—â–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –¥–µ–π—Å—Ç–≤–∏—è–º–∏
        sentences = re.split(r'[.!?]+', section['content'])
        for sentence in sentences:
            if (topic.lower() in sentence.lower() and 
                len(sentence) > 40 and
                any(verb in sentence.lower() for verb in ['–Ω–∞–∂–∞—Ç—å', '–≤—ã–±—Ä–∞—Ç—å', '–æ—Ç–∫—Ä—ã—Ç—å', '–∑–∞–∫—Ä—ã—Ç—å', '–ø–µ—Ä–µ–π—Ç–∏'])):
                specific_details.append(sentence.strip())
    
    if specific_details:
        base = f"–°–æ–≥–ª–∞—Å–Ω–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤—É, {topic} –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º: "
        return base + " ".join(specific_details[:2])
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Ä–∞–∑–¥–µ–ª–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        sections_context = ", ".join([section['title'] for section in relevant_sections[:2]])
        return f"–¢–µ–º–∞ '{topic}' —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è –≤ —Ä–∞–∑–¥–µ–ª–∞—Ö {sections_context}. –í —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–∞–±–æ—Ç–µ —Å —ç—Ç–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–º."

def clean_text_response(text):
    """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"""
    # –£–±–∏—Ä–∞–µ–º HTML-—Ç–µ–≥–∏
    text = re.sub(r'<[^>]+>', '', text)
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    text = re.sub(r'\s+', ' ', text)
    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–ª–µ–º—ã —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π (–∑–∞–º–µ–Ω—è–µ–º —Å—Ç—Ä–∞–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã)
    text = re.sub(r'[^\w\s–∞-—è–ê-–Ø—ë–Å.,!?;:()-]', '', text)
    return text.strip()

def format_sections_for_deep_analysis(relevant_sections):
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–æ–≤ –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    formatted = []
    for i, section in enumerate(relevant_sections[:3], 1):
        # –ë–µ—Ä–µ–º –±–æ–ª—å—à–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        meaningful_content = extract_meaningful_content(section['content'])
        formatted.append(f"–†–ê–ó–î–ï–õ {i}: {section['title']}\n{meaningful_content}")
    
    return "\n\n" + "="*50 + "\n\n".join(formatted) + "\n" + "="*50

def extract_meaningful_content(text, max_length=800):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    sentences = re.split(r'[.!?]+', text)
    meaningful_sentences = []
    
    for sentence in sentences:
        sentence = sentence.strip()
        # –û—Ç–±–∏—Ä–∞–µ–º —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (–Ω–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∏ –Ω–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –º—É—Å–æ—Ä)
        if (len(sentence) > 20 and 
            not re.match(r'^[\d\s\-\.]+$', sentence) and
            not any(word in sentence.lower() for word in ['–æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ', '—Å—Ç—Ä–∞–Ω–∏—Ü–∞', '–≥–ª–∞–≤–∞'])):
            meaningful_sentences.append(sentence)
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º, –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—è –¥–ª–∏–Ω—É
    result = '. '.join(meaningful_sentences[:15]) + '.'
    if len(result) > max_length:
        result = result[:max_length] + "..."
    
    return result

def clean_explanation_text(text):
    """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –æ—Ç HTML –∏ –ª–∏—à–Ω–µ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    # –£–±–∏—Ä–∞–µ–º HTML-—Ç–µ–≥–∏
    text = re.sub(r'<[^>]+>', '', text)
    # –£–±–∏—Ä–∞–µ–º –º–∞—Ä–∫–µ—Ä—ã JSON
    text = re.sub(r'[{}[\]"]', '', text)
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    text = re.sub(r'\s+', ' ', text)
    # –£–±–∏—Ä–∞–µ–º —Ñ—Ä–∞–∑—ã –ø—Ä–æ JSON
    text = re.sub(r'json\s*:', '', text, flags=re.IGNORECASE)
    
    return text.strip()

def is_low_quality_explanation(explanation):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è"""
    if len(explanation) < 200:
        return True
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–µ —Ñ–∞–∫—Ç–æ–≤ –±–µ–∑ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
    sentences = re.split(r'[.!?]+', explanation)
    if len(sentences) < 5:
        return True
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –≥–ª—É–±–æ–∫–∏—Ö –æ–±—ä—è—Å–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π
    deep_patterns = [
        r'–ø–æ–º–æ–≥–∞–µ—Ç', r'–ø–æ–∑–≤–æ–ª—è–µ—Ç', r'–Ω—É–∂–Ω–æ —á—Ç–æ–±—ã', r'–≤–∞–∂–Ω–æ –ø–æ—Ç–æ–º—É —á—Ç–æ',
        r'–∫–∞–∫ –µ—Å–ª–∏ –±—ã', r'–ø—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ —á—Ç–æ', r'—ç—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞'
    ]
    
    explanation_lower = explanation.lower()
    deep_matches = sum(1 for pattern in deep_patterns if re.search(pattern, explanation_lower))
    
    return deep_matches < 2

def create_quality_context_explanation(topic, relevant_sections):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö"""
    if not relevant_sections:
        return f"–¢–µ–º–∞ '{topic}' —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è –≤ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ –ø–æ —Ü–∏—Ñ—Ä–æ–≤–æ–π –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç–∏. –≠—Ç–æ –≤–∞–∂–Ω—ã–π –∞—Å–ø–µ–∫—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–∂–µ—Ç –≤–∞–º –ª—É—á—à–µ –ø–æ–Ω–∏–º–∞—Ç—å —Ä–∞–±–æ—Ç—É —Å –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã–º–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è–º–∏."
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
    context_keywords = analyze_context_keywords(relevant_sections, topic)
    
    if context_keywords:
        explanation = f"–í —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ —Ç–µ–º–∞ '{topic}' —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ {context_keywords['primary_context']}. "
        explanation += f"–û—Å–Ω–æ–≤–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ —É–¥–µ–ª—è–µ—Ç—Å—è {context_keywords['key_aspects']}. "
        explanation += f"–≠—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º {context_keywords['practical_benefit']}. "
        explanation += "–ü–æ–Ω–∏–º–∞–Ω–∏–µ —ç—Ç–æ–π —Ç–µ–º—ã —Å–¥–µ–ª–∞–µ—Ç —Ä–∞–±–æ—Ç—É —Å –∫–æ–º–ø—å—é—Ç–µ—Ä–æ–º –±–æ–ª–µ–µ –∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ–π –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π."
    else:
        explanation = f"–¢–µ–º–∞ '{topic}' - –≤–∞–∂–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç —Ü–∏—Ñ—Ä–æ–≤–æ–π –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç–∏. –í —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é —ç—Ç–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –≤ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö, —á—Ç–æ –ø–æ–º–æ–∂–µ—Ç –≤–∞–º —Å—Ç–∞—Ç—å –±–æ–ª–µ–µ —É–≤–µ—Ä–µ–Ω–Ω—ã–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º."
    
    return explanation

def analyze_context_keywords(relevant_sections, topic):
    """–ê–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    all_content = " ".join([section['content'] for section in relevant_sections[:2]])
    content_lower = all_content.lower()
    
    # –ò—â–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    patterns = {
        'primary_context': find_primary_context(content_lower, topic),
        'key_aspects': find_key_aspects(content_lower, topic),
        'practical_benefit': find_practical_benefit(content_lower, topic)
    }
    
    return patterns

def find_primary_context(content, topic):
    """–ü–æ–∏—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    context_indicators = [
        r'–¥–ª—è\s+\w+\s+–Ω—É–∂–Ω–æ', r'–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è\s+–¥–ª—è', r'–ø–æ–∑–≤–æ–ª—è–µ—Ç',
        r'—Å\s+–ø–æ–º–æ—â—å—é', r'–ø—Ä–∏\s+—Ä–∞–±–æ—Ç–µ'
    ]
    
    for indicator in context_indicators:
        matches = re.findall(f"{indicator}[^.!?]*{topic}[^.!?]*[.!?]", content)
        if matches:
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∏ –æ—á–∏—â–∞–µ–º
            match = matches[0]
            return clean_context_phrase(match)
    
    return "—Ä–∞–±–æ—Ç—ã —Å –∫–æ–º–ø—å—é—Ç–µ—Ä–æ–º"

def find_key_aspects(content, topic):
    """–ü–æ–∏—Å–∫ –∫–ª—é—á–µ–≤—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤"""
    # –ò—â–µ–º –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—è –∏ —Å–ø–∏—Å–∫–∏
    list_indicators = [r'–≤–æ-–ø–µ—Ä–≤—ã—Ö[^.!?]*', r'—Ç–∞–∫–∂–µ[^.!?]*', r'–∫—Ä–æ–º–µ —Ç–æ–≥–æ[^.!?]*']
    
    aspects = []
    for indicator in list_indicators:
        pattern = f"{indicator}[^.!?]*{topic}[^.!?]*[.!?]"
        matches = re.findall(pattern, content)
        for match in matches:
            aspect = clean_context_phrase(match)
            if aspect and aspect not in aspects:
                aspects.append(aspect)
    
    if aspects:
        return ", ".join(aspects[:2])
    
    return "–æ—Å–Ω–æ–≤–Ω—ã–º –ø—Ä–∏–Ω—Ü–∏–ø–∞–º –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–º—É –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é"

def find_practical_benefit(content, topic):
    """–ü–æ–∏—Å–∫ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π –ø–æ–ª—å–∑—ã"""
    benefit_indicators = [
        r'–ø–æ–º–æ–≥–∞–µ—Ç[^.!?]*', r'—É–ø—Ä–æ—â–∞–µ—Ç[^.!?]*', r'—É—Å–∫–æ—Ä—è–µ—Ç[^.!?]*',
        r'–ø–æ–∑–≤–æ–ª—è–µ—Ç[^.!?]*', r'–¥–∞–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å[^.!?]*'
    ]
    
    for indicator in benefit_indicators:
        pattern = f"{indicator}[^.!?]*{topic}[^.!?]*[.!?]"
        matches = re.findall(pattern, content)
        if matches:
            benefit = clean_context_phrase(matches[0])
            return benefit.replace(topic, "—ç—Ç–æ–≥–æ")
    
    return "—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —Ä–µ—à–∞—Ç—å –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏"

def clean_context_phrase(phrase):
    """–û—á–∏—Å—Ç–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π —Ñ—Ä–∞–∑—ã"""
    phrase = re.sub(r'\s+', ' ', phrase)
    phrase = phrase.strip()
    # –£–±–∏—Ä–∞–µ–º —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã
    if len(phrase) > 100:
        words = phrase.split()
        return ' '.join(words[:15]) + '...'
    return phrase



@app.route('/api/status')
def status():
    """–°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã"""
    sections_count = 0
    if db:
        try:
            sections = db.get_guide_sections(limit=1)
            sections_count = len(sections)
        except:
            sections_count = 0
    
    return jsonify({
        'status': 'running',
        'gigachat_available': GIGACHAT_AVAILABLE,
        'sections_loaded': sections_count
    })

def initialize_system():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã - –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ô –ü–ê–†–°–ò–ù–ì"""
    logger.info("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã —Ç—Ä–µ–Ω–∞–∂–µ—Ä–∞...")
    
    Config.init_directories()
    
    # –ü–†–Ø–ú–ê–Ø –ü–†–û–í–ï–†–ö–ê –§–ê–ô–õ–ê
    guide_path = "guide/digital_literacy_guide.pdf"
    logger.info(f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞: {os.path.abspath(guide_path)}")
    logger.info(f"üìÑ –§–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {os.path.exists(guide_path)}")
    
    if db:
        db.init_db()
        
        from services.pdf_parser import GuideParser
        parser = GuideParser()
        
        # –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ô –ü–ê–†–°–ò–ù–ì –í–°–ï–ì–û PDF
        logger.info("üîÑ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ–≥–æ PDF...")
        db.clear_guide_data()  # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
        
        sections_count = parser.parse_guide_pdf()
        
        if sections_count > 0:
            logger.info(f"‚úÖ PDF —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω: {sections_count} —Å—Ç—Ä–∞–Ω–∏—Ü")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            sections = db.get_guide_sections(limit=5)
            total_sections = len(db.get_guide_sections(limit=1000))
            logger.info(f"üìñ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ë–î: –∑–∞–≥—Ä—É–∂–µ–Ω–æ —Ä–∞–∑–¥–µ–ª–æ–≤ –≤—Å–µ–≥–æ: {total_sections}")
            for section in sections:
                logger.info(f"   - '{section['section_title']}' ({len(section['section_content'])} chars)")
                
            # –¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
            test_sections = get_relevant_sections("–∫–æ–º–ø—å—é—Ç–µ—Ä")
            logger.info(f"üîç –¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ '–∫–æ–º–ø—å—é—Ç–µ—Ä': –Ω–∞–π–¥–µ–Ω–æ {len(test_sections)} —Ä–∞–∑–¥–µ–ª–æ–≤")
        else:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å PDF")
    
    logger.info("‚úÖ –°–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")

if __name__ == '__main__':
    initialize_system()
    
    logger.info("üöÄ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ç—Ä–µ–Ω–∞–∂–µ—Ä –∑–∞–ø—É—â–µ–Ω!")
    logger.info("üîç –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å: http://localhost:5000/")
    
    app.run(debug=True, host='0.0.0.0', port=5000, use_reloader=False)